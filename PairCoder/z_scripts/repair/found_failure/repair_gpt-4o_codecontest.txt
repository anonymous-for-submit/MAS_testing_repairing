['\n[NO]']
Namespace(dataset='codecontest', split_name='test', model='gpt-4o', solution_file_name='solutions.json', id_range=None, id_list=None, dir_path='results_repair', method='pair_programming', output_path='./outputs/repair/', input_path='/data/zlyuaj/muti-agent/PairCoder/outputs/fuzzing/results-fuzzing_gpt-4o_codecontest_1-1_0-392rounds/_node_391.jsonl', output_file_name='repair_gpt-4o_codecontest', num_generate=10, parallel=0, mutate_method='random', num_round=1000, save_seed=1, recover=0, calc_analyst=1, calc_final_result=1, save_all_seed=0, set_threshold_analyst=1, calc_relative_reward=1, clean_mutate_method=1, split_input=1, mutate_level='whole', alpha=1.0, beta=1, add_monitor=1, repair_plan=1, repair_code=1, run_multi_gen=1, repair_prompt_num=2)
num_problems: 165
private_tests_dict 165
len of loaded problems: 14
multi-gen-prompt:
Luntik came out for a morning stroll and found an array a of length n. He calculated the sum s of the elements of the array. The formula he used for the calculation is (s= ∑_{i=1}^{n} a_i). Luntik calls a subsequence of the array a nearly full if the sum of the numbers in that subsequence is equal to s-1.

Luntik really wants to know the number of nearly full subsequences of the array a. But he needs to come home so he asks you to solve that problem!

A sequence x is a subsequence of a sequence y if x can be obtained from y by deletion of several (possibly, zero or all) elements.

Input

The first line contains a single integer t (1 ≤ t ≤ 1000) — the number of test cases. The next 2 ⋅ t lines contain descriptions of test cases. The description of each test case consists of two lines.

The first line of each test case contains a single integer n (1 ≤ n ≤ 60) — the length of the array.

The second line contains n integers a_1, a_2, …, a_n (0 ≤ a_i ≤ 10^9) — the elements of the array a.

Output

For each test case print the number of nearly full subsequences of the array.

Example

Input


5
5
1 2 3 4 5
2
1000 1000
2
1 0
5
3 0 2 1 1
5
2 1 0 3 0


Output


1
0
2
4
4

Note

In the first test case, s=1+2+3+4+5=15, only (2,3,4,5) is a nearly full subsequence among all subsequences, the sum in it is equal to 2+3+4+5=14=15-1.

In the second test case, there are no nearly full subsequences.

In the third test case, s=1+0=1, the nearly full subsequences are (0) and () (the sum of an empty subsequence is 0).
multi-gen-prompt:
Luntik came out for a morning stroll and found an array a of length n, calculating the sum s of the elements of the array (s= ∑_{i=1}^{n} a_i). Luntik calls a subsequence of the array a nearly full if the sum of the numbers in that subsequence is equal to s-1. Luntik really wants to know the number of nearly full subsequences of the array a, and he needs to come home so he asks you to solve that problem! A sequence x is a subsequence of a sequence y if x can be obtained from y by deletion of several (possibly, zero or all) elements.

Input

The first line contains a single integer t (1 ≤ t ≤ 1000) — the number of test cases. The next 2 ⋅ t lines contain descriptions of test cases. The description of each test case consists of two lines.

The first line of each test case contains a single integer n (1 ≤ n ≤ 60) — the length of the array.

The second line contains n integers a_1, a_2, …, a_n (0 ≤ a_i ≤ 10^9) — the elements of the array a.

Output

For each test case print the number of nearly full subsequences of the array.

Example

Input


5
5
1 2 3 4 5
2
1000 1000
2
1 0
5
3 0 2 1 1
5
2 1 0 3 0


Output


1
0
2
4
4

Note

In the first test case, s=1+2+3+4+5=15, only (2,3,4,5) is a nearly full subsequence among all subsequences, the sum in it is equal to 2+3+4+5=14=15-1.

In the second test case, there are no nearly full subsequences.

In the third test case, s=1+0=1, the nearly full subsequences are (0) and () (the sum of an empty subsequence is 0).
generating with gpt-4o
----------
['def count_nearly_full_subsequences(n, a):\n    # Calculate the sum of the array\n    s = sum(a)\n    \n    # Count the number of 1s in the array\n    count_of_ones = a.count(1)\n    \n    # Count the number of elements equal to s-1\n    count_of_s_minus_1 = a.count(s - 1)\n    \n    # Calculate the number of nearly full subsequences\n    if count_of_s_minus_1 > 0:\n        return (2 ** count_of_ones) + count_of_s_minus_1 - 1\n    else:\n        return (2 ** count_of_ones) - 1\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = count_nearly_full_subsequences(n, a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def count_nearly_full_subsequences(test_cases):\n    results = []\n    for n, array in test_cases:\n        total_sum = sum(array)\n        count_of_1 = array.count(1)\n        count_of_0 = array.count(0)\n        if count_of_1 > 0:\n            results.append(count_of_1 * (2 ** count_of_0))\n        else:\n            results.append(0)\n    return results\n\ndef parse_input():\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        array = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, array))\n    \n    return test_cases\n\nif __name__ == "__main__":\n    test_cases = parse_input()\n    results = count_nearly_full_subsequences(test_cases)\n    for result in results:\n        print(result)', 'def count_nearly_full_subsequences(n, array):\n    # Calculate the total sum of the array\n    total_sum = sum(array)\n    \n    # Count the number of 1s in the array\n    count_of_ones = array.count(1)\n    \n    # If there are no 1s, we cannot form a nearly full subsequence\n    if count_of_ones == 0:\n        return 0\n    \n    # Calculate the number of nearly full subsequences\n    # This is 2^count_of_ones - 1 because we can choose any subset of 1s except the empty set\n    return (2 ** count_of_ones) - 1\n\ndef process_test_cases(test_cases):\n    results = []\n    for n, array in test_cases:\n        result = count_nearly_full_subsequences(n, array)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        array = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, array))\n    \n    results = process_test_cases(test_cases)\n    \n    for result in results:\n        print(result)', 'from itertools import combinations\n\ndef count_nearly_full_subsequences(arr):\n    total_sum = sum(arr)\n    if total_sum == 0:\n        return 0\n    count = 0\n    n = len(arr)\n    for i in range(1, n + 1):\n        for subseq in combinations(arr, i):\n            if sum(subseq) == total_sum - 1:\n                count += 1\n    return count\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        arr = list(map(int, data[index:index + n]))\n        index += n\n        result = count_nearly_full_subsequences(arr)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def count_nearly_full_subsequences(test_cases):\n    results = []\n    for n, array in test_cases:\n        total_sum = sum(array)\n        if total_sum == 0:\n            results.append(0)\n            continue\n        \n        target_sum = total_sum - 1\n        count = 0\n        \n        # Generate all possible subsequences using binary masks\n        for mask in range(1 << n):\n            subsequence_sum = sum(array[i] for i in range(n) if mask & (1 << i))\n            if subsequence_sum == target_sum:\n                count += 1\n        \n        results.append(count)\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        array = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, array))\n    \n    results = count_nearly_full_subsequences(test_cases)\n    \n    for result in results:\n        print(result)', 'def count_nearly_full_subsequences(n, a):\n    # Calculate the total sum of the array\n    total_sum = sum(a)\n    \n    # Initialize a counter for nearly full subsequences\n    count = 0\n    \n    # Iterate through each element\n    for element in a:\n        # Check if removing the element results in a sum of s-1\n        if total_sum - element == total_sum - 1:\n            count += 1\n    \n    return count\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = count_nearly_full_subsequences(n, a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def count_nearly_full_subsequences(n, a):\n    total_sum = sum(a)\n    count_of_ones = a.count(1)\n    \n    if total_sum - 1 < 0:\n        return 0\n    \n    # The number of nearly full subsequences is 2^count_of_ones - 1\n    # because we can choose any subset of \'1\'s to make the sum s-1.\n    return (1 << count_of_ones) - 1\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = count_nearly_full_subsequences(n, a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def count_nearly_full_subsequences(n, array):\n    # Calculate the total sum of the array\n    total_sum = sum(array)\n    \n    # Count the number of \'1\'s in the array\n    count_of_ones = array.count(1)\n    \n    # If there are no \'1\'s, there can be no nearly full subsequences\n    if count_of_ones == 0:\n        return 0\n    \n    # Calculate the number of nearly full subsequences\n    # Each \'1\' can either be included or not in a subsequence\n    # We subtract 1 to exclude the empty subsequence\n    return (2 ** count_of_ones) - 1\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        array = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = count_nearly_full_subsequences(n, array)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'from itertools import combinations\n\ndef count_nearly_full_subsequences(n, arr):\n    total_sum = sum(arr)\n    target_sum = total_sum - 1\n    count = 0\n    \n    # Generate all possible subsequences\n    for r in range(n + 1):\n        for subseq in combinations(arr, r):\n            if sum(subseq) == target_sum:\n                count += 1\n    \n    return count\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        arr = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = count_nearly_full_subsequences(n, arr)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def count_nearly_full_subsequences(n, a):\n    s = sum(a)\n    count = 0\n    \n    # Edge case handling\n    if s == 0:\n        return 2**n - 1\n    elif n == 1:\n        return 1 if a[0] == 1 else 0\n    \n    # Iterate over all possible subsequences using a binary mask\n    for mask in range(1 << n):\n        subsequence_sum = 0\n        for i in range(n):\n            if mask & (1 << i):\n                subsequence_sum += a[i]\n        \n        if subsequence_sum == s - 1:\n            count += 1\n    \n    return count\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = count_nearly_full_subsequences(n, a)\n        results.append(result)\n    \n    for res in results:\n        print(res)']
----------
["- name: \nSubsequence Sum Verification\n\n- content: \nThis approach explicitly verifies subsequence sums using a methodical check. However, given constraints, it's simplified by leveraging insights from the problem description.\nSteps:\n1. For each test case, read the array length `n` and the array elements `a`.\n2. Calculate the sum `s` of the array.\n3. Iterate through each element, `a[i]`, checking if it's equal to 1.\n4. For each `1` found, verify that excluding it results in a subsequence with sum `s - 1`.\n5. Count such occurrences and output the count.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'nearly full subsequence'\n    Explanation: A subsequence of the array whose sum is exactly one less than the total sum of the array.\n\n# [phrase showing quantity relationship]\n    'equal to s-1': This indicates that the sum of the subsequence should be exactly one less than the sum of the entire array. In code, this can be implemented by checking if the sum of a subsequence is `s - 1`.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 3 and 4 should be implemented simultaneously. When iterating through each element to check if it's equal to 1, you should also verify that excluding it results in a subsequence with sum `s - 1`. This can be done in a single loop where you check the condition and count occurrences.\n\n# [edge case] \n    Test case with all elements as zero: \n    Input: 3\n           0 0 0\n    Output: 0\n    Explanation: The sum of the array is 0, and there cannot be a subsequence with sum -1.\n\n    Test case with only one element being 1:\n    Input: 1\n           1\n    Output: 1\n    Explanation: The sum of the array is 1, and excluding the single element results in an empty subsequence with sum 0, which is `s - 1`.\n\n    Test case with multiple ones:\n    Input: 4\n           1 1 1 1\n    Output: 4\n    Explanation: The sum of the array is 4, and excluding any one of the '1's results in a subsequence with sum 3, which is `s - 1`.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if s == 0:\n            return 0\n        count = a.count(1)\n        return count", "- name: \nEfficient Counting Using Hash Map\n\n- content: \nThis solution uses a hash map to count occurrences of each number in the array. The focus is on numbers that can potentially be excluded to form a nearly full subsequence, specifically numbers that reduce the total sum by their value plus one when excluded (here specifically '1').\n\nSteps:\n1. Initialize a list to store results for each test case.\n2. Iterate over each test case:\n   - Parse n and the array a.\n   - Calculate the total sum s of the array.\n   - Utilize a hash map (dictionary) to count occurrences of each integer in the array.\n   - The number of nearly full subsequences is determined by the count of '1' in the hash map multiplied by 2^(count_of_0), where count_of_0 is from step 2.\n3. Append the result for each test case to the results list.\n4. Output the results list.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'nearly full subsequence'\n    Explanation: A subsequence of the array whose sum is equal to the total sum of the array minus one.\n\n    'subsequence'\n    Explanation: A sequence derived from another sequence by deleting some or no elements without changing the order of the remaining elements.\n\n# [phrase showing quantity relationship]\n    'equal to s-1': The sum of the subsequence should be exactly one less than the total sum of the array.\n    Implementation: Calculate the total sum `s` and check if the sum of a subsequence is `s-1`.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps involving counting occurrences of numbers and calculating the number of nearly full subsequences should be implemented simultaneously. Specifically, counting occurrences of '1' and '0' can be done in a single pass through the array, and then use these counts to determine the number of nearly full subsequences.\n\n# [edge case] \n    Test case with all elements as zero: \n    Input: 3\n           0 0 0\n    Output: 8\n    Explanation: The total sum is 0, and any subsequence excluding one element (or none) will have a sum of -1, which is not possible. However, since we are looking for subsequences that sum to -1, we consider all possible subsequences formed by excluding zero elements, which are 2^3 = 8.\n\n    Test case with no '1's:\n    Input: 3\n           2 2 2\n    Output: 0\n    Explanation: There are no '1's to exclude, so no nearly full subsequences can be formed.\n\n    Test case with mixed numbers:\n    Input: 4\n           1 0 2 1\n    Output: 4\n    Explanation: The total sum is 4, and excluding one '1' gives a sum of 3. There are two '1's and one '0', so the number of nearly full subsequences is 2 * 2^1 = 4.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        def count_nearly_full_subsequences(test_cases):\n            results = []\n            for n, array in test_cases:\n                total_sum = sum(array)\n                count_of_1 = array.count(1)\n                count_of_0 = array.count(0)\n                if count_of_1 > 0:\n                    results.append(count_of_1 * (2 ** count_of_0))\n                else:\n                    results.append(0)\n            return results", '- name: \nDirect Sum Calculation and Element Exclusion\n- content: \nThis approach directly computes the number of subsequences whose sum is exactly one less than the total sum of the array by excluding specific elements. Here’s how it can be implemented:\n\n1. For each test case, calculate the total sum `s` of the array.\n2. Initialize a counter for nearly full subsequences as zero.\n3. Iterate through each element in the array:\n   - If an element is `1`, increment the counter since removing this element would make a subsequence sum equal to `s-1`.\n   - If no elements are `1`, no nearly full subsequence can be formed.\n4. After processing all elements, store the counter value as the result for the current test case.\n5. Output all results after processing all test cases.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'nearly full subsequence\'\n    Explanation: A subsequence of the array whose sum is exactly one less than the total sum of the array.\n\n# [phrase showing quantity relationship]\n    \'equal to\': means that the sum of the subsequence should be exactly s-1, where s is the sum of the array.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps 2-4 should be implemented simultaneously:\n    "Initialize a counter for nearly full subsequences as zero",\n    "Iterate through each element in the array",\n    "If an element is `1`, increment the counter since removing this element would make a subsequence sum equal to `s-1`"\n    This can be done by iterating through the array and checking if each element is 1, incrementing the counter if true.\n\n# [edge case] \n    Test case with all elements as 1: [1, 1, 1, 1] = 4\n    Explanation: Removing any single \'1\' results in a subsequence sum of s-1.\n    \n    Test case with no elements as 1: [2, 3, 4] = 0\n    Explanation: No element can be removed to achieve a subsequence sum of s-1.\n    \n    Test case with mixed elements including zero: [0, 1, 2] = 1\n    Explanation: Removing \'1\' results in a subsequence sum of s-1.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of checking for elements equal to \'1\' and incrementing the counter suffices.', '- name: \nBrute Force Subsequence Generation\n- content: \nThis approach involves generating all possible subsequences of the given array and checking if the sum of the subsequence is equal to s-1, where s is the total sum of the array.\n\n- For each test case, calculate the total sum \'s\' of the array.\n- Generate all possible non-empty subsequences of the array.\n- For each subsequence, calculate its sum and check if it equals s-1.\n- Count the number of valid subsequences that satisfy this condition.\n- Return the count for each test case.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'nearly full subsequence\'\n    Explanation: A subsequence of the array whose sum is exactly one less than the total sum of the array.\n\n    \'subsequence\'\n    Explanation: A sequence derived from another sequence where some elements may be deleted without changing the order of the remaining elements.\n\n# [phrase showing quantity relationship]\n    \'equal to s-1\': This means that the sum of the subsequence should be exactly one less than the total sum of the array. In code, this can be implemented by checking if the sum of a subsequence is equal to `total_sum - 1`.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps "Generate all possible non-empty subsequences of the array" and "For each subsequence, calculate its sum and check if it equals s-1" should be implemented simultaneously. This can be done by iterating through all possible combinations of elements in the array and checking their sums in a single loop or recursive function.\n\n# [edge case] \n    Test case: [0, 0, 0] = 0\n    Explanation: The total sum is 0, and there cannot be a subsequence with a sum of -1.\n\n    Test case: [1, 1, 1] = 3\n    Explanation: The total sum is 3, and each subsequence with two elements (e.g., [1, 1]) has a sum of 2, which is equal to 3-1.\n\n    Test case: [10^9, 10^9] = 0\n    Explanation: The total sum is 2 * 10^9, and there cannot be a subsequence with a sum of 2 * 10^9 - 1 because each element is 10^9.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where the array consists entirely of zeros or very large numbers.\n    \n    ```python\n    def count_nearly_full_subsequences(arr):\n        total_sum = sum(arr)\n        if total_sum == 0:\n            return 0\n        count = 0\n        for i in range(1, len(arr) + 1):\n            for subseq in combinations(arr, i):\n                if sum(subseq) == total_sum - 1:\n                    count += 1\n        return count\n    ```', "- name: \nBinary Mask Simulation (Inefficient)\n\n- content: \nThis approach considers generating all possible subsequences and counting those whose sum is `s-1`. This is largely inefficient for larger arrays but serves as an educational method to understand how subsequences can be checked.\n\nSteps:\n1. For each test case, read the integer n and the array a of length n.\n2. Calculate the total sum s of all elements in the array.\n3. Generate all possible binary masks of length n (2^n masks).\n4. For each mask, generate a subsequence and calculate its sum.\n   - If any subsequence sum equals `s-1`, increment a counter.\n5. Output the counter as it represents the number of nearly full subsequences.\n\nEdge Cases:\n- This approach is inefficient for n > 20 due to exponential growth in possible masks.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'nearly full subsequence'\n    Explanation: A subsequence of the array whose sum of elements is exactly one less than the total sum of the array.\n\n    'subsequence'\n    Explanation: A sequence derived from another sequence where some elements may be deleted without changing the order of the remaining elements.\n\n# [phrase showing quantity relationship]\n    's-1': This indicates that the sum of the subsequence should be exactly one less than the total sum of the array. In code, this can be implemented by calculating the total sum `s` and checking if any subsequence sums to `s-1`.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 3 and 4 should be implemented simultaneously. Generating a binary mask and calculating the subsequence sum should occur in the same loop to efficiently check each possible subsequence.\n\n# [edge case] \n    Test case with all elements zero: \n    Input: 3\n           0 0 0\n    Output: 0\n    Explanation: The total sum `s` is 0, so `s-1` is -1. No subsequence can have a negative sum, so the output is 0.\n\n    Test case with a single element:\n    Input: 1\n           5\n    Output: 0\n    Explanation: The total sum `s` is 5, so `s-1` is 4. The only subsequence is the empty one or the single element itself, neither of which sums to 4.\n\n    Test case with two identical elements:\n    Input: 2\n           3 3\n    Output: 0\n    Explanation: The total sum `s` is 6, so `s-1` is 5. No subsequence can sum to 5 since each element is 3.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where the sum `s` is zero or when there are very few elements.\n    \n```python\ndef count_nearly_full_subsequences(test_cases):\n    results = []\n    for n, array in test_cases:\n        total_sum = sum(array)\n        if total_sum == 0:\n            results.append(0)\n            continue\n        \n        target_sum = total_sum - 1\n        count = 0\n        \n        # Generate all possible subsequences using binary masks\n        for mask in range(1 << n):\n            subsequence_sum = sum(array[i] for i in range(n) if mask & (1 << i))\n            if subsequence_sum == target_sum:\n                count += 1\n        \n        results.append(count)\n    \n    return results\n```\nThis code handles cases where the total sum is zero by immediately returning zero for that test case, as no subsequence can have a negative sum.", '- name: \nCheck Subsequence Sum with One Removal\n- content: \n- For each test case, calculate the total sum `s` of the array.\n- Iterate over each element in the array.\n- For each element, check if its removal results in a subsequence sum of `s-1`.\n- If so, it means that element can be excluded to form a nearly full subsequence.\n- Count the number of such elements that can be removed to form nearly full subsequences.\n- This approach ensures that each element is checked for its potential to reduce the total sum by exactly 1, ensuring correctness.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'nearly full subsequence\'\n    Explanation: A subsequence of the array whose sum is exactly one less than the total sum of the array.\n\n    \'subsequence\'\n    Explanation: A sequence derived from another sequence where some elements may be deleted without changing the order of the remaining elements.\n\n# [phrase showing quantity relationship]\n    \'equal to s-1\': This means that the sum of the subsequence should be exactly one less than the total sum of the array. In code, this can be implemented by checking if the sum of the subsequence equals `s-1`.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps "Iterate over each element in the array" and "For each element, check if its removal results in a subsequence sum of `s-1`" should be implemented simultaneously. This can be done by iterating through the array and checking if removing each element results in the desired subsequence sum.\n\n# [edge case] \n    Test case: [0, 0, 0] = 0\n    Explanation: The total sum is 0, and removing any element still results in a sum of 0, which is not `s-1`.\n\n    Test case: [1, 1, 1] = 3\n    Explanation: The total sum is 3, and removing any one element results in a sum of 2, which is `s-1`.\n\n    Test case: [10^9, 10^9] = 0\n    Explanation: The total sum is 2 * 10^9, and removing any one element results in a sum of 10^9, which is not `s-1`.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating through each element and checking if its removal results in a subsequence sum of `s-1` will naturally handle these cases.', '- name: \nUse Hash Map to Track Counts\n\n- content: \nA hash map can be used to efficiently count occurrences of each element in the array, particularly focusing on \'1\', which is critical for forming nearly full subsequences. Here are the steps:\n1. For each test case, read the integer n and the array a.\n2. Calculate the total sum s of the array.\n3. Use a hash map (or dictionary) to count occurrences of elements in a.\n4. Retrieve and output the count of \'1\' from the hash map, since removing each \'1\' results in a nearly full subsequence.\n5. Print the result for each test case.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'nearly full subsequence\'\n    Explanation: A subsequence of the array whose sum is exactly one less than the total sum of the array.\n\n# [phrase showing quantity relationship]\n    \'equal to s-1\': This means the sum of the subsequence should be exactly one less than the total sum of the array. In code, this can be implemented by checking if the sum of a subsequence is `s - 1`.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps 3 and 4 should be implemented simultaneously.\n    "Use a hash map (or dictionary) to count occurrences of elements in a."\n    "Retrieve and output the count of \'1\' from the hash map, since removing each \'1\' results in a nearly full subsequence."\n    This can be done by iterating through the array once to populate the hash map and then directly accessing the count of \'1\'.\n\n# [edge case] \n    Test case: [1, 1, 1, 1] = 4\n    Explanation: The total sum is 4, and removing any one \'1\' results in a sum of 3, which is `4 - 1`. There are four \'1\'s, so there are four nearly full subsequences.\n    \n    Test case: [0, 0, 0] = 0\n    Explanation: The total sum is 0, and there are no elements to remove to achieve `0 - 1`, so there are no nearly full subsequences.\n    \n    Test case: [2, 2, 2] = 0\n    Explanation: The total sum is 6, and no single element removal can achieve a sum of `6 - 1 = 5`, so there are no nearly full subsequences.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of counting occurrences of \'1\' and using it to determine nearly full subsequences will handle these cases correctly.', "- name: \nUsing Inclusion-Exclusion Principle\n\n- content: \nAnother approach is to use the inclusion-exclusion principle to find subsets.\nSteps:\n1. Iterate over each test case.\n2. Calculate the sum 's' of the array elements.\n3. For each element in the array, check if it is equal to 1.\n4. If an element is equal to 1, consider the array without this element and calculate the sum, which should be s-1.\n5. Count such valid exclusions where removing the element makes the sum s-1.\n6. Output the count as the number of nearly full subsequences.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'nearly full subsequence'\n    Explanation: A subsequence of the array where the sum of its elements is exactly one less than the total sum of the array.\n\n# [phrase showing quantity relationship]\n    'equal to': means that the sum of the subsequence should be exactly s-1, where s is the sum of the entire array.\n    Implementation: Check if removing an element results in a sum of s-1.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 3-5 should be implemented simultaneously.\n    Explanation: For each element in the array, check if it is equal to 1, and if so, consider the array without this element and calculate the sum. Count such valid exclusions where removing the element makes the sum s-1.\n\n# [edge case] \n    Test case with all elements as 0: [0, 0, 0] = 0\n    Explanation: The sum of the array is 0, and no subsequence can have a sum of -1.\n    \n    Test case with all elements as 1: [1, 1, 1] = 3\n    Explanation: Removing any one element results in a sum of 2, which is s-1. There are three such subsequences.\n    \n    Test case with a single element equal to 1: [1] = 1\n    Explanation: The only subsequence that can be nearly full is the empty subsequence, which has a sum of 0.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        for each test case:\n            calculate total sum s\n            if s == 0:\n                print(0)\n            else:\n                count = 0\n                for element in array:\n                    if element == 1:\n                        count += 1\n                print(count)", '- name: \nBrute Force Subsequence Generation\n\n- content: \nThis approach involves generating all possible subsequences and checking their sums.\nSteps:\n1. For each test case, read the integer n (length of array) and the array a.\n2. Calculate the total sum s of the array.\n3. Generate all possible subsequences of the array.\n4. For each subsequence, calculate its sum.\n5. Check if the sum is equal to s-1. If yes, count it as a nearly full subsequence.\n6. After checking all subsequences, print the count for each test case.\nNote: This approach is inefficient for large arrays, but it works given the constraints (n ≤ 60).\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'nearly full subsequence\'\n    Explanation: A subsequence of the array whose sum of elements is exactly one less than the total sum of the array.\n\n# [phrase showing quantity relationship]\n    \'equal to s-1\': This means that the sum of the subsequence should be exactly one less than the total sum of the array. In code, this can be implemented by checking if the sum of a subsequence is equal to `total_sum - 1`.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 3-5 should be implemented simultaneously. \n    "Generate all possible subsequences of the array",\n    "For each subsequence, calculate its sum",\n    "Check if the sum is equal to s-1. If yes, count it as a nearly full subsequence."\n    This can be done by iterating through all possible combinations of elements in the array, calculating their sum, and checking if it matches `total_sum - 1`.\n\n# [edge case] \n    Test case: [0, 0, 0] = 7\n    Explanation: The total sum is 0. The nearly full subsequences are all possible non-empty subsequences since their sum is -1, which is not possible. However, since all elements are zero, any non-empty subsequence will have a sum of 0, which is equal to `0 - 1 + 1` (considering the empty subsequence as well).\n\n    Test case: [1, 1, 1] = 3\n    Explanation: The total sum is 3. The nearly full subsequences are those whose sum is 2. These are (1,1), (1,1), and (1,1) for each pair of ones.\n\n    Test case: [10^9, 10^9] = 0\n    Explanation: The total sum is 2 * 10^9. There are no subsequences whose sum is `2 * 10^9 - 1`, so the output is 0.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases efficiently.\n    Since generating all subsequences is inefficient for large arrays, we can optimize by considering:\n    \n    - If there are multiple identical elements, we can use combinatorial counting instead of generating all subsequences.\n    - Specifically, if there are `k` elements with value `v`, and `s - v = s - 1`, then we can count how many ways we can exclude one element `v` from the total set of `v` elements.\n    \n    Example code snippet:\n    ```python\n    from collections import Counter\n\n    def count_nearly_full_subsequences(arr):\n        total_sum = sum(arr)\n        count = Counter(arr)\n        result = 0\n        \n        for value in count:\n            if total_sum - value == total_sum - 1:\n                result += count[value]\n        \n        return result\n    ```', '- name: \nSimulation of Subsequence Formation\n\n- content: \nThis approach involves simulating the formation of subsequences to find those whose sum is exactly s-1. While less efficient, it provides a direct understanding of subsequence formation:\n1. For each test case, read the array and calculate the sum s.\n2. Generate all possible subsequences using a binary mask technique (iterate through all 2^n possible combinations).\n3. For each subsequence, calculate its sum.\n4. Check if the sum is equal to s-1, and if so, increment the count.\n5. Output the count for each test case.\nNote: This approach is not efficient for larger arrays due to its exponential nature but works within constraints.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'nearly full subsequence\'\n    Explanation: A subsequence of the array whose sum is exactly one less than the total sum of the array elements.\n\n# [phrase showing quantity relationship]\n    \'equal to s-1\': means that the sum of the subsequence should be exactly one less than the total sum of the array elements.\n    Implementation: Check if the sum of a subsequence is equal to s-1.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 3 and 4 should be implemented simultaneously.\n    "For each subsequence, calculate its sum" and "Check if the sum is equal to s-1, and if so, increment the count" can be done in a single loop where each subsequence\'s sum is calculated and immediately checked against s-1.\n\n# [edge case] \n    Test case with all elements being zero: [0, 0, 0] = 7\n    Explanation: The sum s is 0, so any subsequence with a sum of -1 is impossible. However, the empty subsequence is considered valid as its sum is 0, which is s-1.\n    \n    Test case with a single element: [1] = 0\n    Explanation: The sum s is 1, and the only nearly full subsequence is the empty one, which has a sum of 0.\n    \n    Test case with all elements being the same: [2, 2, 2] = 3\n    Explanation: The sum s is 6, and any subsequence with a sum of 5 (s-1) can be formed by removing one element.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if s == 0:\n            return 2**n - 1\n        elif n == 1:\n            return 1 if a[0] == 1 else 0\n        (other code)']
----------
False
----------
0
multi-gen-prompt:
The problem statement looms below, filling you with determination.

Consider a grid in which some cells are empty and some cells are filled. Call a cell in this grid exitable if, starting at that cell, you can exit the grid by moving up and left through only empty cells. This includes the cell itself. Therefore, all filled in cells are not exitable. Note that you can exit the grid from any leftmost empty cell (cell in the first column) by going left, and from any topmost empty cell (cell in the first row) by going up.

Let's call a grid determinable if, given only which cells are exitable, we can exactly determine which cells are filled in and which aren't.

You are given a grid a of dimensions n × m , i. e. a grid with n rows and m columns. You need to answer q queries (1 ≤ q ≤ 2 ⋅ 10^5). Each query gives two integers x_1, x_2 (1 ≤ x_1 ≤ x_2 ≤ m) and asks whether the subgrid of a consisting of the columns x_1, x_1 + 1, …, x_2 - 1, x_2 is determinable.

Input

The first line contains two integers n, m (1 ≤ n, m ≤ 10^6, nm ≤ 10^6) — the dimensions of the grid a.

n lines follow. The y-th line contains m characters, the x-th of which is 'X' if the cell on the intersection of the the y-th row and x-th column is filled and "." if it is empty.

The next line contains a single integer q (1 ≤ q ≤ 2 ⋅ 10^5) — the number of queries.

q lines follow. Each line contains two integers x_1 and x_2 (1 ≤ x_1 ≤ x_2 ≤ m), representing a query asking whether the subgrid of a containing the columns x_1, x_1 + 1, …, x_2 - 1, x_2 is determinable.

Output

For each query, output one line containing "YES" if the subgrid specified by the query is determinable and "NO" otherwise. The output is case insensitive (so "yEs" and "No" will also be accepted).

Example

Input


4 5
..XXX
...X.
...X.
...X.
5
1 3
3 3
4 5
5 5
1 5


Output


YES
YES
NO
YES
NO

Note

For each query of the example, the corresponding subgrid is displayed twice below: first in its input format, then with each cell marked as "E" if it is exitable and "N" otherwise.

For the first query: 
    
    
      
    ..X EEN  
    ... EEE  
    ... EEE  
    ... EEE  
    
    
    
      
      
    

For the second query: 
    
    
      
    X N  
    . E  
    . E  
    . E  
    

Note that you can exit the grid by going left from any leftmost cell (or up from any topmost cell); you do not need to reach the top left corner cell to exit the grid.
    
    
      
      
    

For the third query: 
    
    
      
    XX NN  
    X. NN  
    X. NN  
    X. NN  
    

This subgrid cannot be determined only from whether each cell is exitable, because the below grid produces the above "exitability grid" as well: 
    
    
      
    XX  
    XX  
    XX  
    XX  
    
    
    
      
      
    

For the fourth query: 
    
    
      
    X N  
    . E  
    . E  
    . E  
    
    
    
      
      
    

For the fifth query: 
    
    
      
    ..XXX EENNN  
    ...X. EEENN  
    ...X. EEENN  
    ...X. EEENN  
    

This query is simply the entire grid. It cannot be determined only from whether each cell is exitable because the below grid produces the above "exitability grid" as well: 
    
    
      
    ..XXX  
    ...XX  
    ...XX  
    ...XX  
    
multi-gen-prompt:
The problem statement looms below, filling you with determination.

Consider a grid in which some cells are empty and some cells are filled, and call a cell in this grid exitable if, starting at that cell, you can exit the grid by moving up and left through only empty cells, including the cell itself, so all filled in cells are not exitable. Note that you can exit the grid from any leftmost empty cell (cell in the first column) by going left, and from any topmost empty cell (cell in the first row) by going up.

Let's call a grid determinable if, given only which cells are exitable, we can exactly determine which cells are filled in and which aren't.

You are given a grid a of dimensions n × m , i. e. a grid with n rows and m columns. You need to answer q queries (1 ≤ q ≤ 2 ⋅ 10^5). Each query gives two integers x_1, x_2 (1 ≤ x_1 ≤ x_2 ≤ m) and asks whether the subgrid of a consisting of the columns x_1, x_1 + 1, …, x_2 - 1, x_2 is determinable.

Input

The first line contains two integers n, m (1 ≤ n, m ≤ 10^6, nm ≤ 10^6) — the dimensions of the grid a.

n lines follow. The y-th line contains m characters, the x-th of which is 'X' if the cell on the intersection of the the y-th row and x-th column is filled and "." if it is empty.

The next line contains a single integer q (1 ≤ q ≤ 2 ⋅ 10^5) — the number of queries.

q lines follow. Each line contains two integers x_1 and x_2 (1 ≤ x_1 ≤ x_2 ≤ m), representing a query asking whether the subgrid of a containing the columns x_1, x_1 + 1, …, x_2 - 1, x_2 is determinable.

Output

For each query, output one line containing "YES" if the subgrid specified by the query is determinable and "NO" otherwise. The output is case insensitive (so "yEs" and "No" will also be accepted).

Example

Input


4 5
..XXX
...X.
...X.
...X.
5
1 3
3 3
4 5
5 5
1 5


Output


YES
YES
NO
YES
NO

Note

For each query of the example, the corresponding subgrid is displayed twice below: first in its input format, then with each cell marked as "E" if it is exitable and "N" otherwise.

For the first query: 
    
    
      
    ..X EEN  
    ... EEE  
    ... EEE  
    ... EEE  
    
    
    
      
      
    

For the second query: 
    
    
      
    X N  
    . E  
    . E  
    . E  
    

Note that you can exit the grid by going left from any leftmost cell (or up from any topmost cell); you do not need to reach the top left corner cell to exit the grid.
    
    
      
      
    

For the third query: 
    
    
      
    XX NN  
    X. NN  
    X. NN  
    X. NN  
    

This subgrid cannot be determined only from whether each cell is exitable, because the below grid produces the above "exitability grid" as well: 
    
    
      
    XX  
    XX  
    XX  
    XX  
    
    
    
      
      
    

For the fourth query: 
    
    
      
    X N  
    . E  
    . E  
    . E  
    
    
    
      
      
    

For the fifth query: 
    
    
      
    ..XXX EENNN  
    ...X. EEENN  
    ...X. EEENN  
    ...X. EEENN  
    

This query is simply the entire grid. It cannot be determined only from whether each cell is exitable because the below grid produces the above "exitability grid" as well: 
    
    
      
    ..XXX  
    ...XX  
    ...XX  
    ...XX  
    
generating with gpt-4o
----------
['def preprocess_affected(grid, n, m):\n    affected = [False] * (m - 1)\n    for i in range(n):\n        for j in range(m - 1):\n            if grid[i][j] == \'X\' and grid[i][j + 1] == \'.\':\n                affected[j] = True\n    return affected\n\ndef check_determinable(affected, x1, x2):\n    for j in range(x1, x2):\n        if affected[j]:\n            return "NO"\n    return "YES"\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    n = int(data[index])\n    m = int(data[index + 1])\n    index += 2\n    \n    grid = []\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n    \n    q = int(data[index])\n    index += 1\n    \n    queries = []\n    for _ in range(q):\n        x1 = int(data[index]) - 1\n        x2 = int(data[index + 1]) - 1\n        queries.append((x1, x2))\n        index += 2\n    \n    affected = preprocess_affected(grid, n, m)\n    \n    results = []\n    for x1, x2 in queries:\n        result = check_determinable(affected, x1, x2)\n        results.append(result)\n    \n    for result in results:\n        print(result)', 'def precompute_transitions(grid, n, m):\n    # Initialize the transition array\n    transitions = [0] * (m - 1)\n    \n    # Iterate through each row to find transitions between adjacent columns\n    for row in range(n):\n        for col in range(m - 1):\n            # Check if there\'s a transition from a filled cell in one column to an empty cell in the next column\n            if grid[row][col] == \'X\' and grid[row][col + 1] == \'.\':\n                transitions[col] = 1\n    \n    return transitions\n\ndef is_determinable(transitions, x1, x2):\n    # Check if there is any transition between columns x1 and x2\n    for col in range(x1, x2):\n        if transitions[col] == 1:\n            return "NO"\n    return "YES"\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    # Read dimensions of the grid\n    n = int(data[0])\n    m = int(data[1])\n    \n    # Read the grid\n    grid = []\n    index = 2\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n    \n    # Precompute transitions\n    transitions = precompute_transitions(grid, n, m)\n    \n    # Read number of queries\n    q = int(data[index])\n    index += 1\n    \n    # Process each query\n    results = []\n    for _ in range(q):\n        x1 = int(data[index]) - 1  # Convert to 0-based index\n        x2 = int(data[index + 1]) - 1  # Convert to 0-based index\n        index += 2\n        \n        result = is_determinable(transitions, x1, x2)\n        results.append(result)\n    \n    # Output results for each query\n    for result in results:\n        print(result)', 'def preprocess_grid(n, m, grid):\n    # Step 1: Initialize the non_determinable array\n    non_determinable = [0] * (m - 1)\n\n    # Step 2: Traverse the grid to identify transitions between adjacent columns\n    for row in range(n):\n        for col in range(m - 1):\n            if grid[row][col] == \'X\' and grid[row][col + 1] == \'.\':\n                non_determinable[col] = 1\n\n    # Step 3: Precompute prefix sums on non_determinable array\n    prefix_sums = [0] * (m)\n    for i in range(1, m):\n        prefix_sums[i] = prefix_sums[i - 1] + non_determinable[i - 1]\n\n    return prefix_sums\n\ndef is_determinable(prefix_sums, x1, x2):\n    # Check if there are any transitions in the range [x1, x2-1]\n    if prefix_sums[x2 - 1] - prefix_sums[x1 - 1] > 0:\n        return "NO"\n    else:\n        return "YES"\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n\n    # Read dimensions of the grid\n    n = int(data[0])\n    m = int(data[1])\n\n    # Read the grid\n    grid = []\n    index = 2\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n\n    # Preprocess the grid to get prefix sums\n    prefix_sums = preprocess_grid(n, m, grid)\n\n    # Read number of queries\n    q = int(data[index])\n    index += 1\n\n    # Process each query\n    results = []\n    for _ in range(q):\n        x1 = int(data[index])\n        x2 = int(data[index + 1])\n        index += 2\n        results.append(is_determinable(prefix_sums, x1, x2))\n\n    # Output results for each query\n    for result in results:\n        print(result)', 'def handle_edge_cases(grid, queries):\n    # Check if the grid is entirely empty or filled\n    all_empty = all(cell == \'.\' for row in grid for cell in row)\n    all_filled = all(cell == \'X\' for row in grid for cell in row)\n    \n    if all_empty or all_filled:\n        return ["YES" for _ in queries]\n    \n    # Proceed with normal logic if not an edge case\n    return None\n\ndef detect_barriers(grid, n, m):\n    # Create a barrier array to mark where barriers exist between columns\n    barriers = [False] * (m - 1)\n    \n    for col in range(1, m):\n        for row in range(n):\n            # Check if there\'s a transition from \'X\' to \'.\' between columns\n            if grid[row][col - 1] == \'X\' and grid[row][col] == \'.\':\n                barriers[col - 1] = True\n                break\n    \n    return barriers\n\ndef process_queries(barriers, queries):\n    results = []\n    for x1, x2 in queries:\n        # Check if there is any barrier between columns x1 and x2\n        if any(barriers[x1 - 1:x2 - 1]):\n            results.append("NO")\n        else:\n            results.append("YES")\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    m = int(data[1])\n    \n    grid = []\n    index = 2\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n    \n    q = int(data[index])\n    index += 1\n    \n    queries = []\n    for _ in range(q):\n        x1 = int(data[index])\n        x2 = int(data[index + 1])\n        queries.append((x1, x2))\n        index += 2\n    \n    # Handle edge cases first\n    edge_case_result = handle_edge_cases(grid, queries)\n    if edge_case_result is not None:\n        for result in edge_case_result:\n            print(result)\n    else:\n        # Detect barriers between columns\n        barriers = detect_barriers(grid, n, m)\n        \n        # Process each query and output the result\n        results = process_queries(barriers, queries)\n        for result in results:\n            print(result)', 'def precompute_transitions(grid, n, m):\n    # Initialize the transitions array\n    transitions = [0] * m\n    \n    # Traverse the grid row-wise\n    for i in range(n):\n        for j in range(1, m):\n            # If there\'s a filled cell in the current column and an empty cell in the next column in the same row\n            if grid[i][j - 1] == \'X\' and grid[i][j] == \'.\':\n                transitions[j] = 1\n    \n    # Compute prefix sums for transitions to quickly check ranges\n    prefix_sum = [0] * (m + 1)\n    for j in range(1, m + 1):\n        prefix_sum[j] = prefix_sum[j - 1] + transitions[j - 1]\n    \n    return prefix_sum\n\ndef is_determinable(prefix_sum, x1, x2):\n    # Check if there is any transition between columns x1 and x2\n    if prefix_sum[x2] - prefix_sum[x1 - 1] > 0:\n        return "NO"\n    else:\n        return "YES"\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    # Read dimensions of the grid\n    n = int(data[0])\n    m = int(data[1])\n    \n    # Read the grid\n    grid = []\n    index = 2\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n    \n    # Precompute transitions\n    prefix_sum = precompute_transitions(grid, n, m)\n    \n    # Read number of queries\n    q = int(data[index])\n    index += 1\n    \n    # Process each query\n    results = []\n    for _ in range(q):\n        x1 = int(data[index])\n        x2 = int(data[index + 1])\n        index += 2\n        \n        result = is_determinable(prefix_sum, x1, x2)\n        results.append(result)\n    \n    # Output results for each query\n    for result in results:\n        print(result)', 'def precompute_transition_points(grid, n, m):\n    transition_points = [0] * m  # Initialize with 0, meaning no transition initially\n\n    for y in range(1, n):\n        for x in range(1, m):\n            if grid[y][x] == \'X\' and grid[y - 1][x - 1] == \'.\':\n                transition_points[x] = 1\n                break\n\n    return transition_points\n\ndef precompute_cumulative_transitions(transition_points, m):\n    cumulative_transitions = [0] * (m + 1)  # Initialize with 0\n\n    for i in range(1, m + 1):\n        cumulative_transitions[i] = cumulative_transitions[i - 1] + transition_points[i - 1]\n\n    return cumulative_transitions\n\ndef is_determinable(cumulative_transitions, x1, x2):\n    if cumulative_transitions[x2] == cumulative_transitions[x1]:\n        return "YES"\n    else:\n        return "NO"\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    m = int(data[1])\n    \n    grid = []\n    index = 2\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n    \n    q = int(data[index])\n    index += 1\n    \n    queries = []\n    for _ in range(q):\n        x1 = int(data[index])\n        x2 = int(data[index + 1])\n        queries.append((x1, x2))\n        index += 2\n    \n    transition_points = precompute_transition_points(grid, n, m)\n    cumulative_transitions = precompute_cumulative_transitions(transition_points, m)\n    \n    results = []\n    for x1, x2 in queries:\n        result = is_determinable(cumulative_transitions, x1 - 1, x2)\n        results.append(result)\n    \n    for result in results:\n        print(result)', 'def preprocess_grid(grid, n, m):\n    # Create a list to store the connectivity information\n    connectivity = [0] * m\n    \n    # Iterate over each row to determine connectivity between columns\n    for i in range(1, n):\n        for j in range(m):\n            if grid[i][j] == \'.\' and grid[i-1][j] == \'.\':\n                connectivity[j] = 1\n    \n    # Create a prefix sum array to quickly check connectivity in subgrids\n    prefix_sum = [0] * (m + 1)\n    for j in range(1, m):\n        prefix_sum[j] = prefix_sum[j-1] + connectivity[j]\n    \n    return prefix_sum\n\ndef is_determinable(prefix_sum, x1, x2):\n    # Check if the subgrid is determinable by checking connectivity\n    if prefix_sum[x2-1] - prefix_sum[x1-1] == 0:\n        return "YES"\n    else:\n        return "NO"\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    # Read grid dimensions\n    n = int(data[0])\n    m = int(data[1])\n    \n    # Read the grid\n    grid = []\n    index = 2\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n    \n    # Preprocess the grid to find connectivity information\n    prefix_sum = preprocess_grid(grid, n, m)\n    \n    # Read number of queries\n    q = int(data[index])\n    index += 1\n    \n    # Process each query\n    results = []\n    for _ in range(q):\n        x1 = int(data[index])\n        x2 = int(data[index+1])\n        index += 2\n        \n        result = is_determinable(prefix_sum, x1, x2)\n        results.append(result)\n    \n    # Output results for each query\n    for result in results:\n        print(result)', 'def preprocess_grid(n, m, grid):\n    # Create a transition array to mark where transitions occur\n    transition = [False] * (m - 1)\n    \n    # Iterate over each row to find transitions between columns\n    for i in range(n):\n        for j in range(m - 1):\n            if grid[i][j] == \'X\' and grid[i][j + 1] == \'.\':\n                transition[j] = True\n    \n    return transition\n\ndef is_determinable(transition, x1, x2):\n    # Check if there is any transition in the range [x1, x2-1]\n    for j in range(x1 - 1, x2 - 1):\n        if transition[j]:\n            return False\n    return True\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    # Read dimensions of the grid\n    index = 0\n    n = int(data[index])\n    m = int(data[index + 1])\n    index += 2\n    \n    # Read the grid\n    grid = []\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n    \n    # Preprocess the grid to find transitions\n    transition = preprocess_grid(n, m, grid)\n    \n    # Read number of queries\n    q = int(data[index])\n    index += 1\n    \n    # Process each query\n    results = []\n    for _ in range(q):\n        x1 = int(data[index])\n        x2 = int(data[index + 1])\n        index += 2\n        \n        if is_determinable(transition, x1, x2):\n            results.append("YES")\n        else:\n            results.append("NO")\n    \n    # Output results for each query\n    for result in results:\n        print(result)', 'def construct_prefix_sum(n, m, grid):\n    # Initialize the prefix sum array\n    prefix_sum = [0] * (m + 1)\n    \n    # Traverse the grid row by row\n    for row in range(1, n):\n        for col in range(1, m):\n            # Check for a transition from filled to empty cell\n            if grid[row][col - 1] == \'X\' and grid[row][col] == \'.\':\n                prefix_sum[col] += 1\n    \n    # Accumulate the prefix sum array\n    for col in range(1, m + 1):\n        prefix_sum[col] += prefix_sum[col - 1]\n    \n    return prefix_sum\n\ndef is_determinable(prefix_sum, x1, x2):\n    # Check if there are any transitions in the range [x1, x2]\n    if prefix_sum[x2] - prefix_sum[x1 - 1] == 0:\n        return "YES"\n    else:\n        return "NO"\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    # Read dimensions of the grid\n    n = int(data[0])\n    m = int(data[1])\n    \n    # Read the grid\n    grid = []\n    index = 2\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n    \n    # Construct the prefix sum array\n    prefix_sum = construct_prefix_sum(n, m, grid)\n    \n    # Read number of queries\n    q = int(data[index])\n    index += 1\n    \n    # Process each query\n    results = []\n    for _ in range(q):\n        x1 = int(data[index])\n        x2 = int(data[index + 1])\n        index += 2\n        \n        result = is_determinable(prefix_sum, x1, x2)\n        results.append(result)\n    \n    # Output results for each query\n    for result in results:\n        print(result)', 'def preprocess_grid(grid, n, m):\n    # Initialize an array to mark non-determinable starts\n    non_determinable_starts = [0] * m\n    \n    # Iterate through each column starting from the second one\n    for col in range(1, m):\n        for row in range(n):\n            # Check for non-determinable patterns\n            if grid[row][col] == \'.\' and grid[row][col - 1] == \'X\':\n                non_determinable_starts[col] = 1\n                break\n            if grid[row][col] == \'X\' and grid[row][col - 1] == \'.\':\n                non_determinable_starts[col] = 1\n                break\n    \n    return non_determinable_starts\n\ndef is_determinable(non_determinable_starts, x1, x2):\n    # Check if there is any non-determinable start between x1 and x2\n    return "NO" if any(non_determinable_starts[x1:x2]) else "YES"\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    # Read dimensions of the grid\n    n = int(data[0])\n    m = int(data[1])\n    \n    # Read the grid\n    grid = []\n    index = 2\n    for _ in range(n):\n        grid.append(data[index])\n        index += 1\n    \n    # Preprocess the grid to find non-determinable starts\n    non_determinable_starts = preprocess_grid(grid, n, m)\n    \n    # Read number of queries\n    q = int(data[index])\n    index += 1\n    \n    # Process each query\n    results = []\n    for _ in range(q):\n        x1 = int(data[index]) - 1  # Convert to 0-based index\n        x2 = int(data[index + 1]) - 1  # Convert to 0-based index\n        index += 2\n        \n        # Determine if the subgrid is determinable\n        result = is_determinable(non_determinable_starts, x1, x2)\n        results.append(result)\n    \n    # Output results for each query\n    for result in results:\n        print(result)']
----------
['- name: \nPrecompute Exitable Cells and Check Vertical Transitions\n\n- content: \n- Precompute a table that indicates whether each cell in the grid is exitable.\n- For each column, track vertical transitions between exitable and non-exitable cells.\n- For each query, check the subgrid for vertical transitions between columns.\n- If a vertical transition from exitable to non-exitable is found within the queried columns, the subgrid is not determinable.\n- Output "YES" if no such transition exists, otherwise output "NO".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'exitable\'\n    Explanation: In the context of the grid, an exitable cell is one from which you can exit the grid by moving up or left through only empty cells. Filled cells (\'X\') are not exitable.\n\n    \'determinable\'\n    Explanation: A grid is determinable if, given only the information about which cells are exitable, you can exactly determine which cells are filled and which are empty.\n\n# [phrase showing quantity relationship]\n    No explicit phrases showing quantity relationships are present in the requirement.\n\n# [degree adverb]\n    No degree adverbs are present in the requirement.\n\n# [code logic]\n    The steps "Precompute a table that indicates whether each cell in the grid is exitable" and "For each column, track vertical transitions between exitable and non-exitable cells" should be implemented simultaneously. This can be done by iterating through the grid once to mark exitable cells and simultaneously noting transitions between exitable and non-exitable states.\n\n# [edge case]\n    1. A grid with all cells empty:\n       Input: \n       ```\n       3 3\n       ...\n       ...\n       ...\n       1\n       1 3\n       ```\n       Expected Output: YES\n       Explanation: All cells are exitable, and there are no transitions from exitable to non-exitable within any subgrid.\n\n    2. A grid with all cells filled:\n       Input:\n       ```\n       3 3\n       XXX\n       XXX\n       XXX\n       1\n       1 3\n       ```\n       Expected Output: NO\n       Explanation: No cells are exitable, making it impossible to determine the grid based on exitability.\n\n    3. A grid with a single column of alternating filled and empty cells:\n       Input:\n       ```\n       4 1\n       .\n       X\n       .\n       X\n       1\n       1 1\n       ```\n       Expected Output: NO\n       Explanation: The alternating pattern creates vertical transitions that make it indeterminable.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where vertical transitions occur.\n    ```python\n    def preprocess_exitable(grid, n, m):\n        exitable = [[False] * m for _ in range(n)]\n        for i in range(n):\n            for j in range(m):\n                if grid[i][j] == \'.\':\n                    if i == 0 or j == 0 or exitable[i-1][j] or exitable[i][j-1]:\n                        exitable[i][j] = True\n        return exitable\n\n    def check_determinable(exitable, x1, x2, n):\n        for j in range(x1, x2):\n            for i in range(1, n):\n                if exitable[i][j] and not exitable[i-1][j]:\n                    return "NO"\n        return "YES"\n\n    # Example usage:\n    # grid = [[\'.\', \'.\', \'X\'], [\'.\', \'.\', \'.\'], [\'.\', \'.\', \'.\']]\n    # exitable = preprocess_exitable(grid, 3, 3)\n    # result = check_determinable(exitable, 0, 2, 3)\n    ```', '- name: \nPrecompute Exitability Transitions\n\n- content: \n1. Precompute a "transition" array for the entire grid. This array will record for each column index where a transition from non-exitable to exitable cells occurs when moving from top to bottom.\n2. Iterate through the grid column by column:\n   - For each column, traverse each cell from top to bottom.\n   - Mark the transition point where the exitability changes due to a filled cell (\'X\').\n3. Use the precomputed transition data to answer each query in constant time:\n   - For a query checking columns x_1 to x_2, ensure there is no transition between x_1 and x_2. If there is no transition, the subgrid is determinable; otherwise, it\'s not.\n4. This approach efficiently processes the input grid once and answers each query in constant time, ensuring scalability.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'exitable\'\n    Explanation: A cell is exitable if you can exit the grid by moving up and left through only empty cells starting from that cell.\n\n    \'determinable\'\n    Explanation: A grid is determinable if, given only which cells are exitable, you can exactly determine which cells are filled and which aren\'t.\n\n# [phrase showing quantity relationship]\n    No phrase showing quantity relationship\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps 1-3 should be implemented simultaneously.\n    "Precompute a \'transition\' array for the entire grid",\n    "Iterate through the grid column by column",\n    "Mark the transition point where the exitability changes due to a filled cell (\'X\')"\n    This can be done by iterating through each column and marking transition points in a single pass.\n\n# [edge case] \n    Edge Case 1: A grid with all cells empty.\n    Input:\n    ```\n    3 3\n    ...\n    ...\n    ...\n    1\n    1 3\n    ```\n    Expected Output: YES\n    Explanation: Since all cells are empty, the subgrid is determinable.\n\n    Edge Case 2: A grid with all cells filled.\n    Input:\n    ```\n    3 3\n    XXX\n    XXX\n    XXX\n    1\n    1 3\n    ```\n    Expected Output: NO\n    Explanation: Since all cells are filled, the subgrid is not determinable.\n\n    Edge Case 3: A grid with alternating filled and empty cells.\n    Input:\n    ```\n    3 3\n    X.X\n    .X.\n    X.X\n    1\n    1 3\n    ```\n    Expected Output: NO\n    Explanation: The alternating pattern makes it impossible to determine the filled and empty cells based solely on exitability.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of precomputing transition points and checking for transitions between columns in queries will handle these cases correctly.', '- name: \nColumn-Based Transition Identification\n\n- content: \nThis approach focuses on identifying transitions between columns that could lead to non-determinable subgrids.\n- Step 1: Initialize an array `non_determinable` of size `m` with all zeros. This array will be used to mark columns where transitions occur that could lead to non-determinability.\n- Step 2: Traverse the grid row by row. For each row, check if there is a filled cell (\'X\') in the column immediately to the right of an empty cell (\'.\'). If such a transition is found, mark the column index in `non_determinable`.\n- Step 3: Precompute prefix sums on `non_determinable` array to quickly answer queries. This will allow us to determine if there are transitions in the queried range.\n- Step 4: For each query `(x_1, x_2)`, check the prefix sum in the range `[x_1, x_2-1]`. If there are any transitions marked, output "NO". Otherwise, output "YES".\n- This solution efficiently handles queries by leveraging precomputation, ensuring that each query is answered in constant time.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'exitable\'\n    Explanation: In the context of the grid, a cell is exitable if you can move up or left through only empty cells to exit the grid. Filled cells (\'X\') are not exitable.\n\n    \'determinable\'\n    Explanation: A grid is determinable if, given only the information about which cells are exitable, you can exactly determine which cells are filled and which are empty.\n\n# [phrase showing quantity relationship]\n    No explicit phrases showing quantity relationships are present in the requirement.\n\n# [degree adverb] \n    No degree adverbs are present in the requirement.\n\n# [code logic]\n    Steps 2 and 3 should be considered simultaneously. \n    - Step 2 involves identifying transitions in each row, which can be done while traversing the grid.\n    - Step 3 involves precomputing prefix sums, which can be integrated into the same loop to optimize performance.\n\n# [edge case] \n    Edge Case 1: A grid with all empty cells.\n    Explanation: Since there are no filled cells, every subgrid is determinable. The expected output for any query would be "YES".\n\n    Edge Case 2: A grid with all filled cells.\n    Explanation: Since there are no exitable cells, every subgrid is determinable. The expected output for any query would be "YES".\n\n    Edge Case 3: A grid with alternating filled and empty cells in a checkerboard pattern.\n    Explanation: This pattern might create non-determinable subgrids due to transitions between filled and empty cells. The expected output would depend on the specific query range.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of marking transitions and using prefix sums will handle these scenarios effectively.', '- name: \nVertical Barrier Detection\n\n- content: \n- Iterate through each column and identify "barrier" rows where a change from filled (\'X\') to empty (\'.\') occurs.\n- Create an array where each element represents if a barrier exists between two consecutive columns.\n- For each query, determine if any barrier exists between the specified column range. If a barrier exists, the subgrid is not determinable; otherwise, it is.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'exitable\'\n    Explanation: A cell is exitable if you can move up or left through only empty cells to exit the grid. Filled cells (\'X\') are not exitable.\n\n    \'determinable\'\n    Explanation: A grid is determinable if, given the exitable cells, you can exactly determine which cells are filled and which are empty.\n\n# [phrase showing quantity relationship]\n    \'1 ≤ q ≤ 2 ⋅ 10^5\'\n    Explanation: The number of queries is between 1 and 200,000 inclusive. This indicates the need for efficient query processing.\n    \n    \'1 ≤ x_1 ≤ x_2 ≤ m\'\n    Explanation: The query specifies a subgrid from column x_1 to x_2, inclusive, within the grid\'s column range.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented in sequence, but the creation of the barrier array and checking for barriers in queries can be optimized to work together. The barrier detection and query checking can be done in a single pass over the grid and queries.\n\n# [edge case]\n    Edge Case 1: A grid with all cells empty.\n    Explanation: Any subgrid is determinable because there are no filled cells to create ambiguity.\n    \n    Edge Case 2: A grid with all cells filled.\n    Explanation: Any subgrid is determinable because there are no exitable cells to create ambiguity.\n    \n    Edge Case 3: A grid with alternating filled and empty cells in a checkerboard pattern.\n    Explanation: Some subgrids may not be determinable due to the alternating pattern creating ambiguous exitable paths.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where the grid is entirely filled or empty, as these are trivial cases that can be checked before processing queries.\n    \n```python\ndef handle_edge_cases(grid, queries):\n    # Check if the grid is entirely empty or filled\n    all_empty = all(cell == \'.\' for row in grid for cell in row)\n    all_filled = all(cell == \'X\' for row in grid for cell in row)\n    \n    if all_empty:\n        return ["YES" for _ in queries]\n    elif all_filled:\n        return ["YES" for _ in queries]\n    \n    # Proceed with normal logic if not an edge case\n    return None\n```\n', '- name: \nSegment Tree for Fast Query\n\n- content: \nUse a segment tree to efficiently determine whether any blocking exists in the queried subgrid columns:\n1. Create a segment tree where each node contains information about whether a blocking exists in its range of columns.\n2. During preprocessing, fill the segment tree using the `block` array derived from examining each column for blocking as described previously.\n3. For each query, use the segment tree to quickly check the range [x_1, x_2] for the presence of blocking columns. If any blocking column is found, respond with "NO"; otherwise, respond with "YES".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'exitable\'\n    Explanation: A cell is exitable if you can exit the grid starting from that cell by moving up and left through only empty cells.\n\n    \'determinable\'\n    Explanation: A grid is determinable if, given only which cells are exitable, you can exactly determine which cells are filled and which aren\'t.\n\n# [phrase showing quantity relationship]\n    No phrase showing quantity relationship\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Create a segment tree where each node contains information about whether a blocking exists in its range of columns.\n    - During preprocessing, fill the segment tree using the `block` array derived from examining each column for blocking.\n    - For each query, use the segment tree to quickly check the range [x_1, x_2] for the presence of blocking columns. If any blocking column is found, respond with "NO"; otherwise, respond with "YES".\n    These steps are interconnected and should be implemented in a cohesive manner to ensure efficient query processing.\n\n# [edge case] \n    Edge Case 1: A grid with all cells empty\n    Input: \n    3 3\n    ...\n    ...\n    ...\n    1\n    1 3\n    Expected Output: YES\n    Explanation: Since all cells are empty, the grid is determinable.\n\n    Edge Case 2: A grid with all cells filled\n    Input: \n    3 3\n    XXX\n    XXX\n    XXX\n    1\n    1 3\n    Expected Output: NO\n    Explanation: Since all cells are filled, the grid is not determinable.\n\n    Edge Case 3: A grid with alternating filled and empty cells\n    Input: \n    3 3\n    X.X\n    .X.\n    X.X\n    1\n    1 3\n    Expected Output: NO\n    Explanation: The alternating pattern makes it impossible to determine the filled and empty cells based solely on exitability.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        # Example code snippet:\n        def preprocess_grid(grid):\n            # Create a block array to identify blocking columns\n            block = [False] * m\n            for col in range(m):\n                for row in range(1, n):\n                    if grid[row][col] == \'X\' and grid[row-1][col] == \'.\':\n                        block[col] = True\n                        break\n            return block\n\n        def query_segment_tree(segment_tree, x1, x2):\n            # Use segment tree to check for blocking columns in range [x1, x2]\n            if any(segment_tree[x1:x2+1]):\n                return "NO"\n            else:\n                return "YES"', '- name: \nPrecompute Exitability Transitions\n\n- content: \n- Precompute an array `exitability_transition` where `exitability_transition[i]` is the minimum row index where there is a filled cell directly above an exitable cell in column `i`.\n- Initialize `exitability_transition[i]` to infinity for all columns.\n- Traverse each column from top to bottom, and for each filled cell `grid[y][x]` at position `(y, x)`, check if there is an exitable cell at position `(y+1, x)`. If so, update `exitability_transition[x]` to be the minimum of its current value and `y`.\n- Precompute cumulative minimums of `exitability_transition`, storing in another array `cumulative_min_exitability[i]` such that it represents the minimum value in `exitability_transition` from column 1 to column `i`.\n- For each query `(x_1, x_2)`, check if `cumulative_min_exitability[x_2] <= cumulative_min_exitability[x_1 - 1]`. If true, output "NO", otherwise output "YES".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'exitable\'\n    Explanation: A cell is considered exitable if you can exit the grid starting from that cell by moving up and left through only empty cells. Filled cells are not exitable.\n\n    \'determinable\'\n    Explanation: A grid is determinable if, given only the information about which cells are exitable, you can exactly determine which cells are filled and which aren\'t.\n\n# [phrase showing quantity relationship]\n    No phrase showing quantity relationship\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented sequentially. However, the logic for checking each query can be implemented simultaneously using an if-else statement:\n    - Precompute the `exitability_transition` array.\n    - Precompute the `cumulative_min_exitability` array.\n    - For each query, check the condition and output "YES" or "NO" accordingly.\n\n# [edge case] \n    Edge Case 1: A grid with all empty cells\n    Input: \n    ```\n    3 3\n    ...\n    ...\n    ...\n    1\n    1 3\n    ```\n    Expected Output: YES\n    Explanation: All cells are exitable, and the grid is determinable because there are no filled cells.\n\n    Edge Case 2: A grid with all filled cells\n    Input: \n    ```\n    3 3\n    XXX\n    XXX\n    XXX\n    1\n    1 3\n    ```\n    Expected Output: NO\n    Explanation: No cells are exitable, and the grid is not determinable because all cells are filled.\n\n    Edge Case 3: A single row grid with alternating filled and empty cells\n    Input: \n    ```\n    1 5\n    X.X.X\n    1\n    1 5\n    ```\n    Expected Output: NO\n    Explanation: The alternating pattern makes it impossible to determine the filled and empty cells based solely on exitability.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of precomputing `exitability_transition` and `cumulative_min_exitability` arrays will handle these cases correctly.', "- name: \nGraph-Based Approach Using Connectivity Components\n- content: \nTreat each row of the grid as a node in a graph where edges exist between nodes that have determinable transitions (i.e., exitable cells) across columns. \nBuild a graph representing this connectivity, then use depth-first search (DFS) or union-find to identify connected components.\nFor each query, check if the specified subgrid columns fall entirely within a single connected component, implying determinability.\nThis approach models the problem as a connectivity issue, allowing efficient preprocessing and quick response to queries.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'exitable'\n    Explanation: In the context of the grid, a cell is exitable if you can move up or left through only empty cells to exit the grid. Filled cells ('X') are not exitable.\n\n    'determinable'\n    Explanation: A grid is determinable if, given only the exitable cells, you can exactly determine which cells are filled and which are empty.\n\n# [phrase showing quantity relationship]\n    No explicit phrases showing quantity relationships are present in the requirement.\n\n# [degree adverb]\n    No degree adverbs are present in the requirement.\n\n# [code logic]\n    The plan suggests using a graph-based approach to model the grid's connectivity. The steps of building a graph and identifying connected components should be implemented simultaneously. This can be done by iterating over the grid to establish connections and then using a graph traversal algorithm like DFS or union-find to identify components.\n\n# [edge case]\n    1. A grid with all cells empty:\n       Input: \n       ```\n       3 3\n       ...\n       ...\n       ...\n       1\n       1 3\n       ```\n       Expected Output: YES\n       Explanation: All cells are exitable, and since there are no filled cells, the grid is trivially determinable.\n\n    2. A grid with all cells filled:\n       Input:\n       ```\n       3 3\n       XXX\n       XXX\n       XXX\n       1\n       1 3\n       ```\n       Expected Output: NO\n       Explanation: No cells are exitable, and without any exitable information, the grid cannot be determined.\n\n    3. A grid with a single row of alternating filled and empty cells:\n       Input:\n       ```\n       1 5\n       X.X.X\n       1\n       1 5\n       ```\n       Expected Output: NO\n       Explanation: The pattern of filled and empty cells cannot be determined solely from exitable information as multiple configurations could result in the same exitable pattern.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where the entire row or column is filled or empty. This can be handled by checking if all cells in a row or column are either filled or empty before processing queries.\n    \n    ```python\n    def preprocess_grid(grid):\n        n = len(grid)\n        m = len(grid[0])\n        # Check for fully filled or empty rows/columns\n        fully_filled_rows = [all(cell == 'X' for cell in row) for row in grid]\n        fully_empty_rows = [all(cell == '.' for cell in row) for row in grid]\n        \n        # Additional logic to handle these cases during query processing\n        return fully_filled_rows, fully_empty_rows\n\n    # Use this preprocessing step before handling queries\n    ```", '- name: \nPreprocessing with Exitability Tracking\n\n- content: \nTo determine if a subgrid is determinable, we can preprocess the grid to track where non-determinability might occur:\n1. Iterate over each column of the grid and mark transitions between filled (\'X\') and empty (\'.\') cells.\n2. Create an array `transition` where `transition[j]` is True if there is a row where the columns `j` and `j+1` have a filled-empty transition across them.\n3. For each query, check if there exists any transition within the queried column range. If there is no transition in the range from `x_1` to `x_2-1`, output "YES". Otherwise, output "NO".\nThis approach ensures efficient query handling by preprocessing in O(n*m) time and answering each query in O(1) time.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'exitable\'\n    Explanation: A cell is considered exitable if you can exit the grid starting from that cell by moving up and left through only empty cells. Filled cells are not exitable.\n\n    \'determinable\'\n    Explanation: A grid is determinable if, given only the information about which cells are exitable, you can exactly determine which cells are filled and which aren\'t.\n\n# [phrase showing quantity relationship]\n    No phrase showing quantity relationship\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The preprocessing steps should be implemented simultaneously:\n    "Iterate over each column of the grid and mark transitions between filled (\'X\') and empty (\'.\') cells",\n    "Create an array `transition` where `transition[j]` is True if there is a row where the columns `j` and `j+1` have a filled-empty transition across them"\n    These steps can be done in a single pass through the grid to efficiently track transitions.\n\n# [edge case] \n    Edge Case 1: A grid with all cells empty.\n    Input:\n    ```\n    3 3\n    ...\n    ...\n    ...\n    1\n    1 3\n    ```\n    Expected Output: YES\n    Explanation: Since all cells are empty, there are no transitions, making the subgrid determinable.\n\n    Edge Case 2: A grid with all cells filled.\n    Input:\n    ```\n    3 3\n    XXX\n    XXX\n    XXX\n    1\n    1 3\n    ```\n    Expected Output: YES\n    Explanation: Since all cells are filled, there are no transitions, making the subgrid determinable.\n\n    Edge Case 3: A grid with alternating filled and empty cells in each row.\n    Input:\n    ```\n    3 3\n    X.X\n    .X.\n    X.X\n    1\n    1 3\n    ```\n    Expected Output: NO\n    Explanation: The alternating pattern creates transitions between filled and empty cells, making the subgrid non-determinable.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The preprocessing logic with transition tracking will naturally handle these scenarios.', '- name: \nUse Prefix Sum Arrays\n\n- content: \n1. Construct a prefix sum array that computes the number of transitions (or potential non-determinable patterns) up to each column.\n2. Traverse the grid row by row to determine when a filled cell is followed by an empty cell across columns, indicating a transition.\n3. Use this information to fill the prefix sum array, where each entry represents the count of transitions up to that column.\n4. For each query `(x1, x2)`, determine if there are any transitions in the range using the prefix sum difference `prefix[x2] - prefix[x1 - 1]`.\n5. If the difference is zero, the subgrid is determinable, output "YES". Otherwise, output "NO".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'exitable\'\n    Explanation: In the requirement, a cell is exitable if you can exit the grid by moving up and left through only empty cells, including the cell itself.\n\n    \'determinable\'\n    Explanation: A grid is determinable if, given only which cells are exitable, we can exactly determine which cells are filled in and which aren\'t.\n\n# [phrase showing quantity relationship]\n    No phrase showing quantity relationship\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 1-3 should be implemented simultaneously as they involve constructing and filling the prefix sum array based on transitions detected in the grid. This can be done in a single traversal of the grid.\n\n# [edge case] \n    Edge Case 1: A grid with all empty cells.\n    Input:\n    ```\n    3 3\n    ...\n    ...\n    ...\n    1\n    1 3\n    ```\n    Expected Output: YES\n    Explanation: Since all cells are empty, there are no transitions, making the subgrid determinable.\n\n    Edge Case 2: A grid with all filled cells.\n    Input:\n    ```\n    3 3\n    XXX\n    XXX\n    XXX\n    1\n    1 3\n    ```\n    Expected Output: NO\n    Explanation: Since all cells are filled, there are no exitable cells, making it impossible to determine the original grid from exitability.\n\n    Edge Case 3: A grid with alternating filled and empty cells.\n    Input:\n    ```\n    3 3\n    X.X\n    .X.\n    X.X\n    1\n    1 3\n    ```\n    Expected Output: NO\n    Explanation: The alternating pattern creates transitions that make it non-determinable.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using prefix sum arrays will handle these cases correctly by checking for transitions in the specified subgrid range.', '- name: \nPreprocessing with Cumulative Array for Quick Query\n\n- content: \n- First, preprocess the grid by creating a cumulative array that marks where non-determinable patterns start.\n- Iterate through each column (starting from the second one) and check if a filled cell in the current column is directly above or below an empty cell in the previous column.\n- Mark this column position as a start of a non-determinable pattern in the cumulative array.\n- For each query, check if there is any marked non-determinable start between the specified columns x_1 and x_2.\n- If there is a mark, the subgrid is not determinable ("NO"), otherwise it is determinable ("YES").\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'exitable\'\n    Explanation: In the context of the grid, a cell is exitable if you can move up or left through only empty cells to exit the grid. Filled cells are not exitable.\n\n    \'determinable\'\n    Explanation: A grid is determinable if, given only the information about which cells are exitable, you can exactly determine which cells are filled and which are empty.\n\n# [phrase showing quantity relationship]\n    \'1 ≤ q ≤ 2 ⋅ 10^5\': This indicates the range of queries that can be processed, meaning the number of queries is between 1 and 200,000.\n    \'1 ≤ n, m ≤ 10^6\': This indicates the range for the dimensions of the grid, meaning both rows and columns can be between 1 and 1,000,000.\n    \'nm ≤ 10^6\': This indicates that the total number of cells in the grid will not exceed 1,000,000.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented in sequence as they build upon each other. However, the check for non-determinable patterns and query processing can be optimized to run efficiently using preprocessed data.\n\n# [edge case]\n    Edge Case 1: A grid with all cells empty.\n    Explanation: Since all cells are empty, every cell is exitable, and the grid is determinable for any subgrid query.\n    \n    Edge Case 2: A grid with all cells filled.\n    Explanation: Since no cell is exitable, the grid is determinable for any subgrid query as all cells are filled.\n    \n    Edge Case 3: A grid with alternating filled and empty cells in a checkerboard pattern.\n    Explanation: This pattern may create non-determinable subgrids depending on the query range due to mixed exitable and non-exitable cells.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases efficiently by preprocessing the grid to quickly determine if a subgrid is determinable.\n    \n```python\ndef preprocess_grid(grid, n, m):\n    non_determinable_starts = [0] * m\n    for col in range(1, m):\n        for row in range(n):\n            if grid[row][col] == \'.\' and grid[row][col - 1] == \'X\':\n                non_determinable_starts[col] = 1\n                break\n            if grid[row][col] == \'X\' and grid[row][col - 1] == \'.\':\n                non_determinable_starts[col] = 1\n                break\n    return non_determinable_starts\n\ndef is_determinable(non_determinable_starts, x1, x2):\n    return "NO" if any(non_determinable_starts[x1:x2]) else "YES"\n```\nThis code preprocesses the grid to mark columns where non-determinable patterns start and uses this information to quickly answer queries.']
----------
False
----------
0
multi-gen-prompt:
Theofanis has a riddle for you and if you manage to solve it, he will give you a Cypriot snack halloumi for free. Halloumi is a delicious Cypriot cheese.

You are given an integer n. You need to find two integers l and r such that -10^{18} ≤ l < r ≤ 10^{18} and l + (l + 1) + … + (r - 1) + r = n.

Input

The first line contains a single integer t (1 ≤ t ≤ 10^4) — the number of test cases.

The first and only line of each test case contains a single integer n (1 ≤ n ≤ 10^{18}).

Output

For each test case, print the two integers l and r such that -10^{18} ≤ l < r ≤ 10^{18} and l + (l + 1) + … + (r - 1) + r = n. 

It can be proven that an answer always exists. If there are multiple answers, print any.

Example

Input


7
1
2
3
6
100
25
3000000000000


Output


0 1
-1 2 
1 2 
1 3 
18 22
-2 7
999999999999 1000000000001

Note

In the first test case, 0 + 1 = 1.

In the second test case, (-1) + 0 + 1 + 2 = 2.

In the fourth test case, 1 + 2 + 3 = 6.

In the fifth test case, 18 + 19 + 20 + 21 + 22 = 100.

In the sixth test case, (-2) + (-1) + 0 + 1 + 2 + 3 + 4 + 5 + 6 + 7 = 25.
multi-gen-prompt:
Theofanis has a riddle for you and if you manage to solve it, he will give you a Cypriot snack halloumi for free (Cypriot cheese). You are given an integer n, and you need to find two integers l and r such that -10^{18} ≤ l < r ≤ 10^{18} and l + (l + 1) + … + (r - 1) + r = n.

Input

The first line contains a single integer t (1 ≤ t ≤ 10^4) — the number of test cases.

The first and only line of each test case contains a single integer n (1 ≤ n ≤ 10^{18}).

Output

For each test case, print the two integers l and r such that -10^{18} ≤ l < r ≤ 10^{18} and l + (l + 1) + … + (r - 1) + r = n. 

It can be proven that an answer always exists. If there are multiple answers, print any.

Example

Input


7
1
2
3
6
100
25
3000000000000


Output


0 1
-1 2 
1 2 
1 3 
18 22
-2 7
999999999999 1000000000001

Note

In the first test case, 0 + 1 = 1.

In the second test case, (-1) + 0 + 1 + 2 = 2.

In the fourth test case, 1 + 2 + 3 = 6.

In the fifth test case, 18 + 19 + 20 + 21 + 22 = 100.

In the sixth test case, (-2) + (-1) + 0 + 1 + 2 + 3 + 4 + 5 + 6 + 7 = 25.
generating with gpt-4o
----------
['def find_l_r(n):\n    # Start with r = 1 and calculate the sum of integers from 1 to r\n    r = 1\n    current_sum = 0\n    \n    # Increment r until the sum is at least n\n    while current_sum < n:\n        current_sum += r\n        r += 1\n    \n    # Calculate the difference between the current sum and n\n    diff = current_sum - n\n    \n    # If diff is zero, l = 0 and r is the correct answer\n    if diff == 0:\n        return 0, r - 1\n    \n    # Otherwise, adjust l to find the correct range\n    l = -diff\n    return l, r - 1\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    results = []\n    \n    for i in range(1, t + 1):\n        n = int(data[i])\n        l, r = find_l_r(n)\n        results.append(f"{l} {r}")\n    \n    print("\\n".join(results))', 'def find_l_r(n):\n    # Use a mathematical approach to find l and r\n    # S = (r * (r + 1) / 2) - (l * (l - 1) / 2) = n\n    # Rearrange to find r given l: r = sqrt(2n + l^2 - l)\n    \n    import math\n    \n    # Start with a reasonable range for l\n    l = -int(math.sqrt(2 * n)) - 1\n    \n    while True:\n        # Calculate the sum from l to r using the formula\n        # S = (r * (r + 1) / 2) - (l * (l - 1) / 2)\n        # Rearrange to find r given l: r = sqrt(2n + l^2 - l)\n        \n        # Calculate the discriminant part\n        discriminant = 2 * n + l * (l - 1)\n        \n        if discriminant < 0:\n            l += 1\n            continue\n        \n        # Calculate r using the discriminant\n        r = int(math.sqrt(discriminant))\n        \n        # Check if the calculated sum matches n\n        sum_l_r = (r * (r + 1)) // 2 - (l * (l - 1)) // 2\n        \n        if sum_l_r == n and l < r:\n            return (l, r)\n        \n        # Increment l to try the next possible sequence\n        l += 1\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    results = []\n    \n    for i in range(1, t + 1):\n        n = int(data[i])\n        result = find_l_r(n)\n        if result is not None:\n            l, r = result\n            results.append(f"{l} {r}")\n    \n    for result in results:\n        print(result)', 'def find_l_r(n):\n    # We will use binary search to find the appropriate r\n    left, right = 0, 10**18\n    while left <= right:\n        mid = (left + right) // 2\n        # Calculate the sum from l to mid\n        # We need to find l such that l + (l+1) + ... + mid = n\n        # This is equivalent to finding l such that (mid - l + 1) * (l + mid) / 2 = n\n        # Rearranging gives us: l = (2*n - mid*(mid+1)) / (2*mid + 2)\n        if mid * (mid + 1) // 2 < n:\n            left = mid + 1\n        else:\n            right = mid - 1\n\n    # Now we have a candidate for r, which is `left`\n    r = left\n    # Calculate l using the formula derived above\n    l = (2 * n - r * (r + 1)) // (2 * r + 2)\n\n    return l, r\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    results = []\n    \n    for i in range(1, t + 1):\n        n = int(data[i])\n        l, r = find_l_r(n)\n        results.append(f"{l} {r}")\n    \n    print("\\n".join(results))', 'def find_l_r(n):\n    # We need to find l and r such that the sum of integers from l to r equals n.\n    # The sum of integers from l to r is given by the formula:\n    # S = (r * (r + 1) / 2) - ((l - 1) * l / 2)\n    # Simplifying, we get: S = (r * (r + 1) - l * (l - 1)) / 2 = n\n\n    # Start with a reasonable guess for l based on the value of n\n    if n > 0:\n        l = -n\n    else:\n        l = n\n\n    while True:\n        # Calculate the sum from l to r\n        c = -(2 * n + l * (l - 1))\n        discriminant = 1 - 4 * c\n        \n        if discriminant < 0:\n            l += 1\n            continue\n        \n        sqrt_discriminant = int(discriminant**0.5)\n        \n        if sqrt_discriminant * sqrt_discriminant != discriminant:\n            l += 1\n            continue\n        \n        r = (-1 + sqrt_discriminant) // 2\n        \n        if r > l and (r * (r + 1) // 2) - ((l - 1) * l // 2) == n:\n            return l, r\n        \n        l += 1\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    results = []\n    \n    for i in range(1, t + 1):\n        n = int(data[i])\n        l, r = find_l_r(n)\n        results.append(f"{l} {r}")\n    \n    print("\\n".join(results))', 'import math\n\ndef find_l_r(n):\n    # Use the quadratic formula to find l and r\n    # Sum = (r - l + 1) * (l + r) / 2 = n\n    # Rearrange to find l and r using the quadratic formula\n    # We need to solve the equation: m * (2l + m - 1) / 2 = n\n    # Which simplifies to: m^2 + (2l - 1)m - 2n = 0\n    # Use the quadratic formula: m = (-b ± sqrt(b^2 - 4ac)) / 2a\n    # Here, a = 1, b = (2l - 1), c = -2n\n\n    # We need to find integer solutions for l and r\n    for l in range(-int(math.sqrt(2 * n)), int(math.sqrt(2 * n)) + 1):\n        # Calculate discriminant\n        discriminant = (2 * l - 1)**2 + 8 * n\n        if discriminant < 0:\n            continue\n        \n        sqrt_discriminant = int(math.sqrt(discriminant))\n        if sqrt_discriminant * sqrt_discriminant != discriminant:\n            continue\n        \n        # Calculate potential m values\n        m1 = (- (2 * l - 1) + sqrt_discriminant) // 2\n        m2 = (- (2 * l - 1) - sqrt_discriminant) // 2\n        \n        # Check if m1 is a valid solution\n        if m1 > 0 and m1 * (2 * l + m1 - 1) // 2 == n:\n            return l, l + m1 - 1\n        \n        # Check if m2 is a valid solution\n        if m2 > 0 and m2 * (2 * l + m2 - 1) // 2 == n:\n            return l, l + m2 - 1\n    \n    return None\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    results = []\n    \n    for i in range(1, t + 1):\n        n = int(data[i])\n        l, r = find_l_r(n)\n        results.append(f"{l} {r}")\n    \n    print("\\n".join(results))', 'def find_l_r(n):\n    l = -n + 1\n    r = n\n    return l, r\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    results = []\n    \n    for i in range(1, t + 1):\n        n = int(data[i])\n        l, r = find_l_r(n)\n        results.append(f"{l} {r}")\n    \n    for result in results:\n        print(result)', 'def find_l_r(n):\n    l = 0\n    while True:\n        # Calculate r using the derived formula\n        r = int((2 * n + l * (l - 1))**0.5)\n        # Check if the sum from l to r equals n\n        if (r * (r + 1) // 2) - ((l - 1) * l // 2) == n:\n            return l, r\n        l -= 1\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    results = []\n    \n    for i in range(1, t + 1):\n        n = int(data[i])\n        l, r = find_l_r(n)\n        results.append(f"{l} {r}")\n    \n    for result in results:\n        print(result)', 'def find_consecutive_sequence(n):\n    # Iterate over possible lengths of sequences starting from 2\n    k = 2\n    while True:\n        # Calculate the sum of the first k natural numbers\n        sum_of_first_k_naturals = k * (k - 1) // 2\n        \n        # Check if (n - sum_of_first_k_naturals) is divisible by k\n        if (n - sum_of_first_k_naturals) % k == 0:\n            l = (n - sum_of_first_k_naturals) // k\n            r = l + k - 1\n            \n            # Check if l and r satisfy the constraints\n            if -10**18 <= l < r <= 10**18:\n                return l, r\n        \n        # Increment k to check the next possible sequence length\n        k += 1\n\ndef solve(test_cases):\n    results = []\n    for n in test_cases:\n        l, r = find_consecutive_sequence(n)\n        results.append((l, r))\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    test_cases = [int(data[i]) for i in range(1, t + 1)]\n    \n    results = solve(test_cases)\n    \n    for l, r in results:\n        print(l, r)', 'def find_consecutive_sum(n):\n    # Start with a midpoint m\n    m = n // 2\n    \n    # Try to find l and r around m\n    for length in range(1, 10**6):  # Arbitrary large range to ensure we find a solution\n        # Calculate the sum of the sequence of this length\n        total = length * (2 * m + length - 1) // 2\n        \n        if total == n:\n            l = m\n            r = m + length - 1\n            return l, r\n        \n        # Adjust m to try to find a valid sequence\n        if total < n:\n            m += 1\n        else:\n            m -= 1\n    \n    # Return a special value indicating no valid sequence was found\n    return -1, -1\n\ndef solve(test_cases):\n    results = []\n    for n in test_cases:\n        l, r = find_consecutive_sum(n)\n        results.append((l, r))\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    test_cases = [int(data[i]) for i in range(1, t + 1)]\n    \n    results = solve(test_cases)\n    \n    for l, r in results:\n        if l == -1 and r == -1:\n            print("No solution")\n        else:\n            print(l, r)', 'def find_l_r(n):\n    # Start with l = 0 and iterate upwards to find a valid pair (l, r)\n    l = 0\n    while True:\n        # Calculate r using the formula derived from the sum of arithmetic series\n        # n = (r - l + 1) * (l + r) / 2\n        # Rearranging gives: r = (2n + l^2 - l) / (2 * (l + 1))\n        numerator = 2 * n + l * l - l\n        denominator = 2 * (l + 1)\n        \n        if numerator % denominator == 0:\n            r = numerator // denominator\n            if l < r:\n                return l, r\n        \n        l += 1\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    results = []\n    \n    for i in range(1, t + 1):\n        n = int(data[i])\n        result = find_l_r(n)\n        if result:\n            l, r = result\n            results.append(f"{l} {r}")\n    \n    print("\\n".join(results))']
----------
['- name: \nBrute Force Search with Constraints\n\n- content: \nGiven the constraints, we can attempt to find integers l and r using a brute force search with careful range selection:\n\n1. Loop through possible values of l from a small number (possibly negative) up to a value where sum could exceed n.\n2. For each l, compute the sum starting from l and incrementally add consecutive integers until the sum either matches or exceeds n.\n3. If the sum matches n, store the corresponding r value.\n4. If multiple solutions exist (multiple r for the same l), select any valid pair.\n5. This approach relies on guaranteed existence of a solution and exploits brute force within feasible range limits.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'integer n\'\n    Explanation: The integer n is the target sum that needs to be achieved by finding two integers l and r such that their consecutive sum equals n.\n\n    \'two integers l and r\'\n    Explanation: These are the two integers that need to be found such that their consecutive sum equals the given integer n.\n\n# [phrase showing quantity relationship]\n    \'≤\': means less than or equal to, used in constraints for l and r.\n    \'≥\': means greater than or equal to, used in constraints for l and r.\n    \'l < r\': means l is strictly less than r, which is a condition for the solution.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps 2 and 3 should be implemented simultaneously:\n    "For each l, compute the sum starting from l and incrementally add consecutive integers until the sum either matches or exceeds n."\n    "If the sum matches n, store the corresponding r value."\n    This can be done by writing a loop that starts from l, adds consecutive integers, and checks if the sum equals n.\n\n# [edge case] \n    Test case with n = 1: 0 1\n    Explanation: The smallest possible sum is achieved with l = 0 and r = 1, where 0 + 1 = 1.\n\n    Test case with n = 10^18: -10^9 10^9\n    Explanation: A large range of numbers can be used to achieve this sum, ensuring the constraints are met.\n\n    Test case with n = 2: -1 2\n    Explanation: The sum (-1) + 0 + 1 + 2 = 2 satisfies the condition.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The brute force approach inherently handles all possible values within the constraints.', "- name: \nMiddle-Out Approach\n\n- content: \nAnother approach is to start from a middle integer and expand outwards to find the sequence whose sum equals n:\n1. Start with an integer m such that m*(m+1)/2 >= n, as it gives a sequence with enough numbers to potentially reach n.\n2. Calculate the potential center of sequence and adjust leftwards and rightwards until the sum matches n.\n3. Use binary search or systematic trial from the middle integer m to find suitable l and r.\n4. Ensure bounds are maintained and verify if the sum matches n.\n5. Return any valid pair of (l, r).\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'integer n'\n    Explanation: The integer n is the target sum that needs to be achieved by finding two integers l and r such that the sum of all integers from l to r equals n.\n\n    'two integers l and r'\n    Explanation: These are the two integers that define the range of numbers whose sum should equal n. The condition -10^{18} ≤ l < r ≤ 10^{18} must be satisfied.\n\n# [phrase showing quantity relationship]\n    '≤': This indicates that l and r must be within the bounds of -10^{18} and 10^{18}.\n    'l < r': This means that l must be strictly less than r.\n    'l + (l + 1) + … + (r - 1) + r = n': This is the sum of an arithmetic sequence from l to r, which must equal n. In code, this can be implemented by iterating from l to r and summing the values.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be considered simultaneously. Calculating the potential center of the sequence and adjusting leftwards and rightwards until the sum matches n can be done in a loop or using a binary search approach to efficiently find the correct l and r.\n\n# [edge case]\n    Case 1: n = 1\n    Expected output: 0 1\n    Explanation: The smallest possible sum that equals 1 is achieved by the sequence 0 + 1.\n\n    Case 2: n = 10^{18}\n    Expected output: A valid pair (l, r) such that their sum equals 10^{18}.\n    Explanation: The sequence should be carefully chosen to ensure it sums up to this large number while respecting the bounds.\n\n    Case 3: n = 2\n    Expected output: -1 2\n    Explanation: The sequence (-1) + 0 + 1 + 2 equals 2, which satisfies the condition.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n    Specifically, we need to ensure that the chosen l and r respect the bounds and that the sum calculation is efficient for large values of n.\n    \n```python\ndef find_l_r(n):\n    # Start with a middle point m\n    m = int((2 * n) ** 0.5)\n    \n    # Adjust m to find suitable l and r\n    for m in range(m, -m, -1):\n        total = m * (m + 1) // 2\n        if total == n:\n            return (0, m)\n        elif total > n:\n            continue\n        else:\n            # Calculate l and r based on m\n            l = m - (total - n)\n            if -10**18 <= l < m <= 10**18:\n                return (l, m)\n    \n    # If no valid pair found, return a default or error\n    return None\n\n# Example usage for edge cases\nprint(find_l_r(1))   # Output: (0, 1)\nprint(find_l_r(2))   # Output: (-1, 2)\nprint(find_l_r(10**18)) # Output: A valid pair (l, r)\n```", "- name: \nIterative Brute Force Search\n\n- content: \nDirectly iterate over possible values for l and calculate corresponding r based on the desired sum.\nSteps:\n1. Initialize l to a reasonable starting point, such as 0 or a small negative number.\n2. Use a loop to increment r starting from l+1 and calculate the sum of integers from l to r.\n3. Check if the sum equals n, if so, output (l, r).\n4. If not, adjust l and r accordingly to find the next potential solution.\n5. This approach may not be efficient for large values but is guaranteed to find a solution within given constraints.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'integer n'\n    Explanation: The integer n is the target sum that needs to be achieved by finding two integers l and r such that the sum of all integers from l to r equals n.\n\n    'l and r'\n    Explanation: These are the two integers that need to be found such that their sum, including all integers between them, equals the given integer n.\n\n# [phrase showing quantity relationship]\n    '-10^{18} ≤ l < r ≤ 10^{18}': This indicates the range within which l and r must fall. It means l must be less than r, and both must be within the specified bounds.\n    \n    'l + (l + 1) + … + (r - 1) + r = n': This represents the sum of a sequence of consecutive integers starting from l and ending at r, which must equal n.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be implemented simultaneously. You need to increment r starting from l+1 and calculate the sum of integers from l to r in a loop, checking if the sum equals n. This can be done using a single loop where you adjust r and calculate the sum until it matches n.\n\n# [edge case] \n    Test case with n = 1: 0 1\n    Explanation: The smallest possible sum is achieved with l = 0 and r = 1, where 0 + 1 = 1.\n\n    Test case with n = 2: -1 2\n    Explanation: The sum is achieved with l = -1 and r = 2, where (-1) + 0 + 1 + 2 = 2.\n\n    Test case with n = 10^{18}: -10^{18} -10^{18}+1\n    Explanation: The sum is achieved with l = -10^{18} and r = -10^{18}+1, where -10^{18} + (-10^{18}+1) = n.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases efficiently.\n        def find_l_r(n):\n            for l in range(-10**18, 10**18):\n                r = l\n                current_sum = 0\n                while current_sum < n and r <= 10**18:\n                    current_sum += r\n                    if current_sum == n:\n                        return l, r\n                    r += 1\n            return None\n\n        (other code)", "- name: \nMathematical Approach Using Arithmetic Series Formula\n\n- content: \n- The sum of integers from l to r is given by the arithmetic series formula: S = (r - l + 1) * (l + r) / 2.\n- Our task is to find two integers l and r such that the above formula equals n.\n- A simple way to ensure this is to fix a small value for the number of terms in the series, say k, and calculate l and r.\n- Choose k as 2 or 3 for simplicity:\n  1. For k = 2, set l = n // 2 and r = l + 1. Check if the sum matches n.\n  2. For k = 3, set l = n // 3 and r = l + 2. Check if the sum matches n.\n- Adjust l and r slightly if necessary to match exactly n.\n- This approach ensures that we can find l and r efficiently due to the guaranteed existence of a solution.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'arithmetic series'\n    Explanation: The requirement involves finding two integers l and r such that the sum of integers from l to r equals n. This is a classic problem involving arithmetic series, where the sum of consecutive integers can be calculated using the formula S = (r - l + 1) * (l + r) / 2.\n\n# [phrase showing quantity relationship]\n    '≤': indicates that l and r must be within the specified range, -10^{18} ≤ l < r ≤ 10^{18}.\n    'l + (l + 1) + … + (r - 1) + r = n': indicates that the sum of integers from l to r must equal n.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps involving choosing k as 2 or 3 and calculating l and r should be considered simultaneously. This involves setting l and r based on the chosen k and checking if the sum matches n in one code block.\n\n# [edge case] \n    For n = 1, l = 0, r = 1\n    Explanation: The sum 0 + 1 equals 1, which matches n.\n    \n    For n = 2, l = -1, r = 2\n    Explanation: The sum (-1) + 0 + 1 + 2 equals 2, which matches n.\n    \n    For n = 10^{18}, l = 499999999999999999, r = 500000000000000001\n    Explanation: The sum of these two numbers equals 10^{18}, which matches n.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of choosing k and adjusting l and r ensures that a solution always exists due to the guaranteed existence of a solution.", '- name: \nTwo-Pointer Approach\n\n- content: \nUse a two-pointer approach to find l and r such that their sum equals n. This method is based on attempting to expand or contract the range until the sum equals n, leveraging the properties of consecutive integers.\n- Step 1: Start with l = 0 and r = 1, and calculate the sum of numbers in this range.\n- Step 2: Use two pointers to adjust the range:\n  - If the current sum is less than n, move the right pointer to expand the range.\n  - If the current sum is greater than n, move the left pointer to contract the range.\n- Step 3: Repeat step 2 until the sum equals n.\n- Step 4: Output l and r for each test case once the sum equals n.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'two integers l and r\'\n    Explanation: The requirement is to find two integers such that their sum of consecutive numbers equals n.\n\n    \'sum of consecutive integers\'\n    Explanation: This involves finding a sequence of numbers starting from l to r whose sum equals the given integer n.\n\n# [phrase showing quantity relationship]\n    \'≤\': means less than or equal to, used to define the range for l and r.\n    \'≥\': means greater than or equal to, used to define the range for l and r.\n    \'l < r\': means l is strictly less than r, ensuring the sequence has at least two numbers.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps 2 and 3 should be implemented simultaneously.\n    "Use two pointers to adjust the range" and "Repeat step 2 until the sum equals n" can be done in a loop where the pointers are adjusted based on the current sum compared to n.\n\n# [edge case] \n    n = 1 -> 0 1\n    Explanation: The smallest possible sum of consecutive integers that equals 1 is 0 + 1.\n    \n    n = 10^18 -> 999999999999999999 1000000000000000000\n    Explanation: The largest possible sum within the given constraints, where l and r are close to the upper limit.\n    \n    n = 2 -> -1 2\n    Explanation: The sum of consecutive integers from -1 to 2 equals 2.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The two-pointer approach inherently handles these cases by adjusting the pointers until the sum matches n.', "- name: \nTwo-Pointer Approach with Incremental Search\n\n- content: \nThis solution uses a two-pointer technique to incrementally find the sequence of numbers summing to n:\n- Initialize pointers l and r starting from a small range, e.g., l = 0, r = 1.\n- Compute the sum of integers from l to r, adjusting l and r incrementally based on whether the sum is less than or greater than n.\n- If the sum is less than n, increase r to include more numbers; if greater, increase l to reduce the sum.\n- Continue adjusting until the sum equals n.\n- Print values of l and r for each test case once the condition is satisfied.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'integer n'\n    Explanation: The integer n is the target sum that needs to be achieved by finding two integers l and r such that the sum of all integers from l to r equals n.\n\n    'two integers l and r'\n    Explanation: These are the boundaries of the sequence of consecutive integers whose sum should equal the given integer n.\n\n# [phrase showing quantity relationship]\n    '≤ l < r ≤'\n    Explanation: This indicates the range within which l and r must fall, with l being less than r, and both being within the specified limits of -10^{18} and 10^{18}. In code, this can be implemented using conditional checks to ensure l and r satisfy these constraints.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps of adjusting l and r based on the sum should be implemented simultaneously. This involves:\n    - Calculating the sum from l to r.\n    - Adjusting l and r in a loop until the sum equals n.\n    This can be done using a while loop where both pointers are adjusted based on the current sum compared to n.\n\n# [edge case]\n    Test case: n = 1\n    Expected output: 0 1\n    Explanation: The smallest sequence that sums to 1 is 0 + 1.\n\n    Test case: n = 10^{18}\n    Expected output: A valid pair (l, r) such that their sum equals 10^{18}, e.g., (499999999999999999, 500000000000000001)\n    Explanation: The sequence from l to r should sum up to 10^{18}.\n\n    Test case: n = 2\n    Expected output: -1 2\n    Explanation: The sequence (-1) + 0 + 1 + 2 sums to 2.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The logic of incrementally adjusting l and r will naturally handle these cases as long as the constraints are checked within the loop.", "- name: \nBinary Search on `r`\n\n- content: \nUse binary search to efficiently find `r` for a given `l` such that the sum equals `n`:\n1. Fix a starting point `l`, initially at or near zero, and calculate the minimum possible `r` using the sum formula.\n2. Use binary search on possible values of `r`, starting from `l + 1` to a maximum feasible value based on constraints.\n3. In each iteration, calculate the sum of integers from `l` to mid-point `r`.\n4. Adjust `l` and repeat until the sum matches `n`.\nThis approach reduces the number of calculations significantly compared to brute force by narrowing down potential `r` values efficiently.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'integer n'\n    Explanation: The integer n is the target sum that needs to be achieved by finding two integers l and r such that the sum of all integers from l to r equals n.\n\n    'two integers l and r'\n    Explanation: These are the two integers that define the range of numbers whose sum should equal the given integer n.\n\n# [phrase showing quantity relationship]\n    '-10^{18} ≤ l < r ≤ 10^{18}': This indicates the range within which the integers l and r must lie. It sets the boundary conditions for the values of l and r.\n    'l + (l + 1) + … + (r - 1) + r = n': This is the sum formula that needs to be satisfied. It means that the sum of all integers from l to r should equal n.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously in a loop or recursive function. Specifically, steps 2-4 can be combined into a single binary search function that iteratively adjusts l and r until the sum matches n.\n\n# [edge case] \n    Test case with n = 1: 0 1\n    Explanation: The smallest possible sum is achieved with l = 0 and r = 1, where 0 + 1 = 1.\n\n    Test case with n = 10^{18}: -10^{18} -10^{18}+1\n    Explanation: The largest possible sum within constraints is achieved with l = -10^{18} and r = -10^{18}+1, where -10^{18} + (-10^{18}+1) = 10^{18}.\n\n    Test case with n = 2: -1 2\n    Explanation: The sum is achieved with l = -1 and r = 2, where (-1) + 0 + 1 + 2 = 2.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        def find_l_r(n):\n            # Initialize l and r\n            l = -10**18\n            r = l + 1\n            \n            # Binary search logic to find correct l and r\n            while True:\n                current_sum = sum(range(l, r+1))\n                if current_sum == n:\n                    return l, r\n                elif current_sum < n:\n                    r += 1\n                else:\n                    l += 1\n\n        # Example usage for edge cases\n        print(find_l_r(1)) # Output: (0, 1)\n        print(find_l_r(10**18)) # Output: (-10**18, -10**18+1)\n        print(find_l_r(2)) # Output: (-1, 2)", "- name: \nMathematical Derivation\n\n- content: \nUtilize the arithmetic series sum formula S = (r-l+1)*(l+r)/2 = n to derive a relationship between l and r. This can be manipulated into a quadratic form where solving for potential integer values of l and r becomes feasible. You may need to use properties of numbers to quickly narrow down a valid pair (l, r) without iterating unnecessarily. Check specific cases where n can be expressed as sums of small sequences directly.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'arithmetic series'\n    Explanation: The requirement involves finding two integers l and r such that the sum of the arithmetic series from l to r equals n. This is a classic problem involving arithmetic progression where the sum of consecutive integers is calculated.\n\n# [phrase showing quantity relationship]\n    '≤': indicates that l and r must be within the specified range, -10^{18} ≤ l < r ≤ 10^{18}.\n    'l + (l + 1) + … + (r - 1) + r = n': indicates that the sum of integers from l to r must equal n. This can be implemented using the formula for the sum of an arithmetic series: S = (r-l+1)*(l+r)/2 = n.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The plan suggests using mathematical derivation to find l and r. The steps should be implemented simultaneously as they involve deriving a relationship between l and r using the arithmetic series formula. This can be done in one code block where the quadratic equation derived from the formula is solved to find potential values of l and r.\n\n# [edge case] \n    For n = 1, a possible pair is (0, 1) because 0 + 1 = 1.\n    For n = 2, a possible pair is (-1, 2) because (-1) + 0 + 1 + 2 = 2.\n    For n = 3, a possible pair is (1, 2) because 1 + 2 = 3.\n    Explanation: These edge cases demonstrate small values of n where the sum can be easily verified by manually adding consecutive integers.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using the arithmetic series formula should be sufficient to find valid pairs (l, r) for any given n within the specified range.", '- name: \nTwo-Pointer Search Approach\n\n- content: \nUse a two-pointer technique to explore potential values for l and r such that their sum equals n. This method involves iteratively adjusting the pointers based on the sum of integers from l to r.\n\nSteps:\n1. Initialize two pointers, l and r, starting from a reasonable point, say l = -10^{9} and r = -10^{9} + 1.\n2. Calculate the sum from l to r using the formula (r-l+1)*(l+r)/2.\n3. If the sum is less than n, increment r to increase the sum.\n4. If the sum is greater than n, increment l to decrease the sum.\n5. Repeat until a valid pair (l, r) is found such that their sum equals n.\n6. Ensure constraints -10^{18} ≤ l < r ≤ 10^{18} are satisfied.\n7. Print the pair (l, r) for each test case.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'two integers l and r\'\n    Explanation: The task is to find two integers, l and r, such that the sum of all integers from l to r equals n.\n\n    \'sum of integers\'\n    Explanation: The sum of integers from l to r is calculated using the formula (r-l+1)*(l+r)/2, which represents the sum of an arithmetic series.\n\n# [phrase showing quantity relationship]\n    \'less than\': l < r means that l should be strictly less than r.\n    \n    \'equals\': l + (l + 1) + … + (r - 1) + r = n means the sum of integers from l to r should be exactly equal to n.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 3 and 4 should be considered simultaneously. \n    "If the sum is less than n, increment r to increase the sum."\n    "If the sum is greater than n, increment l to decrease the sum."\n    These steps can be implemented in a loop where you adjust l and r based on the current sum compared to n.\n\n# [edge case] \n    Case 1: n = 1\n    Output: 0 1\n    Explanation: The smallest possible sum that equals 1 is achieved with l = 0 and r = 1.\n\n    Case 2: n = 10^18\n    Output: A possible output could be a large range such as 0 to a large number close to 10^18.\n    Explanation: The sum needs to be exactly 10^18, which requires careful selection of l and r within constraints.\n\n    Case 3: n = 2\n    Output: -1 2\n    Explanation: The sum (-1) + 0 + 1 + 2 equals 2, satisfying the condition.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The logic of adjusting l and r based on the sum will naturally handle these cases as long as constraints are respected.', "- name: \nDynamic Programming Approach to Build Sum\n\n- content: \nUse a dynamic programming approach to build sums incrementally and determine ranges that satisfy the condition.\nSteps:\n1. Initialize a dynamic programming table that tracks achievable sums using increments.\n2. Start from a base case (e.g., sum equals zero) and incrementally add integers to build the sum up to n.\n3. Track the range (l, r) where the sum equals n using table updates.\n4. Output the first valid range found in the table that satisfies the condition l + (l + 1) + … + (r - 1) + r = n.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'integer n'\n    Explanation: The integer n is the target sum that needs to be achieved by finding two integers l and r such that the sum of all integers from l to r equals n.\n\n# [phrase showing quantity relationship]\n    '-10^{18} ≤ l < r ≤ 10^{18}': This indicates the range within which the integers l and r must fall. It sets the boundary conditions for the values of l and r.\n    'l + (l + 1) + … + (r - 1) + r = n': This describes the sum of consecutive integers from l to r that must equal n. In code, this can be implemented using a loop or formula to calculate the sum of a sequence.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously as they are part of a dynamic programming approach. Specifically, steps 2 and 3 should be integrated into a loop that updates the dynamic programming table and tracks the range (l, r) as the sum is built incrementally.\n\n# [edge case]\n    n = 1 = 0 1\n    Explanation: The smallest possible sum is achieved with l = 0 and r = 1, where 0 + 1 = 1.\n    \n    n = 10^{18} = -10^{18} 10^{18}\n    Explanation: The largest possible sum within the given constraints can be achieved with l = -10^{18} and r = 10^{18}, where the sum of all integers from -10^{18} to 10^{18} equals n.\n    \n    n = 2 = -1 2\n    Explanation: A small sum can be achieved with l = -1 and r = 2, where (-1) + 0 + 1 + 2 = 2.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling edge cases)\n        # Example code snippet:\n        def find_range(n):\n            # Initialize variables\n            l, r = -10**18, -10**18\n            current_sum = 0\n            \n            # Iterate to find valid range\n            while current_sum < n:\n                current_sum += r\n                if current_sum == n:\n                    return l, r\n                r += 1\n            \n            # Adjust l if needed\n            while current_sum > n:\n                current_sum -= l\n                l += 1\n            \n            return l, r"]
----------
True
----------
2
multi-gen-prompt:
You are given array a_1, a_2, …, a_n, consisting of non-negative integers.

Let's define operation of "elimination" with integer parameter k (1 ≤ k ≤ n) as follows:

  * Choose k distinct array indices 1 ≤ i_1 < i_2 < … < i_k ≤ n. 
  * Calculate x = a_{i_1} ~ \& ~ a_{i_2} ~ \& ~ … ~ \& ~ a_{i_k}, where \& denotes the [bitwise AND operation](https://en.wikipedia.org/wiki/Bitwise_operation#AND). There is a notes section that contains formal definition. 
  * Subtract x from each of a_{i_1}, a_{i_2}, …, a_{i_k}; all other elements remain untouched. 

Find all possible values of k, such that it's possible to make all elements of array a equal to 0 using a finite number of elimination operations with parameter k. It can be proven that exists at least one possible k for any array a.

Note that you firstly choose k and only after that perform elimination operations with value k you've chosen initially.

Input

Each test contains multiple test cases. The first line contains the number of test cases t (1 ≤ t ≤ 10^4). Description of the test cases follows.

The first line of each test case contains one integer n (1 ≤ n ≤ 200 000) — the length of array a.

The second line of each test case contains n integers a_1, a_2, …, a_n (0 ≤ a_i < 2^{30}) — array a itself.

It's guaranteed that the sum of n over all test cases doesn't exceed 200 000.

Output

For each test case, print all values k, such that it's possible to make all elements of a equal to 0 in a finite number of elimination operations with the given parameter k.

Print them in increasing order.

Example

Input


5
4
4 4 4 4
4
13 7 25 19
6
3 5 3 1 7 1
1
1
5
0 0 0 0 0


Output


1 2 4
1 2
1
1
1 2 3 4 5

Note

In the first test case:

  * If k = 1, we can make four elimination operations with sets of indices \{1\}, \{2\}, \{3\}, \{4\}. Since \& of one element is equal to the element itself, then for each operation x = a_i, so a_i - x = a_i - a_i = 0. 
  * If k = 2, we can make two elimination operations with, for example, sets of indices \{1, 3\} and \{2, 4\}: x = a_1 ~ \& ~ a_3 = a_2 ~ \& ~ a_4 = 4 ~ \& ~ 4 = 4. For both operations x = 4, so after the first operation a_1 - x = 0 and a_3 - x = 0, and after the second operation — a_2 - x = 0 and a_4 - x = 0. 
  * If k = 3, it's impossible to make all a_i equal to 0. After performing the first operation, we'll get three elements equal to 0 and one equal to 4. After that, all elimination operations won't change anything, since at least one chosen element will always be equal to 0. 
  * If k = 4, we can make one operation with set \{1, 2, 3, 4\}, because x = a_1 ~ \& ~ a_2 ~ \& ~ a_3 ~ \& ~ a_4 = 4. 



In the second test case, if k = 2 then we can make the following elimination operations:

  * Operation with indices \{1, 3\}: x = a_1 ~ \& ~ a_3 = 13 ~ \& ~ 25 = 9. a_1 - x = 13 - 9 = 4 and a_3 - x = 25 - 9 = 16. Array a will become equal to [4, 7, 16, 19]. 
  * Operation with indices \{3, 4\}: x = a_3 ~ \& ~ a_4 = 16 ~ \& ~ 19 = 16. a_3 - x = 16 - 16 = 0 and a_4 - x = 19 - 16 = 3. Array a will become equal to [4, 7, 0, 3]. 
  * Operation with indices \{2, 4\}: x = a_2 ~ \& ~ a_4 = 7 ~ \& ~ 3 = 3. a_2 - x = 7 - 3 = 4 and a_4 - x = 3 - 3 = 0. Array a will become equal to [4, 4, 0, 0]. 
  * Operation with indices \{1, 2\}: x = a_1 ~ \& ~ a_2 = 4 ~ \& ~ 4 = 4. a_1 - x = 4 - 4 = 0 and a_2 - x = 4 - 4 = 0. Array a will become equal to [0, 0, 0, 0]. 



Formal definition of bitwise AND:

Let's define bitwise AND (\&) as follows. Suppose we have two non-negative integers x and y, let's look at their binary representations (possibly, with leading zeroes): x_k ... x_2 x_1 x_0 and y_k ... y_2 y_1 y_0. Here, x_i is the i-th bit of number x, and y_i is the i-th bit of number y. Let r = x ~ \& ~ y is a result of operation \& on number x and y. Then binary representation of r will be r_k ... r_2 r_1 r_0, where:

$$$ r_i = \begin{cases} 1, ~ if ~ x_i = 1 ~ and ~ y_i = 1 \\\ 0, ~ if ~ x_i = 0 ~ or ~ y_i = 0 \end{cases} $$$
multi-gen-prompt:
You are given array a_1, a_2, …, a_n, consisting of non-negative integers.

Let's define operation of "elimination" with integer parameter k (1 ≤ k ≤ n) as follows: choose k distinct array indices 1 ≤ i_1 < i_2 < … < i_k ≤ n and calculate x = a_{i_1} ~ \& ~ a_{i_2} ~ \& ~ … ~ \& ~ a_{i_k}, where \& denotes the [bitwise AND operation](https://en.wikipedia.org/wiki/Bitwise_operation#AND) (notes section contains formal definition), then subtract x from each of a_{i_1}, a_{i_2}, …, a_{i_k}; all other elements remain untouched.

Find all possible values of k, such that it's possible to make all elements of array a equal to 0 using a finite number of elimination operations with parameter k. It can be proven that exists at least one possible k for any array a.

Note that you firstly choose k and only after that perform elimination operations with value k you've chosen initially.

Input

Each test contains multiple test cases. The first line contains the number of test cases t (1 ≤ t ≤ 10^4). Description of the test cases follows.

The first line of each test case contains one integer n (1 ≤ n ≤ 200 000) — the length of array a.

The second line of each test case contains n integers a_1, a_2, …, a_n (0 ≤ a_i < 2^{30}) — array a itself.

It's guaranteed that the sum of n over all test cases doesn't exceed 200 000.

Output

For each test case, print all values k, such that it's possible to make all elements of a equal to 0 in a finite number of elimination operations with the given parameter k.

Print them in increasing order.

Example

Input


5
4
4 4 4 4
4
13 7 25 19
6
3 5 3 1 7 1
1
1
5
0 0 0 0 0


Output


1 2 4
1 2
1
1
1 2 3 4 5

Note

In the first test case:

  * If k = 1, we can make four elimination operations with sets of indices \{1\}, \{2\}, \{3\}, \{4\}. Since \& of one element is equal to the element itself, then for each operation x = a_i, so a_i - x = a_i - a_i = 0. 
  * If k = 2, we can make two elimination operations with, for example, sets of indices \{1, 3\} and \{2, 4\}: x = a_1 ~ \& ~ a_3 = a_2 ~ \& ~ a_4 = 4 ~ \& ~ 4 = 4. For both operations x = 4, so after the first operation a_1 - x = 0 and a_3 - x = 0, and after the second operation — a_2 - x = 0 and a_4 - x = 0. 
  * If k = 3, it's impossible to make all a_i equal to 0. After performing the first operation, we'll get three elements equal to 0 and one equal to 4. After that, all elimination operations won't change anything, since at least one chosen element will always be equal to 0. 
  * If k = 4, we can make one operation with set \{1, 2, 3, 4\}, because x = a_1 ~ \& ~ a_2 ~ \& ~ a_3 ~ \& ~ a_4 = 4. 



In the second test case, if k = 2 then we can make the following elimination operations:

  * Operation with indices \{1, 3\}: x = a_1 ~ \& ~ a_3 = 13 ~ \& ~ 25 = 9. a_1 - x = 13 - 9 = 4 and a_3 - x = 25 - 9 = 16. Array a will become equal to [4, 7, 16, 19]. 
  * Operation with indices \{3, 4\}: x = a_3 ~ \& ~ a_4 = 16 ~ \& ~ 19 = 16. a_3 - x = 16 - 16 = 0 and a_4 - x = 19 - 16 = 3. Array a will become equal to [4, 7, 0, 3]. 
  * Operation with indices \{2, 4\}: x = a_2 ~ \& ~ a_4 = 7 ~ \& ~ 3 = 3. a_2 - x = 7 - 3 = 4 and a_4 - x = 3 - 3 = 0. Array a will become equal to [4, 4, 0, 0]. 
  * Operation with indices \{1, 2\}: x = a_1 ~ \& ~ a_2 = 4 ~ \& ~ 4 = 4. a_1 - x = 4 - 4 = 0 and a_2 - x = 4 - 4 = 0. Array a will become equal to [0, 0, 0, 0]. 



Formal definition of bitwise AND:

Let's define bitwise AND (\&) as follows. Suppose we have two non-negative integers x and y, let's look at their binary representations (possibly, with leading zeroes): x_k ... x_2 x_1 x_0 and y_k ... y_2 y_1 y_0. Here, x_i is the i-th bit of number x, and y_i is the i-th bit of number y. Let r = x ~ \& ~ y is a result of operation \& on number x and y. Then binary representation of r will be r_k ... r_2 r_1 r_0, where:

$$$ r_i = \begin{cases} 1, ~ if ~ x_i = 1 ~ and ~ y_i = 1 \\\ 0, ~ if ~ x_i = 0 ~ or ~ y_i = 0 \end{cases} $$$
generating with gpt-4o
----------
['def can_make_zero_with_k(a, n, k):\n    # Check if we can make all elements zero with the given k\n    # We need to check if the number of elements with the same bit pattern is a multiple of k\n    # This is because we can only eliminate elements in groups of k\n    bit_count = [0] * 30  # Since a_i < 2^30, we only need to consider 30 bits\n\n    for num in a:\n        for bit in range(30):\n            if num & (1 << bit):\n                bit_count[bit] += 1\n\n    for count in bit_count:\n        if count % k != 0:\n            return False\n\n    return True\n\ndef solve(test_cases):\n    results = []\n    for n, a in test_cases:\n        possible_k = []\n        for k in range(1, n + 1):\n            if can_make_zero_with_k(a, n, k):\n                possible_k.append(k)\n        results.append(possible_k)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, a))\n    \n    results = solve(test_cases)\n    \n    for result in results:\n        print(" ".join(map(str, result)))', 'def can_eliminate_with_k(a, n, k):\n    # Check if we can eliminate all elements with the given k\n    # We need to check if we can partition the array into groups of size k\n    # such that each group can be reduced to zero.\n    \n    # Calculate the total bitwise AND of the entire array\n    total_and = a[0]\n    for num in a[1:]:\n        total_and &= num\n    \n    # If the total AND is zero, we can make all elements zero with any k\n    if total_and == 0:\n        return True\n    \n    # Otherwise, we need to check if we can partition the array into groups of size k\n    # such that each group has a non-zero AND that can be subtracted from all elements in the group\n    current_and = 0\n    count = 0\n    \n    for num in a:\n        current_and &= num\n        count += 1\n        \n        if count == k:\n            if current_and != 0:\n                return False\n            current_and = num\n            count = 1\n    \n    return current_and == 0\n\ndef solve_case(n, a):\n    possible_k = []\n    \n    for k in range(1, n + 1):\n        if can_eliminate_with_k(a, n, k):\n            possible_k.append(k)\n    \n    return possible_k\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = solve_case(n, a)\n        results.append(" ".join(map(str, result)))\n    \n    print("\\n".join(results))', 'def can_make_all_zero(n, a, k):\n    # Check if we can make all elements zero with the given k\n    # Calculate the total bitwise AND of the array\n    total_and = a[0]\n    for num in a[1:]:\n        total_and &= num\n    \n    # If the total AND is zero, we can make all elements zero with any k\n    if total_and == 0:\n        return True\n    \n    # Otherwise, check if we can partition the array into groups of size k\n    # such that each group\'s AND is equal to the total AND\n    count = 0\n    current_and = (1 << 30) - 1  # Start with all bits set\n    for num in a:\n        current_and &= num\n        if current_and == total_and:\n            count += 1\n            current_and = (1 << 30) - 1  # Reset for the next group\n    \n    return count >= k\n\ndef solve(test_cases):\n    results = []\n    for n, a in test_cases:\n        possible_k = []\n        for k in range(1, n + 1):\n            if can_make_all_zero(n, a, k):\n                possible_k.append(k)\n        results.append(possible_k)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, a))\n    \n    results = solve(test_cases)\n    \n    for result in results:\n        print(" ".join(map(str, result)))', 'from itertools import combinations\n\ndef can_zero_out_with_k(n, a, k):\n    # Check if we can zero out the array using elimination operations with parameter k\n    # We need to find a sequence of operations that zero out all elements\n    # For each combination of k indices, calculate the bitwise AND and subtract it from each element\n    # If we can make all elements zero, return True, otherwise False\n    \n    # Create a copy of the array to perform operations\n    a_copy = a[:]\n    \n    # Generate all combinations of k indices\n    for indices in combinations(range(n), k):\n        # Calculate the bitwise AND for the selected indices\n        x = a_copy[indices[0]]\n        for i in indices[1:]:\n            x &= a_copy[i]\n        \n        # Subtract x from each selected element\n        for i in indices:\n            a_copy[i] -= x\n    \n    # Check if all elements are zero\n    return all(value == 0 for value in a_copy)\n\ndef solve(test_cases):\n    results = []\n    for n, a in test_cases:\n        possible_k_values = []\n        for k in range(1, n + 1):\n            if can_zero_out_with_k(n, a, k):\n                possible_k_values.append(k)\n        results.append(possible_k_values)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, a))\n    \n    results = solve(test_cases)\n    \n    for result in results:\n        print(" ".join(map(str, result)))', 'def can_eliminate_with_k(n, a, k):\n    # Check if we can eliminate all elements with the given k\n    if k == 1:\n        # If k is 1, we can always eliminate each element individually\n        return True\n    \n    # Calculate the total AND of all elements\n    total_and = a[0]\n    for i in range(1, n):\n        total_and &= a[i]\n    \n    # If total AND is zero, we can eliminate all elements with k = n\n    if total_and == 0:\n        return True\n    \n    # For k > 1, check if we can form groups of k elements to eliminate\n    # We need to ensure that the total AND of any group of k elements is non-zero\n    # and can be subtracted to make all elements zero eventually.\n    current_and = 0\n    count = 0\n    for num in a:\n        current_and &= num\n        count += 1\n        if count == k:\n            if current_and == 0:\n                return False\n            current_and = num\n            count = 1\n    \n    return True\n\ndef solve(test_cases):\n    results = []\n    for n, a in test_cases:\n        possible_k = []\n        for k in range(1, n + 1):\n            if can_eliminate_with_k(n, a, k):\n                possible_k.append(k)\n        results.append(possible_k)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, a))\n    \n    results = solve(test_cases)\n    \n    for result in results:\n        print(" ".join(map(str, result)))', 'def compute_cumulative_and(a):\n    # Compute the cumulative bitwise AND of the entire array\n    t = a[0]\n    for num in a[1:]:\n        t &= num\n    return t\n\ndef find_divisors(n):\n    # Find all divisors of n\n    divisors = []\n    for k in range(1, n + 1):\n        if n % k == 0:\n            divisors.append(k)\n    return divisors\n\ndef compute_possible_k(n, a):\n    # Calculate the cumulative bitwise AND of the entire array\n    t = compute_cumulative_and(a)\n    \n    # If the cumulative AND is zero, all k are possible\n    if t == 0:\n        return list(range(1, n + 1))\n    \n    # Find all divisors of n\n    divisors = find_divisors(n)\n    \n    # Check each divisor to see if it can partition the array into groups with AND zero\n    possible_k = []\n    for k in divisors:\n        can_zero = True\n        for i in range(0, n, k):\n            group_and = a[i]\n            for j in range(1, k):\n                group_and &= a[i + j]\n            if group_and != 0:\n                can_zero = False\n                break\n        if can_zero:\n            possible_k.append(k)\n    \n    return possible_k\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = compute_possible_k(n, a)\n        results.append(" ".join(map(str, result)))\n    \n    print("\\n".join(results))', 'def handle_edge_cases(a):\n    if all(x == 0 for x in a):\n        return list(range(1, len(a) + 1))\n    return None\n\ndef can_zero_array_with_k(a, k):\n    n = len(a)\n    # Check if we can zero the array with the given k\n    # We need to find subsets of size k that can be zeroed\n    # For simplicity, we check if all elements are the same\n    # If they are, we can zero them with any k that divides n\n    if len(set(a)) == 1:\n        return True\n    return False\n\ndef solve_test_case(n, a):\n    edge_case_result = handle_edge_cases(a)\n    if edge_case_result is not None:\n        return edge_case_result\n    \n    possible_k_values = []\n    for k in range(1, n + 1):\n        if can_zero_array_with_k(a, k):\n            possible_k_values.append(k)\n    \n    return possible_k_values\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = solve_test_case(n, a)\n        results.append(result)\n    \n    for result in results:\n        print(" ".join(map(str, result)))', 'def calculate_total_and(arr):\n    total_and = arr[0]\n    for num in arr[1:]:\n        total_and &= num\n    return total_and\n\ndef find_valid_k_values(n, arr):\n    total_and = calculate_total_and(arr)\n    if total_and == 0:\n        return list(range(1, n + 1))\n    \n    valid_k_values = []\n    prefix_and = [0] * n\n    prefix_and[0] = arr[0]\n    \n    for i in range(1, n):\n        prefix_and[i] = prefix_and[i - 1] & arr[i]\n    \n    for k in range(1, n + 1):\n        found_subarray = False\n        for i in range(k - 1, n):\n            if i == k - 1:\n                subarray_and = prefix_and[i]\n            else:\n                subarray_and = prefix_and[i] & ~prefix_and[i - k]\n            \n            if subarray_and == total_and:\n                found_subarray = True\n                break\n        \n        if found_subarray:\n            valid_k_values.append(k)\n    \n    return valid_k_values\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        arr = list(map(int, data[index:index + n]))\n        index += n\n        \n        valid_k_values = find_valid_k_values(n, arr)\n        results.append(" ".join(map(str, valid_k_values)))\n    \n    print("\\n".join(results))', 'def find_possible_k(n, array):\n    # If all elements are zero, any k from 1 to n is possible\n    if all(x == 0 for x in array):\n        return list(range(1, n + 1))\n    \n    # Count occurrences of each unique element\n    from collections import Counter\n    element_count = Counter(array)\n    \n    # Find the greatest common divisor of the counts\n    from math import gcd\n    from functools import reduce\n    \n    def gcd_of_list(lst):\n        return reduce(gcd, lst)\n    \n    counts = list(element_count.values())\n    gcd_count = gcd_of_list(counts)\n    \n    # All divisors of gcd_count are possible k values\n    possible_k = []\n    for i in range(1, gcd_count + 1):\n        if gcd_count % i == 0:\n            possible_k.append(i)\n    \n    return possible_k\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        array = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = find_possible_k(n, array)\n        results.append(" ".join(map(str, result)))\n    \n    print("\\n".join(results))', 'from itertools import combinations\n\ndef handle_edge_cases(a):\n    if all(x == 0 for x in a):\n        return list(range(1, len(a) + 1))\n    return None\n\ndef can_zero_out_with_k(a, k):\n    n = len(a)\n    # Try all combinations of k indices\n    for indices in combinations(range(n), k):\n        # Calculate the bitwise AND of the selected elements\n        x = a[indices[0]]\n        for i in indices[1:]:\n            x &= a[i]\n        # Check if subtracting x from each selected element results in zero\n        if all(a[i] - x == 0 for i in indices):\n            return True\n    return False\n\ndef find_possible_k_values(a):\n    n = len(a)\n    possible_k_values = []\n    \n    # Check edge case where all elements are zero\n    edge_case_result = handle_edge_cases(a)\n    if edge_case_result is not None:\n        return edge_case_result\n    \n    # Iterate over all possible k values\n    for k in range(1, n + 1):\n        if can_zero_out_with_k(a, k):\n            possible_k_values.append(k)\n    \n    return possible_k_values\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = find_possible_k_values(a)\n        results.append(" ".join(map(str, result)))\n    \n    print("\\n".join(results))']
----------
['- name: \nGreedy Reduction by Bitwise AND\n\n- content: \nThis approach uses a greedy strategy to reduce elements based on their binary representation:\n1. Identify the bits that are set in any element in the array.\n2. Choose indices where these bits overlap and perform elimination operations.\n3. Validate each possible k by simulating operations and checking if all elements become zero.\n4. Repeat the process for each test case, maintaining a list of viable k values.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'elimination\'\n    Explanation: In the context of this problem, "elimination" refers to a process where a subset of elements in the array is selected, and a bitwise AND operation is performed on these elements. The result of this operation is then subtracted from each of the selected elements.\n\n    \'bitwise AND operation\'\n    Explanation: A bitwise AND operation takes two binary numbers and performs the logical AND operation on each pair of corresponding bits. The result is a new binary number where each bit is 1 if both corresponding bits of the operands are 1, otherwise, it is 0.\n\n# [phrase showing quantity relationship]\n    \'1 ≤ k ≤ n\': This indicates that the parameter k, which represents the number of indices to choose for the elimination operation, must be at least 1 and at most equal to the length of the array n.\n    Implementation: This can be implemented by iterating over possible values of k from 1 to n.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 1 and 2 should be considered simultaneously:\n    "Identify the bits that are set in any element in the array" and "Choose indices where these bits overlap and perform elimination operations" can be implemented together by iterating through the array, identifying common set bits, and selecting indices accordingly.\n\n# [edge case]\n    Test case with all elements already zero: \n    Input: [0, 0, 0, 0] \n    Expected output: 1 2 3 4\n    Explanation: Since all elements are already zero, any k from 1 to n is valid.\n\n    Test case with a single element:\n    Input: [1]\n    Expected output: 1\n    Explanation: With only one element, k can only be 1.\n\n    Test case with maximum element values:\n    Input: [1073741823, 1073741823] (where each element is 2^30 - 1)\n    Expected output: 1 2\n    Explanation: Each element can be reduced individually or together since they are identical.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating over possible k values and checking if all elements can be reduced to zero will naturally handle these cases.', '- name: \nIterative Subtraction Strategy\n\n- content: \nUtilize an iterative approach where you try to perform the elimination operation by iteratively checking for possible values of k starting from 1 up to n.\nSteps:\n1. For each k from 1 to n, check if it is possible to eliminate all elements.\n2. For a given k, attempt to perform the elimination operation by grouping elements and checking if they can collectively be reduced to zero using their bitwise AND.\n3. If successful for a particular k, record this value.\n4. Output all successful k values in increasing order.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'elimination\'\n    Explanation: In the context of this problem, "elimination" refers to the process of reducing selected elements of the array to zero by using the bitwise AND operation and subtracting the result from each selected element.\n\n    \'bitwise AND operation\'\n    Explanation: This is a binary operation that takes two equal-length binary representations and performs the logical AND operation on each pair of corresponding bits. The result in each position is 1 if both bits are 1, otherwise, it is 0.\n\n# [phrase showing quantity relationship]\n    \'1 ≤ k ≤ n\'\n    Explanation: This indicates that the value of k, which represents the number of indices chosen for the elimination operation, must be between 1 and n, inclusive. In code, this can be implemented using a loop that iterates over this range.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps 1 and 2 should be considered simultaneously. For each k, you need to check if it\'s possible to eliminate all elements by grouping them and performing the elimination operation. This can be done in a single loop where you attempt the elimination for each k.\n\n# [edge case]\n    Test case: [0, 0, 0, 0] = 1 2 3 4\n    Explanation: Since all elements are already zero, any k from 1 to n will work because no further operations are needed.\n\n    Test case: [1] = 1\n    Explanation: With a single element, k can only be 1, and since the element is non-zero, it can be reduced to zero by itself.\n\n    Test case: [2, 2, 2] = 1 2 3\n    Explanation: Each element can be reduced to zero individually (k=1), in pairs (k=2), or all together (k=3) because they are identical.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating over possible k values and checking if elimination is possible will naturally handle these cases.', '- name: \nBrute Force with Validity Check\n- content: \nThis solution involves testing each possible value of k from 1 to n and checking if it is possible to make all elements zero using elimination operations. \nSteps:\n1. Iterate through possible values of k from 1 to n.\n2. For each k, check if there exists a sequence of elimination operations with k distinct indices that can reduce the array to all zeros.\n3. Use a bitwise AND operation on selected elements and verify if subtracting the result can iteratively reduce all elements to zero.\n4. Track and print all successful k values.\nThis approach is computationally expensive for large arrays, but ensures correctness by exhaustively checking each possibility.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'elimination\'\n    Explanation: In the requirement, "elimination" refers to the process of selecting k distinct indices from the array and performing a bitwise AND operation on the elements at these indices. The result is then subtracted from each of these elements, aiming to reduce them to zero.\n\n    \'bitwise AND operation\'\n    Explanation: This is a binary operation that takes two bit patterns of equal length and performs the logical AND operation on each pair of corresponding bits. The result is a new bit pattern where each bit is 1 if both corresponding bits of the operands are 1, otherwise it is 0.\n\n# [phrase showing quantity relationship]\n    \'1 ≤ k ≤ n\': This indicates that k can be any integer between 1 and n, inclusive. In code, this can be implemented using a loop that iterates over this range.\n    \n# [degree adverb] \n    \'all\': This means every element in the array should be reduced to zero. In code, this can be checked by verifying if all elements in the array are zero after performing the operations.\n\n# [code logic]\n    The steps 2 and 3 should be considered simultaneously. For each k, you need to select indices, perform the bitwise AND operation, and check if subtracting the result can reduce all elements to zero. This involves iterating over possible combinations of indices and applying the operation in one code block.\n\n# [edge case] \n    Test case with all elements already zero: [0, 0, 0] = 1\n    Explanation: Since all elements are already zero, any k from 1 to n will work, but the smallest k is 1.\n\n    Test case with one element: [5] = 1\n    Explanation: With only one element, k must be 1 to perform the operation on itself.\n\n    Test case with maximum possible value: [1073741823, 1073741823] = 1\n    Explanation: The maximum value for elements is 2^30 - 1. With two identical maximum values, k = 1 will work as each element can be reduced individually.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating through possible values of k and checking if all elements can be reduced to zero will naturally handle these cases.', '- name: \nFull Enumeration and Valid Subset Check\n\n- content: \nThis approach involves enumerating possible subsets and checking their validity for zeroing the array.\n1. For each test case, consider all possible values of k from 1 to n.\n2. For each k, enumerate all combinations of k distinct indices.\n3. Compute the bitwise AND for each combination and check if reduction can zero out chosen elements.\n4. Use memoization or caching to track previously successful subsets for faster validation.\n5. Determine if all elements can be reduced to zero using a sequence of operations based on valid subsets.\n6. Output all feasible values of k that allow complete zeroing in finite steps.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'elimination\'\n    Explanation: In the context of this problem, "elimination" refers to the process of selecting a subset of indices from the array, computing the bitwise AND of the elements at those indices, and subtracting the result from each of those elements. The goal is to make all elements of the array zero through a series of such operations.\n\n    \'bitwise AND operation\'\n    Explanation: The bitwise AND operation takes two binary numbers and performs the logical AND operation on each pair of corresponding bits. The result is a binary number where each bit is 1 if both corresponding bits of the operands are 1, otherwise it is 0.\n\n# [phrase showing quantity relationship]\n    \'1 ≤ k ≤ n\': This indicates that k can be any integer between 1 and n, inclusive. In code, this can be implemented using a loop that iterates over this range.\n    \n    \'finite number of elimination operations\': This implies that there is a limited number of operations needed to achieve the goal. In code, this means we need to ensure our algorithm terminates after a certain number of steps.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be considered simultaneously. For each k, we need to enumerate all combinations of k distinct indices and compute the bitwise AND for each combination in one code block. This can be implemented using nested loops or a library function to generate combinations.\n\n# [edge case]\n    Test case: [0, 0, 0, 0] = 1\n    Explanation: Since all elements are already zero, any k will work, but the smallest k is 1.\n\n    Test case: [1] = 1\n    Explanation: With only one element, k must be 1 to perform any operation.\n\n    Test case: [2, 2, 2] = 1 2 3\n    Explanation: All elements are the same and non-zero, so any k from 1 to n can be used to zero out the array.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating over all possible k values and checking combinations will naturally handle these cases.', '- name: \nEfficient Bitwise AND Operations\n\n- content: \nWe can exploit the properties of the bitwise AND operation to solve the problem efficiently.\n1. Calculate the global bitwise AND result of the entire array. This result will be zero only when all elements are zero.\n2. For each test case:\n   - Check if all elements are zero initially, then the only possible k is 1 (as no operations are needed).\n   - Compute the AND for pairs of elements, triples, and so on, up to n elements.\n   - If the computed AND is non-zero, it indicates the presence of a bit shared by all elements in the chosen set, which can be eliminated.\n3. Generate possible k values by evaluating subsets of elements whose AND results are non-zero.\n4. Output the possible k values in increasing order.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'elimination\'\n    Explanation: In the context of this problem, "elimination" refers to the process of reducing selected elements of the array to zero by performing a bitwise AND operation on them and subtracting the result from each selected element.\n\n    \'bitwise AND operation\'\n    Explanation: A bitwise AND operation takes two binary numbers and performs the logical AND operation on each pair of corresponding bits. The result is a binary number where each bit is 1 if both corresponding bits of the operands are 1, otherwise it is 0.\n\n# [phrase showing quantity relationship]\n    \'1 ≤ k ≤ n\'\n    Explanation: This indicates that the parameter k, which represents the number of indices chosen for the elimination operation, must be at least 1 and at most equal to the length of the array n. In code, this can be implemented by iterating over possible values of k from 1 to n.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be considered simultaneously:\n    - Calculate the global bitwise AND result of the entire array.\n    - For each test case, check if all elements are zero initially.\n    - Compute the AND for subsets of elements.\n    These steps can be implemented in a loop that iterates over each test case, checking conditions and computing results as needed.\n\n# [edge case]\n    Test case with all elements already zero:\n    Input: [0, 0, 0, 0]\n    Expected output: 1\n    Explanation: Since all elements are already zero, no operations are needed, and the only possible k is 1.\n\n    Test case with a single element:\n    Input: [5]\n    Expected output: 1\n    Explanation: With only one element, k can only be 1, and the element can be reduced to zero by itself.\n\n    Test case with maximum possible value for n:\n    Input: [1] * 200000\n    Expected output: 1\n    Explanation: Since all elements are 1, any single element can be reduced to zero by itself, so k = 1 is valid.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of checking if all elements are zero initially and iterating over possible k values will naturally handle these cases.', '- name: \nBrute Force Pairwise Strategy\n\n- content: \nThe brute force approach involves systematically applying the elimination operation for each possible k from 1 to n. For each k, attempt to zero out the elements by selecting various combinations of indices:\n\n1. For k=1, directly apply the elimination operation to each element individually, which is always possible.\n\n2. For k=2 up to n, check if we can select subsets of size k where the bitwise AND of the elements is equal to one of the elements in the subset, allowing us to zero them out. Start with pairs and increase the size, keeping track of indices that can be zeroed out.\n\n3. Use combinatorial selection of indices and simulate the elimination step. If all elements can be zeroed after a sequence of operations for a given k, then k is valid.\n\n4. Output all valid k values after iterating through the possible ks.\n\nThis approach might be inefficient for large n due to the combinatorial aspect but will give correct results as it checks all possibilities.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'elimination\'\n    Explanation: In the context of this problem, "elimination" refers to the process of selecting a subset of indices from the array and performing a bitwise AND operation on the elements at those indices. The result of this operation is then subtracted from each of the selected elements, with the goal of eventually reducing all elements in the array to zero.\n\n    \'bitwise AND operation\'\n    Explanation: A bitwise AND operation takes two binary numbers and performs the logical AND operation on each pair of corresponding bits. The result is a new binary number where each bit is 1 if both corresponding bits of the operands are 1, otherwise it is 0.\n\n# [phrase showing quantity relationship]\n    \'1 ≤ k ≤ n\': This indicates that k can be any integer from 1 to n, inclusive. In code, this can be implemented using a loop that iterates over this range.\n    \n    \'all elements of array a equal to 0\': This means that after performing the elimination operations, every element in the array should be zero. In code, this can be checked by verifying if all elements in the array are zero.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented sequentially, as each step builds upon the results of the previous one. However, within each step, especially when checking combinations for elimination, multiple operations can be performed simultaneously using nested loops or combinatorial functions to generate subsets.\n\n# [edge case]\n    Test case: [0] = 1\n    Explanation: The array already contains only zeros, so any k from 1 to n (which is 1 in this case) is valid.\n\n    Test case: [1, 1, 1] = 1\n    Explanation: Each element can be zeroed out individually with k=1. No other k is possible because any combination of indices will not result in a bitwise AND that equals one of the elements.\n\n    Test case: [2, 2, 2] = 1 2 3\n    Explanation: For k=1, each element can be zeroed out individually. For k=2 and k=3, any combination of indices will result in a bitwise AND of 2, which can zero out all elements.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating through possible values of k and checking if all elements can be zeroed out will naturally handle these cases.', "- name: \nIncremental Zeroing via Pair Selection\n\n- content: \nThis approach focuses on incrementally zeroing elements by pairing:\n1. Start with k = 1, always valid as individual elements can be zeroed.\n2. For k > 1, attempt to pair elements such that their AND can be subtracted to zero them.\n   - Generate all possible pairings and check if after pairing some elements remain non-zero.\n   - Repeat operations until all elements are zeroed or no more valid pairings exist.\n3. For larger k, continue increasing pairs or sets and check for viable operations that reduce all to zero.\n4. Return valid k values.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'elimination'\n    Explanation: The process of reducing elements in the array to zero by performing operations with a chosen parameter k, using bitwise AND and subtraction.\n\n    'bitwise AND operation'\n    Explanation: A binary operation that takes two bit patterns of equal length and performs the logical AND operation on each pair of corresponding bits, resulting in a new bit pattern.\n\n# [phrase showing quantity relationship]\n    'finite number of elimination operations'\n    Explanation: The operations must be performed a limited number of times to achieve the goal of zeroing all elements.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps for k = 1 should be implemented simultaneously as it is always valid to zero individual elements. For k > 1, the process involves checking pairings or sets incrementally, which can be done in separate code blocks or loops.\n\n# [edge case]\n    Test case with all elements already zero: [0, 0, 0, 0] = 1 2 3 4\n    Explanation: Since all elements are already zero, any k value from 1 to n is valid.\n\n    Test case with a single element: [1] = 1\n    Explanation: With only one element, k = 1 is the only valid option to zero it.\n\n    Test case with maximum integer values: [1073741823, 1073741823] = 1\n    Explanation: Each element can be zeroed individually using k = 1, as pairing them would not result in zero due to the maximum value.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of checking valid k values through pairings and sets will naturally handle these scenarios.", '- name: \nBrute Force with Combinatorial Checks\n\n- content: \n- Iterate over each possible value of k from 1 to n.\n- For each k, try to find a combination of indices such that after the elimination operation, all elements become zero.\n- Use a bitmask or recursive function to check all possible combinations of indices for k.\n- If any combination works to make all elements zero, add k to the result list for that test case.\n- This approach is simple but might not be efficient for large n due to the combinatorial explosion of possibilities.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'elimination\'\n    Explanation: In the context of this problem, "elimination" refers to the process of selecting k distinct indices from the array and performing a bitwise AND operation on the elements at these indices. The result of this operation is then subtracted from each of the selected elements, with the goal of eventually making all elements in the array equal to zero.\n\n    \'bitwise AND operation\'\n    Explanation: A bitwise AND operation takes two binary numbers and performs the logical AND operation on each pair of corresponding bits. The result is a new binary number where each bit is 1 if both corresponding bits of the operands are 1, otherwise it is 0.\n\n# [phrase showing quantity relationship]\n    \'1 ≤ k ≤ n\': This indicates that k can be any integer between 1 and n, inclusive. In code, this can be implemented using a loop that iterates over this range.\n    \n    \'finite number of elimination operations\': This implies that there is a limited number of operations needed to achieve the goal, which suggests that the solution should not rely on infinite loops or recursion without a base case.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The plan suggests iterating over each possible value of k and checking combinations of indices. However, this can be computationally expensive for large n. Instead, consider optimizing by checking if there are any patterns or properties (e.g., common factors or bit patterns) that can be exploited to reduce the number of combinations checked.\n\n# [edge case]\n    Test case: [0] = 1\n    Explanation: The array already contains only zeros, so any k from 1 to n (which is 1 in this case) will work. The expected output is 1.\n\n    Test case: [1, 1, 1, 1] = 1 2 3 4\n    Explanation: Since all elements are the same and non-zero, any k will work because the bitwise AND of any subset will be 1, which can be subtracted from each element to make them zero.\n\n    Test case: [2, 2, 2, 2] = 1 2 4\n    Explanation: For k=3, it is impossible to make all elements zero because at least one element will remain non-zero after any operation. For k=1, k=2, and k=4, it is possible to make all elements zero.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n    Specifically, we need to check if all elements are already zero at the start and handle cases where all elements are identical.\n    \n```python\ndef handle_edge_cases(a):\n    if all(x == 0 for x in a):\n        return list(range(1, len(a) + 1))\n    if len(set(a)) == 1:\n        return list(range(1, len(a) + 1))\n    # Continue with original logic\n```\n\nThis additional code checks if all elements are zero or if all elements are identical and returns the appropriate range of k values.', '- name: \nGeneral Elimination Strategy\n\n- content: \nUse the properties of bitwise AND and subtraction to determine feasible k values by examining unique elements and their arrangement.\nSteps:\n1. Iterate through each test case.\n2. Check if all elements are zero; if so, k can be any number from 1 to n.\n3. Identify unique elements and count their occurrences.\n4. For each element, determine if it\'s possible to make it zero by grouping it with other elements of the same value (use its count as a potential k).\n5. If elements are different, analyze pairs or larger groups that can be reduced based on their bitwise AND result.\n6. Return all k values that can achieve zeroing of all elements.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'elimination\'\n    Explanation: The operation of "elimination" involves choosing k distinct indices from the array and performing a bitwise AND operation on the elements at these indices, then subtracting the result from each of these elements.\n\n    \'bitwise AND operation\'\n    Explanation: A bitwise AND operation compares each bit of two numbers and returns a new number where each bit is 1 if both corresponding bits of the operands are 1, otherwise it is 0.\n\n# [phrase showing quantity relationship]\n    \'finite number of elimination operations\'\n    Explanation: This implies that the process of making all elements zero must be achievable within a limited number of steps, not indefinitely.\n\n# [degree adverb]\n    \'all possible values\'\n    Explanation: This means finding every k that can achieve the goal, not just one or some.\n\n# [code logic]\n    Steps 2 and 3 should be considered simultaneously. If all elements are zero, k can be any number from 1 to n. Otherwise, identify unique elements and count their occurrences to determine potential k values.\n\n# [edge case]\n    Test case with all elements already zero:\n    Input: [0, 0, 0, 0]\n    Expected output: 1 2 3 4\n    Explanation: Since all elements are zero, any k from 1 to n can be used.\n\n    Test case with only one element:\n    Input: [1]\n    Expected output: 1\n    Explanation: With a single element, k can only be 1.\n\n    Test case with maximum possible value:\n    Input: [1073741823, 1073741823]\n    Expected output: 1 2\n    Explanation: The maximum value for a_i is 2^30 - 1. With two identical maximum values, k can be either 1 or 2.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if all(x == 0 for x in array):\n            return list(range(1, len(array) + 1))\n        elif len(array) == 1:\n            return [1]\n        # Additional logic for handling maximum value cases and other scenarios.\n', '- name: \nPairwise Elimination\n\n- content: \nThis solution attempts to optimize by utilizing k=2 whenever possible. The key idea is that by choosing pairs of elements with non-zero values, it can often be possible to make progress towards zeroing out the array. The bitwise AND operation on pairs can help reduce values efficiently and is particularly useful when elements have similar bits set.\nSteps:\n- For each test case, check if all elements are zero. If they are, return all possible k values from 1 to n.\n- Otherwise, focus on using k=2 for pairwise elimination.\n- Use a greedy approach to pair up elements and perform elimination until all elements become zero.\n- Output k=1 and k=2 if successful, as pairwise operations often complement single element operations.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'elimination\'\n    Explanation: In the context of this problem, "elimination" refers to the process of reducing selected elements of the array to zero using a specific operation defined by the problem. This involves choosing a subset of indices and applying a bitwise AND operation to compute a value that is subtracted from each selected element.\n\n    \'bitwise AND operation\'\n    Explanation: The bitwise AND operation is a binary operation that takes two equal-length binary representations and performs the logical AND operation on each pair of corresponding bits. The result in each position is 1 if both bits are 1, otherwise, it is 0.\n\n# [phrase showing quantity relationship]\n    \'all possible values of k\'\n    Explanation: This means finding every integer k such that the elimination process can be applied to make all elements zero. In code, this involves iterating over possible k values and checking if the condition can be satisfied.\n\n# [degree adverb]\n    \'all\'\n    Explanation: This indicates that every element in the array must be reduced to zero. In code, this means ensuring that after operations, no element remains non-zero.\n\n# [code logic]\n    The steps "check if all elements are zero" and "return all possible k values from 1 to n" should be implemented simultaneously. If the array is already zero, we can directly output all k values without further operations.\n\n# [edge case]\n    Test case with all elements already zero:\n    Input: [0, 0, 0, 0]\n    Expected output: 1 2 3 4\n    Explanation: Since all elements are already zero, any k value from 1 to n is valid.\n\n    Test case with a single element:\n    Input: [1]\n    Expected output: 1\n    Explanation: With only one element, k=1 is the only possible choice to make it zero.\n\n    Test case with maximum n:\n    Input: [1, 1, ..., 1] (200,000 times)\n    Expected output: 1\n    Explanation: With all elements being 1, only k=1 can be used to make each element zero individually.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where all elements are initially zero.\n    \n```python\ndef handle_edge_cases(a):\n    if all(x == 0 for x in a):\n        return list(range(1, len(a) + 1))\n    return None\n```\n\nThis function checks if all elements are zero and returns all possible k values if true. Otherwise, it returns None, indicating that normal logic should proceed.']
----------
False
----------
0
multi-gen-prompt:
For an array b of n integers, the extreme value of this array is the minimum number of times (possibly, zero) the following operation has to be performed to make b non-decreasing: 

  * Select an index i such that 1 ≤ i ≤ |b|, where |b| is the current length of b. 
  * Replace b_i with two elements x and y such that x and y both are positive integers and x + y = b_i. You can pick any two positive integers that sum up to b_i for this operation. Once replaced, x and y are inserted in place of b_i.
  * This way, the array b changes and the next operation is performed on this modified array. 

For example, if b = [2, 4, 3] and index 2 gets selected, then the possible arrays after this operation are [2, \underline{1}, \underline{3}, 3], [2, \underline{2}, \underline{2}, 3], or [2, \underline{3}, \underline{1}, 3]. And consequently, for this array, this single operation is enough to make it non-decreasing: [2, 4, 3] → [2, \underline{2}, \underline{2}, 3].

It's easy to see that every array of positive integers can be made non-decreasing this way.

YouKn0wWho has an array a of n integers. Help him find the sum of extreme values of all nonempty subarrays of a modulo 998 244 353. If a subarray appears in a multiple times, its extreme value should be counted the number of times it appears.

An array d is a subarray of an array c if d can be obtained from c by deletion of several (possibly, zero or all) elements from the beginning and several (possibly, zero or all) elements from the end.

Input

The first line contains a single integer t (1 ≤ t ≤ 10 000) — the number of test cases.

The first line of each test case contains a single integer n (1 ≤ n ≤ 10^5).

The second line of each test case contains n integers a_1, a_2, …, a_n (1 ≤ a_i ≤ 10^5).

It is guaranteed that the sum of n over all test cases doesn't exceed 10^5.

Output

For each test case, print a single integer — the sum of extreme values of all subarrays of a modulo 998 244 353.

Example

Input


4
3
5 4 3
4
3 2 1 4
1
69
8
7264 40515 28226 92776 35285 21709 75124 48163


Output


5
9
0
117

Note

Let f(l, r) denote the extreme value of [a_l, a_{l+1}, …, a_r].

In the first test case, 

  * f(1, 3) = 3, because YouKn0wWho can perform the following operations on the subarray [5, 4, 3] (the newly inserted elements are underlined):

[5, 4, 3] → [\underline{3}, \underline{2}, 4, 3] → [3, 2, \underline{2}, \underline{2}, 3] → [\underline{1}, \underline{2}, 2, 2, 2, 3];

  * f(1, 2) = 1, because [5, 4] → [\underline{2}, \underline{3}, 4];
  * f(2, 3) = 1, because [4, 3] → [\underline{1}, \underline{3}, 3];
  * f(1, 1) = f(2, 2) = f(3, 3) = 0, because they are already non-decreasing. 



So the total sum of extreme values of all subarrays of a = 3 + 1 + 1 + 0 + 0 + 0 = 5.
multi-gen-prompt:
For an array b of n integers, the extreme value of this array is the minimum number of times (possibly, zero) the following operation has to be performed to make b non-decreasing: Select an index i such that 1 ≤ i ≤ |b|, where |b| is the current length of b, and replace b_i with two elements x and y such that x and y both are positive integers and x + y = b_i. This way, the array b changes and the next operation is performed on this modified array.

For example, if b = [2, 4, 3] and index 2 gets selected, then the possible arrays after this operation are [2, \underline{1}, \underline{3}, 3], [2, \underline{2}, \underline{2}, 3], or [2, \underline{3}, \underline{1}, 3]. And consequently, for this array, this single operation is enough to make it non-decreasing: [2, 4, 3] → [2, \underline{2}, \underline{2}, 3].

YouKn0wWho has an array a of n integers. Help him find the sum of extreme values of all nonempty subarrays of a modulo 998 244 353. If a subarray appears in a multiple times, its extreme value should be counted the number of times it appears.

An array d is a subarray of an array c if d can be obtained from c by deletion of several (possibly, zero or all) elements from the beginning and several (possibly, zero or all) elements from the end.

Input

The first line contains a single integer t (1 ≤ t ≤ 10 000) — the number of test cases.

The first line of each test case contains a single integer n (1 ≤ n ≤ 10^5).

The second line of each test case contains n integers a_1, a_2, …, a_n (1 ≤ a_i ≤ 10^5).

It is guaranteed that the sum of n over all test cases doesn't exceed 10^5.

Output

For each test case, print a single integer — the sum of extreme values of all subarrays of a modulo 998 244 353.

Example

Input


4
3
5 4 3
4
3 2 1 4
1
69
8
7264 40515 28226 92776 35285 21709 75124 48163


Output


5
9
0
117

Note

Let f(l, r) denote the extreme value of [a_l, a_{l+1}, …, a_r].

In the first test case, 

  * f(1, 3) = 3, because YouKn0wWho can perform the following operations on the subarray [5, 4, 3] (the newly inserted elements are underlined):

[5, 4, 3] → [\underline{3}, \underline{2}, 4, 3] → [3, 2, \underline{2}, \underline{2}, 3] → [\underline{1}, \underline{2}, 2, 2, 2, 3];

  * f(1, 2) = 1, because [5, 4] → [\underline{2}, \underline{3}, 4];
  * f(2, 3) = 1, because [4, 3] → [\underline{1}, \underline{3}, 3];
  * f(1, 1) = f(2, 2) = f(3, 3) = 0, because they are already non-decreasing. 



So the total sum of extreme values of all subarrays of a = 3 + 1 + 1 + 0 + 0 + 0 = 5.
generating with gpt-4o
----------
['def calculate_extreme_value(subarray):\n    n = len(subarray)\n    operations = 0\n    max_value = subarray[0]\n    \n    for i in range(1, n):\n        if subarray[i] < max_value:\n            # Calculate the number of splits needed to make subarray[i] >= max_value\n            # The number of splits required is ceil(max_value / subarray[i]) - 1\n            # We can use integer arithmetic to avoid floating point operations\n            splits = (max_value + subarray[i] - 1) // subarray[i] - 1\n            operations += splits\n        else:\n            max_value = subarray[i]\n    \n    return operations\n\ndef sum_of_extreme_values(n, array):\n    total_sum = 0\n    mod = 998244353\n    \n    # Iterate over all possible subarrays\n    for start in range(n):\n        for end in range(start, n):\n            subarray = array[start:end + 1]\n            operations = calculate_extreme_value(subarray)\n            total_sum = (total_sum + operations) % mod\n    \n    return total_sum\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        array = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = sum_of_extreme_values(n, array)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_extreme_value(subarray):\n    # Calculate the number of operations needed to make the subarray non-decreasing\n    operations = 0\n    max_so_far = subarray[0]\n    \n    for i in range(1, len(subarray)):\n        if subarray[i] < max_so_far:\n            # Calculate the number of splits needed\n            splits = (max_so_far + subarray[i] - 1) // subarray[i] - 1\n            operations += splits\n        else:\n            max_so_far = subarray[i]\n    \n    return operations\n\ndef sum_of_extreme_values(n, a):\n    total_sum = 0\n    MOD = 998244353\n    \n    # Iterate over all possible subarrays\n    for start in range(n):\n        max_so_far = a[start]\n        operations = 0\n        for end in range(start, n):\n            if a[end] < max_so_far:\n                # Calculate the number of splits needed\n                splits = (max_so_far + a[end] - 1) // a[end] - 1\n                operations += splits\n            else:\n                max_so_far = a[end]\n            total_sum = (total_sum + operations) % MOD\n    \n    return total_sum\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index+n]))\n        index += n\n        \n        result = sum_of_extreme_values(n, a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_extreme_value(a):\n    n = len(a)\n    extreme_value_sum = 0\n    \n    # Iterate over all possible subarrays\n    for start in range(n):\n        max_in_subarray = a[start]\n        for end in range(start, n):\n            # Update the maximum value in the current subarray\n            max_in_subarray = max(max_in_subarray, a[end])\n            \n            # Calculate the extreme value for the current subarray\n            # The extreme value is the number of operations needed to make it non-decreasing\n            extreme_value = 0\n            current_max = a[start]\n            \n            for i in range(start + 1, end + 1):\n                if a[i] < current_max:\n                    # Calculate how many splits are needed\n                    extreme_value += (current_max - a[i] + a[i] - 1) // a[i]\n                current_max = max(current_max, a[i])\n            \n            # Add to the total sum of extreme values\n            extreme_value_sum += extreme_value\n    \n    return extreme_value_sum % 998244353\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = calculate_extreme_value(a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_extreme_value(subarray):\n    n = len(subarray)\n    operations = 0\n    \n    # Iterate through the subarray to count the number of out-of-order elements\n    for i in range(1, n):\n        if subarray[i] < subarray[i - 1]:\n            operations += 1\n    \n    return operations\n\ndef sum_of_extreme_values(a):\n    n = len(a)\n    total_operations = 0\n    \n    # Iterate over all possible subarrays\n    for start in range(n):\n        for end in range(start, n):\n            subarray = a[start:end+1]\n            total_operations += calculate_extreme_value(subarray)\n    \n    return total_operations % 998244353\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = sum_of_extreme_values(a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_extreme_value(subarray):\n    # Calculate the number of operations needed to make the subarray non-decreasing\n    operations = 0\n    max_value = subarray[0]\n    for i in range(1, len(subarray)):\n        if subarray[i] < max_value:\n            # Calculate how many splits are needed to make subarray[i] >= max_value\n            # We need to split subarray[i] into parts such that each part is >= max_value\n            # The number of splits required is determined by how many parts we need to make subarray[i] >= max_value\n            operations += (max_value - subarray[i] + subarray[i] - 1) // subarray[i]\n        else:\n            max_value = subarray[i]\n    return operations\n\ndef sum_of_extreme_values(n, a):\n    total_sum = 0\n    # Iterate over all possible subarrays\n    for l in range(n):\n        max_value = a[l]\n        operations = 0\n        for r in range(l, n):\n            if a[r] < max_value:\n                # Calculate the number of splits needed to make a[r] >= max_value\n                operations += (max_value - a[r] + a[r] - 1) // a[r]\n            else:\n                max_value = a[r]\n            total_sum += operations\n    return total_sum % 998244353\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index+n]))\n        index += n\n        \n        result = sum_of_extreme_values(n, a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_extreme_value(subarray):\n    n = len(subarray)\n    operations = 0\n    max_value = subarray[0]\n    \n    for i in range(1, n):\n        if subarray[i] < max_value:\n            # Calculate the number of splits needed\n            # We need to split max_value into parts <= subarray[i]\n            needed_splits = (max_value + subarray[i] - 1) // subarray[i]\n            operations += needed_splits - 1\n            max_value = subarray[i] * needed_splits\n        else:\n            max_value = subarray[i]\n    \n    return operations\n\ndef sum_of_extreme_values(a):\n    n = len(a)\n    total_sum = 0\n    for start in range(n):\n        for end in range(start, n):\n            subarray = a[start:end + 1]\n            total_sum += calculate_extreme_value(subarray)\n    return total_sum % 998244353\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = sum_of_extreme_values(a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def count_operations_to_make_non_decreasing(subarray):\n    operations = 0\n    max_value = subarray[0]\n    \n    for i in range(1, len(subarray)):\n        if subarray[i] < max_value:\n            # Calculate the number of splits needed for subarray[i]\n            needed_splits = (max_value + subarray[i] - 1) // subarray[i] - 1\n            operations += needed_splits\n        else:\n            max_value = subarray[i]\n    \n    return operations\n\ndef sum_of_extreme_values(n, a):\n    MOD = 998244353\n    total_sum = 0\n\n    for start in range(n):\n        for end in range(start, n):\n            subarray = a[start:end + 1]\n            operations = count_operations_to_make_non_decreasing(subarray)\n            total_sum = (total_sum + operations) % MOD\n\n    return total_sum\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n\n    t = int(data[0])\n    index = 1\n    results = []\n\n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index+n]))\n        index += n\n\n        result = sum_of_extreme_values(n, a)\n        results.append(result)\n\n    for res in results:\n        print(res)', 'def calculate_extreme_value(subarray):\n    # This function calculates the minimum number of operations needed to make the subarray non-decreasing\n    operations = 0\n    current_max = subarray[0]\n    \n    for i in range(1, len(subarray)):\n        if subarray[i] < current_max:\n            # Calculate the number of splits needed to make subarray[i] at least current_max\n            # We need to split subarray[i] into parts such that each part is <= current_max\n            # The number of parts needed is ceil(current_max / subarray[i])\n            parts_needed = (current_max + subarray[i] - 1) // subarray[i]\n            operations += parts_needed - 1\n            # Update current_max to reflect the new maximum after splitting\n            current_max = subarray[i] * parts_needed\n        else:\n            current_max = subarray[i]\n    \n    return operations\n\ndef sum_of_extreme_values(n, a):\n    total_sum = 0\n    mod = 998244353\n    \n    # Iterate over all possible subarrays\n    for l in range(n):\n        for r in range(l, n):\n            subarray = a[l:r+1]\n            extreme_value = calculate_extreme_value(subarray)\n            total_sum = (total_sum + extreme_value) % mod\n    \n    return total_sum\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index+n]))\n        index += n\n        \n        result = sum_of_extreme_values(n, a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_extreme_value(subarray):\n    # Calculate the minimum number of splits needed to make the subarray non-decreasing\n    operations = 0\n    max_value = subarray[0]\n    \n    for i in range(1, len(subarray)):\n        if subarray[i] < max_value:\n            # Calculate the number of splits needed to make subarray[i] >= max_value\n            operations += (max_value - subarray[i] + subarray[i] - 1) // subarray[i]\n        else:\n            max_value = subarray[i]\n    \n    return operations\n\ndef sum_of_extreme_values(n, a):\n    total_extreme_value = 0\n    MOD = 998244353\n    \n    # Iterate over all possible subarrays\n    for start in range(n):\n        for end in range(start, n):\n            subarray = a[start:end+1]\n            extreme_value = calculate_extreme_value(subarray)\n            total_extreme_value = (total_extreme_value + extreme_value) % MOD\n    \n    return total_extreme_value\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index+n]))\n        index += n\n        \n        result = sum_of_extreme_values(n, a)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_extreme_value_for_subarray(subarray):\n    # Calculate the minimum number of operations needed to make the subarray non-decreasing\n    operations = 0\n    max_value = subarray[0]\n    \n    for i in range(1, len(subarray)):\n        if subarray[i] < max_value:\n            # Calculate how many splits are needed to make subarray[i] >= max_value\n            needed_splits = (max_value + subarray[i] - 1) // subarray[i] - 1\n            operations += needed_splits\n        max_value = max(max_value, subarray[i])\n    \n    return operations\n\ndef sum_of_extreme_values(n, a):\n    MOD = 998244353\n    total_sum = 0\n\n    # Iterate over all possible subarrays\n    for start in range(n):\n        for end in range(start, n):\n            subarray = a[start:end + 1]\n            extreme_value = calculate_extreme_value_for_subarray(subarray)\n            total_sum += extreme_value\n            total_sum %= MOD\n\n    return total_sum\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        a = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = sum_of_extreme_values(n, a)\n        results.append(result)\n    \n    for res in results:\n        print(res)']
----------
["- name: \nDivide and Conquer with Dynamic Programming\n\n- content: \nThis plan uses divide-and-conquer along with dynamic programming to manage subarray operations more efficiently.\n1. Implement a recursive function that divides the array into two halves until reaching base cases of single-element arrays, which require zero operations.\n2. For each divided subarray, compute operations needed to merge them back into a non-decreasing array:\n   - Calculate minimum operations for left and right halves independently.\n   - Consider merging operations across the midpoint where non-decreasing conditions might be violated.\n3. Use dynamic programming to store intermediate results and avoid redundant calculations on overlapping subproblems.\n4. Combine results from both halves and adjust for any additional operations needed for merging, taking care to apply modulo 998244353.\nThis approach leverages problem structure to minimize redundant computations, offering a balance between efficiency and complexity management for larger inputs.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'extreme value'\n    Explanation: The extreme value of an array is the minimum number of operations needed to make the array non-decreasing by splitting elements into two positive integers.\n\n    'non-decreasing'\n    Explanation: An array is non-decreasing if each element is greater than or equal to the previous element.\n\n    'subarray'\n    Explanation: A subarray is a contiguous part of an array, obtained by deleting elements from the beginning and/or end.\n\n# [phrase showing quantity relationship]\n    'minimum number of times': This indicates the least number of operations required to achieve the desired condition (non-decreasing array).\n    Implementation: This can be implemented by calculating the minimum operations needed for each subarray.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Implementing the recursive function to divide the array and calculate operations for merging should be done in a single code block.\n    - Dynamic programming should be used to store intermediate results and avoid redundant calculations.\n\n# [edge case]\n    Test case with a single element: [69] = 0\n    Explanation: A single-element array is already non-decreasing, so no operations are needed.\n\n    Test case with all elements equal: [3, 3, 3] = 0\n    Explanation: Since all elements are equal, the array is non-decreasing, requiring zero operations.\n\n    Test case with strictly decreasing elements: [5, 4, 3] = 3\n    Explanation: Multiple operations are needed to make this array non-decreasing, as shown in the example.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if len(subarray) == 1:\n            return 0\n        if all(x == subarray[0] for x in subarray):\n            return 0\n        (other code for handling general cases)", '- name: \nDynamic Programming with Stack Optimization\n\n- content: \nUtilize dynamic programming along with a stack-based approach to efficiently compute the extreme values:\n1. Define a DP array where dp[i] represents the minimum number of operations needed to make the subarray ending at index i non-decreasing.\n2. Use a stack to keep track of elements in the current non-decreasing sequence.\n3. For each element in the array, determine if it can be appended to the current sequence or if it requires splitting.\n4. Update the DP array based on previous values and stack information.\n5. Calculate the contribution of each subarray using the DP values.\n6. Sum up all contributions modulo 998,244,353 to get the result.\nThis approach reduces redundant calculations by leveraging previously computed results and efficiently manages sequence changes using a stack.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'extreme value\'\n    Explanation: The extreme value refers to the minimum number of operations needed to make a subarray non-decreasing by splitting elements into two positive integers.\n\n    \'non-decreasing\'\n    Explanation: A sequence is non-decreasing if each element is greater than or equal to the previous one.\n\n    \'subarray\'\n    Explanation: A subarray is a contiguous part of an array, obtained by deleting elements from the beginning and/or end.\n\n# [phrase showing quantity relationship]\n    \'minimum number of times\': This indicates the least number of operations required to achieve the desired condition (non-decreasing array).\n    Implementation: Use dynamic programming to track the minimum operations needed for each subarray.\n\n# [degree adverb]\n    \'extreme\': Refers to the minimum operations needed, emphasizing the least amount required.\n    Implementation: Use a dynamic programming approach to ensure the minimum operations are calculated.\n\n# [code logic]\n    Steps 1-3 should be considered simultaneously:\n    "Define a DP array where dp[i] represents the minimum number of operations needed to make the subarray ending at index i non-decreasing",\n    "Use a stack to keep track of elements in the current non-decreasing sequence",\n    "For each element in the array, determine if it can be appended to the current sequence or if it requires splitting"\n    These steps can be implemented in a single loop where you update the DP array and manage the stack concurrently.\n\n# [edge case]\n    Test case with a single element: [69] = 0\n    Explanation: A single element is already non-decreasing, so no operations are needed.\n\n    Test case with all elements equal: [5, 5, 5] = 0\n    Explanation: All elements are equal, hence already non-decreasing.\n\n    Test case with strictly decreasing elements: [5, 4, 3] = 3\n    Explanation: Requires multiple operations to make non-decreasing, as shown in the example.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using dynamic programming and stack optimization will naturally handle these cases.', "- name: \nGreedy with Sliding Window\n\n- content: \nUse a sliding window technique combined with a greedy strategy to efficiently calculate the number of operations required.\nSteps:\n1. Maintain a sliding window that represents the current subarray being considered.\n2. Move the window across the array, checking for violations of the non-decreasing property.\n3. When a violation is found, perform the necessary operation (splitting) to correct it and continue moving the window.\n4. Keep track of operations required and accumulate them for each window position.\n5. Sum up results for all subarrays and apply modulo 998244353.\nThis method focuses on local corrections, reducing redundant checks and improving performance over a naive implementation by focusing on potential problem areas within the array.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'extreme value'\n    Explanation: The extreme value of an array is the minimum number of operations needed to make the array non-decreasing by splitting elements into two positive integers whose sum equals the original element.\n\n    'non-decreasing'\n    Explanation: An array is non-decreasing if each element is not less than the previous one.\n\n    'subarray'\n    Explanation: A subarray is a contiguous part of an array, which can be obtained by deleting some elements from the beginning and/or end of the array.\n\n# [phrase showing quantity relationship]\n    'minimum number of times'\n    Explanation: This refers to the least number of operations needed to achieve the desired condition (non-decreasing array). In code, this can be implemented by counting operations and ensuring they are minimized.\n\n    'sum of extreme values'\n    Explanation: This means adding up all the extreme values calculated for each subarray. In code, this involves iterating over all subarrays, calculating their extreme values, and summing them up.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 1-4 should be implemented simultaneously as they involve maintaining a sliding window and performing operations when violations are found. This can be done using a loop that iterates over the array, checking for non-decreasing violations and performing necessary operations within the same loop.\n\n# [edge case]\n    Edge Case 1: a = [1] -> Expected Output: 0\n    Explanation: A single-element array is already non-decreasing, so no operations are needed.\n\n    Edge Case 2: a = [2, 2, 2] -> Expected Output: 0\n    Explanation: The array is already non-decreasing, so no operations are needed.\n\n    Edge Case 3: a = [3, 2, 1] -> Expected Output: 3\n    Explanation: The entire array is decreasing. Operations are needed to make it non-decreasing, such as splitting elements to achieve [1, 1, 1, 1, 1, 1].\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n    Specifically, we need to check if a subarray is already non-decreasing and skip operations in such cases. This can be done by adding a condition to check if each element is greater than or equal to the previous one before performing any operations.\n    \n```python\ndef calculate_extreme_value(a):\n    n = len(a)\n    extreme_value_sum = 0\n    for start in range(n):\n        for end in range(start, n):\n            subarray = a[start:end+1]\n            if all(subarray[i] <= subarray[i+1] for i in range(len(subarray)-1)):\n                continue\n            # Perform operations to make subarray non-decreasing\n            # Calculate extreme value for this subarray\n            extreme_value = ... # logic to calculate extreme value\n            extreme_value_sum += extreme_value\n    return extreme_value_sum % 998244353\n```", "- name: \nBrute Force with Subarray Enumeration\n\n- content: \nThis approach involves enumerating all possible subarrays and calculating the extreme value for each one. Although straightforward, it might be inefficient for larger arrays.\nSteps:\n1. Iterate over all possible starting indices of subarrays.\n2. For each starting index, iterate over all possible ending indices.\n3. For each subarray defined by a starting and ending index, simulate the process of making it non-decreasing by splitting elements until the array is non-decreasing.\n4. Count the number of operations required to achieve a non-decreasing order and add this to the total sum for the current test case.\n5. Return the sum modulo 998244353.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'extreme value'\n    Explanation: The extreme value of an array is the minimum number of operations needed to make the array non-decreasing by splitting elements.\n\n    'non-decreasing'\n    Explanation: An array is non-decreasing if each element is not less than the previous one.\n\n    'subarray'\n    Explanation: A subarray is a contiguous part of an array, obtained by deleting elements from the beginning and/or end.\n\n# [phrase showing quantity relationship]\n    'minimum number of times'\n    Explanation: This refers to the least number of operations needed to achieve a non-decreasing array. In code, this can be implemented by counting operations and ensuring they are minimized.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 1-3 should be implemented simultaneously as they involve iterating over subarrays and calculating the extreme value for each. This can be done using nested loops where the outer loop iterates over starting indices and the inner loop iterates over ending indices.\n\n# [edge case]\n    Test case: [1] = 0\n    Explanation: A single element array is already non-decreasing, so no operations are needed.\n\n    Test case: [2, 2, 2] = 0\n    Explanation: All elements are equal, so the array is already non-decreasing.\n\n    Test case: [3, 2, 1] = 3\n    Explanation: Each element needs to be split to make the array non-decreasing, requiring multiple operations.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating over subarrays and counting operations will naturally handle these cases.", "- name: \nEfficient Calculation using Dynamic Programming\n\n- content: \nThis approach leverages dynamic programming to efficiently calculate the minimum operations needed for each subarray without recalculating for overlapping segments.\n\nSteps:\n1. For each test case, read the array `a` and its length `n`.\n2. Initialize a DP table `dp` where `dp[i][j]` represents the minimum operations needed for the subarray `a[i..j]`.\n3. Set base cases: single element subarrays have zero operations since they are trivially non-decreasing.\n4. For larger subarrays, iterate over possible lengths and starting positions:\n   - Use a nested loop where the outer loop selects subarray length and the inner loop selects starting index.\n   - For each subarray `a[i..j]`, determine if it's non-decreasing; if not, find an optimal split point `k` such that splitting at `k` minimizes operations (using previously calculated dp values).\n   - Update `dp[i][j]` based on optimal splits.\n5. Sum up all dp values to get the total number of operations across all subarrays.\n6. Compute the total sum modulo 998244353 for each test case.\n7. Output the result for each test case.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'extreme value'\n    Explanation: The extreme value of an array is the minimum number of operations needed to make the array non-decreasing by splitting elements into two positive integers.\n\n    'non-decreasing'\n    Explanation: An array is non-decreasing if each element is greater than or equal to the previous element.\n\n    'subarray'\n    Explanation: A subarray is a contiguous segment of an array.\n\n# [phrase showing quantity relationship]\n    'minimum number of times': This indicates the least number of operations required to achieve the desired condition (non-decreasing array).\n    Implementation: Use dynamic programming to find the minimum operations for each subarray.\n\n# [degree adverb]\n    'minimum': Refers to the least number of operations needed.\n    Implementation: Use dynamic programming to calculate the minimum operations required for each subarray.\n\n# [code logic]\n    Steps 4 and 5 should be considered simultaneously:\n    - Iterate over possible lengths and starting positions of subarrays.\n    - For each subarray, determine if it's non-decreasing and find optimal split points.\n    Implementation: Use nested loops to iterate over subarray lengths and starting indices, updating the DP table accordingly.\n\n# [edge case]\n    Case 1: a = [1] = 0\n    Explanation: A single element array is already non-decreasing, so no operations are needed.\n\n    Case 2: a = [1, 1, 1] = 0\n    Explanation: All elements are equal, so the array is non-decreasing without any operations.\n\n    Case 3: a = [3, 2, 1] = 3\n    Explanation: The array is strictly decreasing, requiring multiple operations to make it non-decreasing.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using dynamic programming will naturally handle these cases by calculating the minimum operations needed for each subarray.", '- name: \nGreedy with Efficient Count Tracking\n- content: \nThis approach employs a greedy strategy combined with efficient tracking of counts:\n1. Maintain an array or data structure to efficiently track counts and positions of elements as you iterate through the array.\n2. For each element, determine if it breaks the non-decreasing order.\n3. If it does, calculate the minimum operations needed using a greedy method, potentially splitting the element optimally.\n4. Update counts and positions dynamically as you process each element in the array.\n5. Sum up the operations required for each subarray as you process them.\n6. Return the result modulo 998244353.\nThis method aims to strike a balance between efficiency and simplicity by using greedy choices and efficient data tracking.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'extreme value\'\n    Explanation: The extreme value of an array is the minimum number of operations needed to make the array non-decreasing by splitting elements into two positive integers that sum up to the original element.\n\n    \'non-decreasing\'\n    Explanation: An array is non-decreasing if each element is not less than the previous one.\n\n    \'subarray\'\n    Explanation: A subarray is a contiguous part of an array, which can be obtained by deleting elements from the beginning and/or end of the array.\n\n# [phrase showing quantity relationship]\n    \'minimum number of times\'\n    Explanation: This refers to the least number of operations required to achieve a non-decreasing array. In code, this can be implemented by calculating the fewest splits needed for each subarray.\n\n    \'sum of extreme values\'\n    Explanation: This means adding up all the extreme values calculated for each subarray. In code, this involves iterating over all subarrays and summing their extreme values.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be considered simultaneously:\n    - "For each element, determine if it breaks the non-decreasing order."\n    - "If it does, calculate the minimum operations needed using a greedy method, potentially splitting the element optimally."\n    These steps can be implemented in a single loop where you check each element and decide if a split is necessary, then perform the split if needed.\n\n# [edge case]\n    Test case: [1] = 0\n    Explanation: A single element is already non-decreasing, so no operations are needed.\n\n    Test case: [1, 1, 1] = 0\n    Explanation: All elements are equal, so the array is already non-decreasing.\n\n    Test case: [5, 5, 5, 5] = 0\n    Explanation: All elements are equal, so no operations are needed to make it non-decreasing.\n\n# [extra code for edge case]\n    We do not need extra code to handle these edge cases. The original logic of checking if an array is already non-decreasing will naturally handle these cases without additional conditions.', '- name: \nEfficient Decomposition with Counting Inversions\n\n- content: \nThis approach leverages the concept of counting inversions to efficiently compute the number of operations needed:\n1. Define an inversion as a pair (i, j) such that i < j and a[i] > a[j].\n2. For each test case, use a modified merge sort algorithm to count the number of inversions in each subarray.\n3. The number of inversions gives a lower bound on the number of operations needed to make a subarray non-decreasing.\n4. Use this inversion count to compute the extreme value for each subarray.\n5. Sum up these values for all subarrays, applying modulo 998,244,353, and return the result for each test case.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'extreme value\'\n    Explanation: The extreme value refers to the minimum number of operations needed to make a subarray non-decreasing by splitting elements into two positive integers.\n\n    \'non-decreasing\'\n    Explanation: A sequence is non-decreasing if each element is greater than or equal to the previous one.\n\n    \'subarray\'\n    Explanation: A subarray is a contiguous part of an array, obtained by deleting elements from the beginning and/or end.\n\n# [phrase showing quantity relationship]\n    \'minimum number of times\': This indicates the least number of operations required to achieve the desired condition (non-decreasing array).\n    Implementation: This can be calculated using an algorithm that counts inversions, as inversions represent pairs that need operations to become non-decreasing.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be implemented simultaneously.\n    "Use a modified merge sort algorithm to count the number of inversions in each subarray",\n    "The number of inversions gives a lower bound on the number of operations needed to make a subarray non-decreasing"\n    This can be done by integrating the inversion counting within the merge sort process.\n\n# [edge case]\n    Test case with a single element: [69] = 0\n    Explanation: A single element is already non-decreasing, so no operations are needed.\n\n    Test case with all elements equal: [5, 5, 5] = 0\n    Explanation: All elements are equal, hence the array is non-decreasing without any operations.\n\n    Test case with strictly increasing elements: [1, 2, 3] = 0\n    Explanation: The array is already non-decreasing, so no operations are needed.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of counting inversions will naturally handle these cases as they result in zero inversions.', "- name: \nBrute Force Subarray Analysis\n\n- content: \nThis solution involves iterating over all possible subarrays of the given array and calculating the extreme value for each subarray. Although inefficient for large arrays, it provides a straightforward way to verify the correctness of the algorithm.\n\nSteps:\n1. For each test case, read the array size `n` and the array `a`.\n2. Iterate over all possible subarray starting points `l` (from 0 to n-1).\n3. For each starting point `l`, iterate over all possible ending points `r` (from l to n-1).\n4. For each subarray `a[l:r+1]`, calculate the minimum number of operations needed to make it non-decreasing by simulating the splitting operation.\n5. Maintain a count of operations for each subarray and sum these counts.\n6. Return the sum modulo 998244353.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'extreme value'\n    Explanation: The extreme value of an array is defined as the minimum number of operations needed to make the array non-decreasing by splitting elements into two positive integers whose sum equals the original element.\n\n    'non-decreasing'\n    Explanation: An array is non-decreasing if each element is not less than the previous one.\n\n    'subarray'\n    Explanation: A subarray is a contiguous part of an array, which can be obtained by deleting some elements from the beginning and/or end of the array.\n\n# [phrase showing quantity relationship]\n    'minimum number of times'\n    Explanation: This refers to finding the least number of operations required to achieve a non-decreasing array. In code, this can be implemented by simulating operations and counting them until the condition is met.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 2-4 should be considered simultaneously. For each subarray, you need to calculate the extreme value by simulating the splitting operation and counting the operations needed to make it non-decreasing. This can be done in a nested loop where you iterate over starting and ending points of subarrays and calculate the extreme value in one go.\n\n# [edge case]\n    Case 1: a = [1] -> Expected output: 0\n    Explanation: A single element array is already non-decreasing, so no operations are needed.\n\n    Case 2: a = [1, 1, 1] -> Expected output: 0\n    Explanation: All elements are equal, so the array is already non-decreasing.\n\n    Case 3: a = [3, 2, 1] -> Expected output: 3\n    Explanation: Each element needs to be split to make the array non-decreasing. For example, [3, 2, 1] -> [1, 2, 1] -> [1, 1, 1, 1] -> [1, 1, 1, 1, 1].\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n    The logic should include:\n    - Checking if a subarray is already non-decreasing.\n    - Implementing a function to simulate the splitting operation and count the number of operations needed.\n    \n```python\ndef calculate_extreme_value(subarray):\n    # Function to calculate extreme value for a given subarray\n    operations = 0\n    while not is_non_decreasing(subarray):\n        # Simulate splitting operation and count\n        # (Implement logic to split elements and count operations)\n        operations += 1\n    return operations\n\ndef is_non_decreasing(array):\n    # Helper function to check if an array is non-decreasing\n    return all(array[i] <= array[i+1] for i in range(len(array) - 1))\n```\n", "- name: \nDynamic Programming Approach\n\n- content: \nUtilize dynamic programming to store intermediate results and optimize the computation of extreme values for subarrays. This approach avoids redundant calculations by reusing previously computed results, aiming to improve efficiency.\nSteps:\n1. Define a DP table where dp[i][j] represents the minimum operations required to make the subarray from index i to j non-decreasing.\n2. Initialize the DP table with base cases: dp[i][i] = 0 for all i, as single-element subarrays are already non-decreasing.\n3. Fill in the DP table using previously computed values, ensuring that each step considers the best way to split elements to achieve a non-decreasing order.\n4. Sum all dp[i][j] values for all valid subarrays.\n5. Return the sum modulo 998244353.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'extreme value'\n    Explanation: The extreme value refers to the minimum number of operations needed to make a subarray non-decreasing by splitting elements.\n\n    'non-decreasing'\n    Explanation: A sequence is non-decreasing if each element is greater than or equal to the previous one.\n\n    'subarray'\n    Explanation: A subarray is a contiguous part of an array, obtained by deleting elements from the beginning and/or end.\n\n# [phrase showing quantity relationship]\n    'minimum number of times': This indicates the least number of operations required to achieve the desired condition (non-decreasing subarray).\n    Implementation: Use dynamic programming to calculate the minimum operations needed for each subarray.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 3 and 4 in the plan should be considered simultaneously. While filling the DP table, we should also sum the values for all valid subarrays to avoid redundant calculations.\n\n# [edge case]\n    Test case with a single element array: [69] = 0\n    Explanation: A single element is already non-decreasing, so no operations are needed.\n\n    Test case with all elements equal: [5, 5, 5] = 0\n    Explanation: All elements are equal, hence the array is non-decreasing without any operations.\n\n    Test case with strictly decreasing array: [5, 4, 3] = 3\n    Explanation: Multiple operations are needed to make it non-decreasing, as shown in the example.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using dynamic programming will naturally handle these cases by considering base cases and filling the DP table accordingly.", "- name: \nDynamic Programming with Prefix Sum Optimization\n\n- content: \nUse dynamic programming combined with prefix sum to efficiently calculate the minimum operations for all subarrays.\n- Define a DP table where dp[i] represents the minimum operations required for subarray starting at index i.\n- Use prefix sums to calculate sums of elements for quick computation of needed splits.\n- For each element, decide whether splitting it results in fewer operations compared to keeping it.\n- Update the DP table accordingly and use it to compute the result for each subarray efficiently.\n- This approach leverages both dynamic programming and prefix sums to minimize redundant calculations, improving performance on large inputs.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'extreme value'\n    Explanation: The extreme value refers to the minimum number of operations needed to make a subarray non-decreasing by splitting elements.\n\n    'non-decreasing'\n    Explanation: A sequence is non-decreasing if each element is greater than or equal to the previous one.\n\n    'subarray'\n    Explanation: A subarray is a contiguous part of an array, obtained by deleting elements from the beginning and/or end.\n\n# [phrase showing quantity relationship]\n    'minimum number of times': This indicates the least number of operations required to achieve the desired condition (non-decreasing array).\n    Implementation: Use dynamic programming to track the minimum operations needed for each subarray.\n\n# [degree adverb]\n    'minimum': Refers to the least number of operations required.\n    Implementation: Use a DP table to store and update the minimum operations for each subarray.\n\n# [code logic]\n    The steps involving dynamic programming and prefix sum calculations should be implemented simultaneously. Specifically, updating the DP table and calculating prefix sums should be done in a single loop to optimize performance.\n\n# [edge case]\n    Case 1: a = [1] = 0\n    Explanation: A single element is already non-decreasing, so no operations are needed.\n\n    Case 2: a = [100000, 99999] = 1\n    Explanation: Only one operation is needed to split the first element to make the array non-decreasing.\n\n    Case 3: a = [1, 2, 3, 4, 5] = 0\n    Explanation: The array is already non-decreasing, so no operations are needed.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using dynamic programming and prefix sums will naturally handle these cases."]
----------
False
----------
0
multi-gen-prompt:
The chef has cooked n dishes yet again: the i-th dish consists of a_i grams of fish and b_i grams of meat. 

Banquet organizers consider two dishes i and j equal if a_i=a_j and b_i=b_j at the same time. They regard these dishes as equivalent when this condition holds true.

The banquet organizers estimate the variety of n dishes as follows. The variety of a set of dishes is equal to the number of different dishes in it. The less variety is, the better.

In order to reduce the variety, a taster was invited. He will eat exactly m_i grams of food from each dish. For each dish, the taster determines separately how much fish and how much meat he will eat. The only condition is that he will eat exactly m_i grams of the i-th dish in total.

Determine how much of what type of food the taster should eat from each dish so that the value of variety is the minimum possible. If there are several correct answers, you may output any of them.

Input

The first line of input data contains an integer t (1 ≤ t ≤ 10^4) — the number of test cases.

Each test case's description is preceded by a blank line. Next comes a line that contains an integer n (1 ≤ n ≤ 2 ⋅ 10^5) — the number of dishes. Then follows n lines, i-th of which contains three integers a_i, b_i and m_i (0 ≤ a_i, b_i ≤ 10^6; 0 ≤ m_i ≤ a_i+b_i) — the mass of fish in i-th dish, the mass of meat in i-th dish and how many grams in total the taster should eat in i-th dish.

The sum of all n values for all input data sets in the test does not exceed 2 ⋅ 10^5.

Output

For each test case, print on the first line the minimum value of variety that can be achieved by eating exactly m_i grams of food (for all i from 1 to n) from a dish i.

Then print n lines that describe a way to do this: the i-th line should contain two integers x_i and y_i (0 ≤ x_i ≤ a_i; 0 ≤ y_i ≤ b_i; x_i+y_i=m_i), where x_i is how many grams of fish the taster should eat from i-th dish, and y_i is how many grams of meat.

If there are several ways to achieve a minimum balance, print any of them.

Example

Input


5

3
10 10 2
9 9 0
10 9 1

2
3 4 1
5 1 2

3
7 2 5
6 5 4
5 5 6

1
13 42 50

5
5 7 12
3 1 4
7 3 7
0 0 0
4 1 5


Output


1
1 1
0 0
1 0
2
0 1
1 1
2
3 2
0 4
1 5
1
8 42
2
5 7
3 1
4 3
0 0
4 1
multi-gen-prompt:
The chef has cooked n dishes yet again: the i-th dish consists of a_i grams of fish and b_i grams of meat. Banquet organizers consider two dishes i and j equal if a_i=a_j and b_i=b_j at the same time. The banquet organizers estimate the variety of n dishes as follows, which is equal to the number of different dishes in it, and the less variety is, the better. In order to reduce the variety, a taster was invited who will eat exactly m_i grams of food from each dish. For each dish, the taster determines separately how much fish and how much meat he will eat, and the only condition is that he will eat exactly m_i grams of the i-th dish in total. Determine how much of what type of food the taster should eat from each dish so that the value of variety is the minimum possible. If there are several correct answers, you may output any of them.

Input

The first line of input data contains an integer t (1 ≤ t ≤ 10^4) — the number of test cases.

Each test case's description is preceded by a blank line. Next comes a line that contains an integer n (1 ≤ n ≤ 2 ⋅ 10^5) — the number of dishes. Then follows n lines, i-th of which contains three integers a_i, b_i and m_i (0 ≤ a_i, b_i ≤ 10^6; 0 ≤ m_i ≤ a_i+b_i) — the mass of fish in i-th dish, the mass of meat in i-th dish and how many grams in total the taster should eat in i-th dish.

The sum of all n values for all input data sets in the test does not exceed 2 ⋅ 10^5.

Output

For each test case, print on the first line the minimum value of variety that can be achieved by eating exactly m_i grams of food (for all i from 1 to n) from a dish i.

Then print n lines that describe a way to do this: the i-th line should contain two integers x_i and y_i (0 ≤ x_i ≤ a_i; 0 ≤ y_i ≤ b_i; x_i+y_i=m_i), where x_i is how many grams of fish the taster should eat from i-th dish, and y_i is how many grams of meat.

If there are several ways to achieve a minimum balance, print any of them.

Example

Input


5

3
10 10 2
9 9 0
10 9 1

2
3 4 1
5 1 2

3
7 2 5
6 5 4
5 5 6

1
13 42 50

5
5 7 12
3 1 4
7 3 7
0 0 0
4 1 5


Output


1
1 1
0 0
1 0
2
0 1
1 1
2
3 2
0 4
1 5
1
8 42
2
5 7
3 1
4 3
0 0
4 1
generating with gpt-4o
----------
['def minimize_variety(t, test_cases):\n    results = []\n    \n    for case in test_cases:\n        n, dishes = case\n        unique_dishes = {}\n        consumption_plan = []\n        \n        for a_i, b_i, m_i in dishes:\n            # Calculate possible range of fish and meat consumption\n            min_fish = max(0, m_i - b_i)\n            max_fish = min(a_i, m_i)\n            \n            # Choose a configuration that minimizes variety\n            # We can choose any valid (x_i, y_i) pair, here we choose min_fish\n            x_i = min_fish\n            y_i = m_i - x_i\n            \n            # Record the configuration after eating\n            new_a_i = a_i - x_i\n            new_b_i = b_i - y_i\n            \n            # Use a tuple to track unique configurations\n            dish_config = (new_a_i, new_b_i)\n            \n            if dish_config not in unique_dishes:\n                unique_dishes[dish_config] = 0\n            unique_dishes[dish_config] += 1\n            \n            # Record the consumption plan\n            consumption_plan.append((x_i, y_i))\n        \n        # The variety is the number of unique configurations\n        variety = len(unique_dishes)\n        results.append((variety, consumption_plan))\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split(\'\\n\')\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        while data[index].strip() == "":\n            index += 1\n        \n        n = int(data[index].strip())\n        index += 1\n        \n        dishes = []\n        for _ in range(n):\n            a_i, b_i, m_i = map(int, data[index].strip().split())\n            dishes.append((a_i, b_i, m_i))\n            index += 1\n        \n        test_cases.append((n, dishes))\n    \n    results = minimize_variety(t, test_cases)\n    \n    for variety, consumption_plan in results:\n        print(variety)\n        for x_i, y_i in consumption_plan:\n            print(x_i, y_i)', 'def minimize_variety(n, dishes):\n    # Dictionary to store the remaining fish and meat after eating\n    remaining_dishes = {}\n    result = []\n\n    for a, b, m in dishes:\n        # Calculate the range of fish and meat that can be eaten\n        min_fish = max(0, m - b)\n        max_fish = min(a, m)\n        \n        # Try to match with existing remaining configurations\n        found = False\n        for fish_eaten in range(min_fish, max_fish + 1):\n            meat_eaten = m - fish_eaten\n            remaining_fish = a - fish_eaten\n            remaining_meat = b - meat_eaten\n            \n            if (remaining_fish, remaining_meat) in remaining_dishes:\n                result.append((fish_eaten, meat_eaten))\n                found = True\n                break\n        \n        if not found:\n            # If no match found, create a new configuration\n            fish_eaten = min_fish\n            meat_eaten = m - fish_eaten\n            remaining_fish = a - fish_eaten\n            remaining_meat = b - meat_eaten\n            \n            result.append((fish_eaten, meat_eaten))\n            remaining_dishes[(remaining_fish, remaining_meat)] = True\n\n    # The variety is the number of unique remaining configurations\n    variety = len(remaining_dishes)\n    return variety, result\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split(\'\\n\')\n    \n    t = int(data[0])\n    index = 1\n    \n    results = []\n    \n    for _ in range(t):\n        if data[index] == \'\':\n            index += 1\n        \n        n = int(data[index])\n        index += 1\n        \n        dishes = []\n        \n        for _ in range(n):\n            a, b, m = map(int, data[index].split())\n            dishes.append((a, b, m))\n            index += 1\n        \n        variety, result = minimize_variety(n, dishes)\n        results.append((variety, result))\n    \n    for variety, result in results:\n        print(variety)\n        for x, y in result:\n            print(x, y)', 'def minimize_variety(t, test_cases):\n    results = []\n    \n    for case in test_cases:\n        n, dishes = case\n        dish_map = {}\n        result = []\n        \n        for a_i, b_i, m_i in dishes:\n            # Calculate possible fish and meat eaten\n            min_fish_eaten = max(0, m_i - b_i)\n            max_fish_eaten = min(a_i, m_i)\n            \n            min_meat_eaten = max(0, m_i - a_i)\n            max_meat_eaten = min(b_i, m_i)\n            \n            # Try to find a configuration that minimizes variety\n            found = False\n            for fish_eaten in range(min_fish_eaten, max_fish_eaten + 1):\n                meat_eaten = m_i - fish_eaten\n                if min_meat_eaten <= meat_eaten <= max_meat_eaten:\n                    remaining_fish = a_i - fish_eaten\n                    remaining_meat = b_i - meat_eaten\n                    dish_key = (remaining_fish, remaining_meat)\n                    \n                    if dish_key in dish_map:\n                        dish_map[dish_key] += 1\n                        result.append((fish_eaten, meat_eaten))\n                        found = True\n                        break\n            \n            if not found:\n                # If no match found, choose any feasible combination\n                fish_eaten = min_fish_eaten\n                meat_eaten = m_i - fish_eaten\n                remaining_fish = a_i - fish_eaten\n                remaining_meat = b_i - meat_eaten\n                dish_key = (remaining_fish, remaining_meat)\n                \n                dish_map[dish_key] = dish_map.get(dish_key, 0) + 1\n                result.append((fish_eaten, meat_eaten))\n        \n        # Calculate variety as the number of unique keys in the hashmap\n        variety = len(dish_map)\n        results.append((variety, result))\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split(\'\\n\')\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        while data[index].strip() == "":\n            index += 1\n        \n        n = int(data[index].strip())\n        index += 1\n        \n        dishes = []\n        for _ in range(n):\n            a_i, b_i, m_i = map(int, data[index].strip().split())\n            dishes.append((a_i, b_i, m_i))\n            index += 1\n        \n        test_cases.append((n, dishes))\n    \n    results = minimize_variety(t, test_cases)\n    \n    for variety, result in results:\n        print(variety)\n        for x_i, y_i in result:\n            print(x_i, y_i)', 'def calculate_reduced_masses(n, dishes):\n    reduced_masses = []\n    for a_i, b_i, m_i in dishes:\n        possible_masses = set()\n        x_min = max(0, m_i - b_i)\n        x_max = min(a_i, m_i)\n        for x in range(x_min, x_max + 1):\n            y = m_i - x\n            reduced_mass = (a_i - x, b_i - y)\n            possible_masses.add(reduced_mass)\n        reduced_masses.append(possible_masses)\n    return reduced_masses\n\ndef minimize_variety(t, test_cases):\n    results = []\n    \n    for case in test_cases:\n        n, dishes = case\n        reduced_masses = calculate_reduced_masses(n, dishes)\n        \n        # Count frequency of each reduced mass\n        mass_count = {}\n        for masses in reduced_masses:\n            for mass in masses:\n                if mass not in mass_count:\n                    mass_count[mass] = 0\n                mass_count[mass] += 1\n        \n        chosen_eats = []\n        used_masses = set()\n        \n        for i in range(n):\n            best_x, best_y = 0, 0\n            best_mass = None\n            max_frequency = -1\n            \n            a_i, b_i, m_i = dishes[i]\n            x_min = max(0, m_i - b_i)\n            x_max = min(a_i, m_i)\n            \n            for x in range(x_min, x_max + 1):\n                y = m_i - x\n                reduced_mass = (a_i - x, b_i - y)\n                \n                if reduced_mass in mass_count and mass_count[reduced_mass] > max_frequency:\n                    max_frequency = mass_count[reduced_mass]\n                    best_x, best_y = x, y\n                    best_mass = reduced_mass\n            \n            chosen_eats.append((best_x, best_y))\n            if best_mass:\n                used_masses.add(best_mass)\n        \n        min_variety = len(used_masses)\n        results.append((min_variety, chosen_eats))\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split("\\n")\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        while data[index].strip() == "":\n            index += 1\n        \n        n = int(data[index].strip())\n        index += 1\n        dishes = []\n        \n        for _ in range(n):\n            a_i, b_i, m_i = map(int, data[index].strip().split())\n            dishes.append((a_i, b_i, m_i))\n            index += 1\n        \n        test_cases.append((n, dishes))\n    \n    results = minimize_variety(t, test_cases)\n    \n    for min_variety, chosen_eats in results:\n        print(min_variety)\n        for x, y in chosen_eats:\n            print(x, y)', 'def calculate_minimum_variety(n, dishes):\n    # Dictionary to store the frequency of each possible dish configuration\n    dish_frequency = {}\n\n    # List to store the chosen configuration for each dish\n    chosen_configurations = []\n\n    for a_i, b_i, m_i in dishes:\n        # Calculate all possible pairs (remaining fish, remaining meat)\n        possible_pairs = []\n        for x_i in range(max(0, m_i - b_i), min(a_i, m_i) + 1):\n            y_i = m_i - x_i\n            if 0 <= y_i <= b_i:\n                possible_pairs.append((a_i - x_i, b_i - y_i))\n\n        # Update frequency dictionary for all possible pairs\n        for pair in possible_pairs:\n            if pair in dish_frequency:\n                dish_frequency[pair] += 1\n            else:\n                dish_frequency[pair] = 1\n\n    # Choose the pair with the maximum frequency for each dish\n    for a_i, b_i, m_i in dishes:\n        possible_pairs = []\n        for x_i in range(max(0, m_i - b_i), min(a_i, m_i) + 1):\n            y_i = m_i - x_i\n            if 0 <= y_i <= b_i:\n                possible_pairs.append((a_i - x_i, b_i - y_i))\n\n        max_pair = max(possible_pairs, key=lambda p: dish_frequency[p])\n        chosen_configurations.append((a_i - max_pair[0], b_i - max_pair[1]))\n\n    # Determine the minimum variety achievable\n    min_variety = len(set(chosen_configurations))\n\n    return min_variety, chosen_configurations\n\ndef process_test_cases(t, test_cases):\n    results = []\n    for n, dishes in test_cases:\n        min_variety, configurations = calculate_minimum_variety(n, dishes)\n        results.append((min_variety, configurations))\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split(\'\\n\')\n\n    t = int(data[0].strip())\n    index = 1\n    test_cases = []\n\n    for _ in range(t):\n        while data[index].strip() == "":\n            index += 1\n        n = int(data[index].strip())\n        index += 1\n        dishes = []\n        for _ in range(n):\n            a_i, b_i, m_i = map(int, data[index].strip().split())\n            dishes.append((a_i, b_i, m_i))\n            index += 1\n        test_cases.append((n, dishes))\n\n    results = process_test_cases(t, test_cases)\n\n    for min_variety, configurations in results:\n        print(min_variety)\n        for x_i, y_i in configurations:\n            print(x_i, y_i)', 'def minimize_variety(n, dishes):\n    # Dictionary to store the final configuration\n    final_config = []\n    \n    # Dictionary to count unique configurations\n    unique_configs = {}\n\n    for a, b, m in dishes:\n        # Calculate possible x and y\n        min_x = max(0, m - b)\n        max_x = min(a, m)\n        \n        best_x = min_x\n        best_y = m - best_x\n        best_config = (a - best_x, b - best_y)\n        \n        # Iterate over all possible x values to find the best configuration\n        for x in range(min_x, max_x + 1):\n            y = m - x\n            config = (a - x, b - y)\n            \n            # Count the occurrence of each configuration\n            if config not in unique_configs:\n                unique_configs[config] = 0\n            unique_configs[config] += 1\n            \n            # Choose the (x, y) pair that results in the most common config\n            if unique_configs[config] > unique_configs.get(best_config, 0):\n                best_x = x\n                best_y = y\n                best_config = config\n\n        # Store the best configuration for this dish\n        final_config.append((best_x, best_y))\n\n    # The variety is the number of unique configurations\n    variety = len(set((a - x, b - y) for (x, y), (a, b, _) in zip(final_config, dishes)))\n    \n    return variety, final_config\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split(\'\\n\')\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        if data[index] == \'\':\n            index += 1\n        \n        n = int(data[index])\n        index += 1\n        \n        dishes = []\n        \n        for _ in range(n):\n            a, b, m = map(int, data[index].split())\n            dishes.append((a, b, m))\n            index += 1\n        \n        variety, config = minimize_variety(n, dishes)\n        \n        results.append(f"{variety}")\n        for x, y in config:\n            results.append(f"{x} {y}")\n    \n    print("\\n".join(results))', 'def minimize_variety(t, test_cases):\n    results = []\n    \n    for case in test_cases:\n        n, dishes = case\n        unique_dishes = {}\n        result = []\n        \n        for a_i, b_i, m_i in dishes:\n            # Try to find the best way to eat m_i grams\n            best_pair = None\n            \n            for x_i in range(max(0, m_i - b_i), min(a_i, m_i) + 1):\n                y_i = m_i - x_i\n                new_a = a_i - x_i\n                new_b = b_i - y_i\n                \n                if (new_a, new_b) in unique_dishes:\n                    best_pair = (x_i, y_i)\n                    break\n            \n            if best_pair is None:\n                # If no existing pair found, create a new one\n                x_i = max(0, m_i - b_i)\n                y_i = m_i - x_i\n                new_a = a_i - x_i\n                new_b = b_i - y_i\n                unique_dishes[(new_a, new_b)] = True\n                best_pair = (x_i, y_i)\n            \n            result.append(best_pair)\n        \n        results.append((len(unique_dishes), result))\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split(\'\\n\')\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        while data[index].strip() == "":\n            index += 1\n        \n        n = int(data[index].strip())\n        index += 1\n        dishes = []\n        \n        for _ in range(n):\n            a_i, b_i, m_i = map(int, data[index].strip().split())\n            dishes.append((a_i, b_i, m_i))\n            index += 1\n        \n        test_cases.append((n, dishes))\n    \n    results = minimize_variety(t, test_cases)\n    \n    for variety, result in results:\n        print(variety)\n        for x_i, y_i in result:\n            print(x_i, y_i)', 'def minimize_variety(t, test_cases):\n    results = []\n    \n    for case in test_cases:\n        n, dishes = case\n        composition_count = {}\n        eating_plan = []\n        \n        for a_i, b_i, m_i in dishes:\n            best_composition = None\n            max_frequency = -1\n            \n            for x in range(max(0, m_i - b_i), min(a_i, m_i) + 1):\n                y = m_i - x\n                remaining_fish = a_i - x\n                remaining_meat = b_i - y\n                composition = (remaining_fish, remaining_meat)\n                \n                if composition in composition_count:\n                    frequency = composition_count[composition] + 1\n                else:\n                    frequency = 1\n                \n                if frequency > max_frequency:\n                    max_frequency = frequency\n                    best_composition = (x, y)\n            \n            x, y = best_composition\n            eating_plan.append((x, y))\n            \n            remaining_fish = a_i - x\n            remaining_meat = b_i - y\n            composition = (remaining_fish, remaining_meat)\n            \n            if composition in composition_count:\n                composition_count[composition] += 1\n            else:\n                composition_count[composition] = 1\n        \n        min_variety = len(composition_count)\n        results.append((min_variety, eating_plan))\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split("\\n")\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        while data[index].strip() == "":\n            index += 1\n        \n        n = int(data[index].strip())\n        index += 1\n        dishes = []\n        \n        for _ in range(n):\n            a_i, b_i, m_i = map(int, data[index].strip().split())\n            dishes.append((a_i, b_i, m_i))\n            index += 1\n        \n        test_cases.append((n, dishes))\n    \n    results = minimize_variety(t, test_cases)\n    \n    for result in results:\n        min_variety, eating_plan = result\n        print(min_variety)\n        for x, y in eating_plan:\n            print(x, y)', 'def minimize_variety(t, test_cases):\n    results = []\n    \n    for case in test_cases:\n        n, dishes = case\n        configurations = []\n        \n        for a_i, b_i, m_i in dishes:\n            # Generate all valid configurations (x_i, y_i)\n            possible_configs = []\n            for x_i in range(max(0, m_i - b_i), min(m_i, a_i) + 1):\n                y_i = m_i - x_i\n                if 0 <= y_i <= b_i:\n                    possible_configs.append((x_i, y_i))\n            \n            configurations.append(possible_configs)\n        \n        # Use a dictionary to track occurrences of adjusted dish types\n        dish_count = {}\n        \n        for i in range(n):\n            for x_i, y_i in configurations[i]:\n                a_prime = dishes[i][0] - x_i\n                b_prime = dishes[i][1] - y_i\n                dish_type = (a_prime, b_prime)\n                if dish_type not in dish_count:\n                    dish_count[dish_type] = 0\n                dish_count[dish_type] += 1\n        \n        # Choose the configuration that results in the most common dish type\n        chosen_configs = []\n        unique_dishes = set()\n        \n        for i in range(n):\n            best_config = None\n            best_count = -1\n            \n            for x_i, y_i in configurations[i]:\n                a_prime = dishes[i][0] - x_i\n                b_prime = dishes[i][1] - y_i\n                dish_type = (a_prime, b_prime)\n                \n                if dish_count[dish_type] > best_count:\n                    best_count = dish_count[dish_type]\n                    best_config = (x_i, y_i)\n            \n            chosen_configs.append(best_config)\n            unique_dishes.add((dishes[i][0] - best_config[0], dishes[i][1] - best_config[1]))\n        \n        # Append the result for this test case\n        results.append((len(unique_dishes), chosen_configs))\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split(\'\\n\')\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        while data[index].strip() == "":\n            index += 1\n        \n        n = int(data[index].strip())\n        index += 1\n        dishes = []\n        \n        for _ in range(n):\n            a_i, b_i, m_i = map(int, data[index].strip().split())\n            dishes.append((a_i, b_i, m_i))\n            index += 1\n        \n        test_cases.append((n, dishes))\n    \n    results = minimize_variety(t, test_cases)\n    \n    for variety, configs in results:\n        print(variety)\n        for x_i, y_i in configs:\n            print(x_i, y_i)', 'def preprocess_dish(a, b, m):\n    # Generate all possible configurations after eating m grams\n    configurations = []\n    for x in range(max(0, m - b), min(a, m) + 1):\n        y = m - x\n        configurations.append((a - x, b - y))\n    return configurations\n\ndef minimize_variety(n, dishes):\n    # Dictionary to track the frequency of each configuration\n    config_count = {}\n    \n    # List to store all possible configurations for each dish\n    all_configurations = []\n    \n    for a, b, m in dishes:\n        configurations = preprocess_dish(a, b, m)\n        all_configurations.append(configurations)\n        for config in configurations:\n            if config in config_count:\n                config_count[config] += 1\n            else:\n                config_count[config] = 1\n    \n    # Find the configuration with the maximum frequency\n    max_frequency = max(config_count.values())\n    \n    # Calculate minimum variety\n    min_variety = n - max_frequency\n    \n    # Find one valid way to achieve this minimum variety\n    result = []\n    \n    # Iterate over each dish and select a configuration that contributes to the minimum variety\n    for configurations in all_configurations:\n        selected_config = None\n        for config in configurations:\n            if config_count[config] == max_frequency:\n                selected_config = config\n                break\n        \n        if selected_config is None:\n            selected_config = configurations[0]\n        \n        x = dishes[all_configurations.index(configurations)][0] - selected_config[0]\n        y = dishes[all_configurations.index(configurations)][1] - selected_config[1]\n        result.append((x, y))\n    \n    return min_variety, result\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().strip().split(\'\\n\')\n    \n    t = int(data[0])\n    index = 1\n    \n    results = []\n    \n    for _ in range(t):\n        if data[index] == \'\':\n            index += 1\n        \n        n = int(data[index])\n        index += 1\n        \n        dishes = []\n        for _ in range(n):\n            a, b, m = map(int, data[index].split())\n            dishes.append((a, b, m))\n            index += 1\n        \n        min_variety, result = minimize_variety(n, dishes)\n        results.append((min_variety, result))\n    \n    for min_variety, result in results:\n        print(min_variety)\n        for x, y in result:\n            print(x, y)']
----------
['- name: \nDynamic Programming for Optimal Configuration\n\n- content: \n- Consider dynamic programming to determine optimal combinations of fish and meat consumption for minimizing unique configurations.\n- Define a DP state where dp[i][f] represents the minimum variety achievable using the first i dishes, with f grams of fish eaten from the i-th dish.\n- Transition between states by evaluating feasible fish-meat combinations for each dish while maintaining total m_i grams eaten.\n- Track and update minimum variety for each configuration.\n- After processing all dishes, backtrack to derive specific combinations for fish and meat consumption that result in minimum variety.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'variety\'\n    Explanation: In the context of this requirement, "variety" refers to the number of different dishes based on their fish and meat composition. The goal is to minimize this variety by adjusting the amount of fish and meat eaten from each dish.\n\n    \'equal dishes\'\n    Explanation: Two dishes are considered equal if they have the same amount of fish and meat after the taster has eaten from them.\n\n# [phrase showing quantity relationship]\n    \'exactly m_i grams\': This means that the taster must consume a total of m_i grams from each dish, combining both fish and meat. In code, this can be implemented by ensuring that for each dish, the sum of fish and meat consumed equals m_i.\n\n# [degree adverb] \n    \'minimum\': This indicates that the goal is to achieve the smallest possible variety of dishes. In code, this can be implemented by using a strategy (like dynamic programming) to track and minimize the number of unique dish configurations.\n\n# [code logic]\n    The steps in the plan suggest using dynamic programming to evaluate combinations of fish and meat consumption. The transition between states should be considered simultaneously for each dish to ensure that the total grams eaten equals m_i while minimizing variety.\n\n# [edge case] \n    1. Input: 1\n       1\n       0 0 0\n       Output: 0\n       Explanation: With no fish or meat in the dish and no grams to eat, the variety is already minimized at 0.\n       \n    2. Input: 1\n       1\n       10 10 20\n       Output: 1\n       Explanation: The taster must eat all available grams, resulting in one unique configuration.\n       \n    3. Input: 1\n       2\n       5 5 5\n       5 5 5\n       Output: 1\n       Explanation: By eating all from one type (either fish or meat) in both dishes, they become identical, minimizing variety to 1.\n\n# [extra code for edge case]\n    We need extra code to handle edge cases where m_i is zero or when a_i + b_i equals m_i.\n    \n    ```python\n    for i in range(n):\n        a, b, m = dishes[i]\n        if m == 0:\n            x, y = 0, 0\n        elif a + b == m:\n            x, y = a, b\n        else:\n            # Implement logic to minimize variety\n            # Example logic:\n            x = min(a, m)\n            y = m - x\n        # Store or print x, y for each dish\n    ```', '- name: \nDynamic Programming with State Compression\n\n- content: \nThis approach uses dynamic programming to explore all possible states of dishes after consumption.\n\nSteps:\n1. Define a DP table where dp[i][f][m] indicates whether it\'s possible to have exactly \'f\' grams of fish and \'m\' grams of meat left after processing up to dish i.\n2. Initialize dp[0][a_0][b_0] as true since initially, we have all grams as they are.\n3. For each dish i from 1 to n:\n   - Iterate over possible fish remaining and meat remaining quantities based on m_i restrictions.\n   - Update dp[i][f\'][m\'] based on dp[i-1][f][m] if transition is valid (the taster can eat m_i grams).\n   - Transition involves checking if f\' <= a_i and m\' <= b_i.\n4. After processing all dishes, identify minimal variety by counting unique valid states in the DP table.\n5. Backtrack through DP table to determine distribution of eaten fish and meat for each dish to achieve minimum variety.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'variety\'\n    Explanation: In the context of this requirement, "variety" refers to the number of different dishes based on their remaining fish and meat quantities after the taster has eaten. The goal is to minimize this variety.\n\n    \'equal dishes\'\n    Explanation: Two dishes are considered equal if they have the same amount of fish and meat remaining after the taster has eaten.\n\n# [phrase showing quantity relationship]\n    \'exactly m_i grams\'\n    Explanation: The taster must eat exactly m_i grams from each dish, which is a strict requirement. In code, this means ensuring that the sum of fish and meat eaten equals m_i for each dish.\n\n# [degree adverb]\n    \'minimum\'\n    Explanation: The requirement is to achieve the minimum possible variety of dishes. This means finding a way to distribute the eating such that the number of unique remaining dish states is minimized.\n\n# [code logic]\n    Steps 3 and 4 in the plan should be considered simultaneously. While iterating over possible fish and meat quantities, both the transition check and DP table update should occur in the same loop to ensure valid states are tracked correctly.\n\n# [edge case]\n    Case 1: n = 1, a_1 = 0, b_1 = 0, m_1 = 0\n    Expected output: 1\n    Explanation: With no fish or meat and no grams to eat, there\'s only one possible state, so the variety is 1.\n\n    Case 2: n = 2, a_1 = 5, b_1 = 5, m_1 = 10; a_2 = 5, b_2 = 5, m_2 = 10\n    Expected output: 1\n    Explanation: Both dishes can be made identical by eating all available grams, resulting in zero variety.\n\n    Case 3: n = 3, a_1 = 3, b_1 = 3, m_1 = 3; a_2 = 3, b_2 = 3, m_2 = 3; a_3 = 3, b_3 = 3, m_3 = 3\n    Expected output: 1\n    Explanation: Each dish can be made identical by eating all available grams in any combination that sums to m_i.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if n == 1:\n            return [(0, 0)] * n\n        # Additional logic to ensure that when all dishes are identical in terms of a_i and b_i,\n        # they are processed to have identical remaining states.\n        # This involves checking if all dishes can be reduced to a common state.\n        (other code)', '- name: \nTwo-pointer Method for Dish Matching\n- content: \n- Sort the list of dishes by the sum of fish and meat they have after the taster eats.\n- Use a two-pointer approach to find pairs of dishes that can be made identical by choosing appropriate (x_i, y_i) values.\n- For each pair of dishes, attempt to match their remaining fish and meat by adjusting how much of each component is eaten.\n- When a match is found, continue to the next unmatched dish with one of the pointers.\n- Keep track of all the matches found to minimize variety.\n- Output the minimum variety and a valid combination of (x_i, y_i) for each dish.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'variety\'\n    Explanation: In the context of this requirement, "variety" refers to the number of distinct dishes based on their fish and meat content after the taster has eaten. The goal is to minimize this variety by making as many dishes identical as possible.\n\n    \'equal\'\n    Explanation: Two dishes are considered equal if they have the same amount of fish and meat after the taster has eaten from them.\n\n# [phrase showing quantity relationship]\n    \'exactly m_i grams\'\n    Explanation: The taster must eat exactly m_i grams from each dish, which is a fixed quantity. This means that the sum of the fish and meat eaten from each dish must equal m_i. In code, this can be implemented by ensuring that for each dish, x_i + y_i = m_i.\n\n# [degree adverb]\n    \'minimum\'\n    Explanation: The requirement is to achieve the minimum possible variety, meaning the smallest number of distinct dishes. This can be implemented by finding combinations of (x_i, y_i) that make as many dishes identical as possible.\n\n# [code logic]\n    The steps involving sorting the dishes and using a two-pointer approach should be considered simultaneously. Sorting helps in efficiently finding pairs of dishes that can be made identical, and the two-pointer technique is used to iterate through these sorted dishes to find matches.\n\n# [edge case]\n    Edge Case 1: n = 1, a_1 = 0, b_1 = 0, m_1 = 0\n    Expected Output: 1\n    Explanation: With only one dish and no grams to eat, the variety is trivially 1 since there\'s only one dish.\n\n    Edge Case 2: n = 2, a_1 = 0, b_1 = 0, m_1 = 0; a_2 = 0, b_2 = 0, m_2 = 0\n    Expected Output: 1\n    Explanation: Both dishes are already identical with no grams to eat, so the variety is minimized at 1.\n\n    Edge Case 3: n = 2, a_1 = 5, b_1 = 5, m_1 = 10; a_2 = 5, b_2 = 5, m_2 = 10\n    Expected Output: 1\n    Explanation: Both dishes can be made identical by eating all available grams (5 fish and 5 meat), resulting in a variety of 1.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of sorting and using a two-pointer approach inherently handles these cases by ensuring that all possible combinations are considered to minimize variety.', "- name: \nHash Map Based Grouping\n\n- content: \nTo solve the problem, we can use a hash map to group dishes based on their reduced mass after the taster eats m_i grams. The aim is to achieve the minimum possible variety by having as many dishes as possible share the same reduced mass.\nSteps:\n1. Initialize a hash map to store reduced dish masses as keys and their count as values.\n2. For each test case, iterate over the dishes. For each dish, calculate possible reduced masses by subtracting combinations of fish and meat such that the total grams eaten equals m_i.\n3. For each dish, find the combination that matches the mass of an existing group in the hash map or creates a new group if no match is found.\n4. Track the maximum count of dishes in any group, which represents the minimum variety.\n5. Output the results: the number of unique reduced masses (minimum variety) and the grams of fish and meat eaten for each dish according to the chosen combination.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'variety'\n    Explanation: In this context, variety refers to the number of different dishes after the taster has eaten a specified amount from each dish. The goal is to minimize this variety by making as many dishes as possible identical in terms of remaining fish and meat.\n\n    'reduced mass'\n    Explanation: This refers to the remaining mass of fish and meat in a dish after the taster has eaten m_i grams. The task is to find combinations of fish and meat eaten that result in the same reduced mass for multiple dishes.\n\n# [phrase showing quantity relationship]\n    'exactly m_i grams'\n    Explanation: The taster must eat exactly m_i grams from each dish, which means the sum of fish and meat eaten must equal m_i. In code, this can be implemented by ensuring x_i + y_i = m_i for each dish.\n\n# [degree adverb]\n    'minimum'\n    Explanation: The goal is to achieve the minimum possible variety, meaning the smallest number of unique dishes after the taster has eaten. This can be implemented by finding the maximum number of dishes that can be grouped together with the same reduced mass.\n\n# [code logic]\n    Steps 2 and 3 should be considered simultaneously. For each dish, calculate possible reduced masses and find or create a group in the hash map. This can be done in a single loop over the dishes, where you calculate combinations and update the hash map accordingly.\n\n# [edge case]\n    Case 1: n = 1, a_1 = 0, b_1 = 0, m_1 = 0\n    Expected output: 1\n    Explanation: With only one dish and no grams to eat, the variety is trivially 1.\n\n    Case 2: n = 2, a_1 = 5, b_1 = 5, m_1 = 10; a_2 = 5, b_2 = 5, m_2 = 10\n    Expected output: 1\n    Explanation: Both dishes are identical and the taster eats all available grams, resulting in zero remaining mass for both dishes.\n\n    Case 3: n = 3, a_1 = 3, b_1 = 3, m_1 = 3; a_2 = 3, b_2 = 3, m_2 = 3; a_3 = 3, b_3 = 3, m_3 = 0\n    Expected output: 2\n    Explanation: The first two dishes can be made identical by eating all grams from one type (either fish or meat), but the third dish remains unchanged, resulting in two unique dishes.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of grouping by reduced mass using a hash map will naturally handle these cases by ensuring that identical dishes are grouped together.", '- name: \nBrute Force with Constraint Checking\n\n- content: \nThis approach explores all possible combinations by brute force within constraints:\n- For each test case, initialize a set to store unique dishes after eating.\n- For each dish i, calculate possible (x_i, y_i) combinations:\n  - Iterate over all possible x_i from max(0, a_i - m_i) to min(a_i, m_i).\n  - Compute y_i = m_i - x_i.\n  - Validate that 0 ≤ x_i ≤ a_i and 0 ≤ y_i ≤ b_i.\n  - Adjust the dish composition to (a_i - x_i, b_i - y_i) and add it to the set.\n- The size of the set will represent the minimum variety.\n- For each dish, output any valid (x_i, y_i) pair.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'variety\'\n    Explanation: In the context of this requirement, "variety" refers to the number of distinct dishes after the taster has eaten a specified amount from each dish. The goal is to minimize this variety by making dishes as similar as possible.\n\n    \'equal\' and \'equivalent\'\n    Explanation: Two dishes are considered equal or equivalent if they have the same amount of fish and meat after the taster has eaten from them.\n\n# [phrase showing quantity relationship]\n    \'exactly m_i grams\'\n    Explanation: The taster must eat exactly m_i grams from each dish, which is a strict requirement. In code, this means ensuring that the sum of x_i (fish eaten) and y_i (meat eaten) equals m_i for each dish.\n\n# [degree adverb]\n    \'minimum\'\n    Explanation: The requirement is to achieve the minimum possible variety, meaning the smallest number of distinct dishes after the taster has eaten. In code, this involves finding combinations that result in the least number of unique dishes.\n\n# [code logic]\n    The steps for calculating possible (x_i, y_i) combinations and validating them should be implemented simultaneously. This involves iterating over possible x_i values, calculating y_i, and checking constraints in one loop to ensure efficiency.\n\n# [edge case]\n    Case 1: n = 1, a_1 = 0, b_1 = 0, m_1 = 0\n    Expected output: 1\n    Explanation: With only one dish and no grams to eat, the variety is already minimized at 1.\n\n    Case 2: n = 2, a_1 = 5, b_1 = 5, m_1 = 10; a_2 = 5, b_2 = 5, m_2 = 10\n    Expected output: 1\n    Explanation: Both dishes can be made identical by eating all available grams, resulting in a variety of 1.\n\n    Case 3: n = 3, a_1 = 10, b_1 = 0, m_1 = 5; a_2 = 0, b_2 = 10, m_2 = 5; a_3 = 5, b_3 = 5, m_3 = 5\n    Expected output: 3\n    Explanation: Each dish has distinct initial compositions that cannot be made identical with the given m_i values.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating over possible (x_i, y_i) combinations and checking constraints will naturally handle these scenarios.', "- name: \nDynamic Programming Approach\n\n- content: \n- Use a dynamic programming table to determine possible outcomes for each dish with different consumption strategies.\n- The state `dp[i][x]` represents whether it is possible to have `x` grams of fish eaten from the i-th dish.\n- Transition states by checking feasible `(x, y)` pairs such that `x + y = m_i` and within bounds.\n- After filling the DP table for all dishes, analyze the states to find the configuration set with minimal distinct entries.\n- Backtrack from the DP table to output one valid configuration for each dish aligning with minimum variety outcome.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'variety'\n    Explanation: In this context, variety refers to the number of distinct dishes after the taster has eaten a specified amount from each dish. The goal is to minimize this variety by making dishes as similar as possible.\n\n    'equal' and 'equivalent'\n    Explanation: Two dishes are considered equal if they have the same amount of fish and meat. They are equivalent when this condition holds true, which affects how we calculate the variety.\n\n# [phrase showing quantity relationship]\n    'exactly m_i grams'\n    Explanation: The taster must eat exactly m_i grams from each dish, which means the sum of fish and meat eaten from a dish must equal m_i. In code, this can be implemented by ensuring that for each dish, x_i + y_i = m_i.\n\n# [degree adverb]\n    'minimum'\n    Explanation: The requirement is to achieve the minimum possible variety, meaning the smallest number of distinct dishes after the taster has eaten. This can be implemented by finding a configuration that results in the least number of unique (a_i - x_i, b_i - y_i) pairs.\n\n# [code logic]\n    The steps involving checking feasible `(x, y)` pairs such that `x + y = m_i` and analyzing states to find minimal distinct entries should be considered simultaneously. This involves iterating over possible values of x and calculating y as m_i - x, then checking if this configuration minimizes variety.\n\n# [edge case]\n    Case 1: n = 1, a_1 = 0, b_1 = 0, m_1 = 0\n    Expected output: 1\n    Explanation: With only one dish and no grams to eat, the variety is trivially 1 since no changes occur.\n\n    Case 2: n = 2, a_1 = 5, b_1 = 5, m_1 = 10; a_2 = 5, b_2 = 5, m_2 = 10\n    Expected output: 1\n    Explanation: Both dishes are identical and the taster eats all available grams, resulting in zero remaining grams for both dishes, making them identical.\n\n    Case 3: n = 3, a_1 = 10, b_1 = 0, m_1 = 5; a_2 = 0, b_2 = 10, m_2 = 5; a_3 = 5, b_3 = 5, m_3 = 5\n    Expected output: 3\n    Explanation: Each dish has distinct remaining grams after the taster eats, resulting in maximum variety.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n    Specifically, we need to ensure that when n=1 and m_i=0 for all i, the output is correctly handled as a single unique dish.\n    \n```python\ndef handle_edge_cases(n, dishes):\n    if n == 1 and all(m == 0 for _, _, m in dishes):\n        return [(0, 0) for _ in range(n)], 1\n    # Other logic to handle general cases\n```", "- name: \nDirect Simulation with Priority Choices\n\n- content: \n- For each dish, calculate the optimal consumption of fish and meat by considering combinations that either balance the remaining quantities or reduce to a common state seen in other dishes.\n- Iterate through each dish, for each possible way to eat m_i grams (x, y), such that 0 <= x <= a_i and 0 <= y <= b_i, and x + y = m_i.\n- Track the resulting (a_i - x, b_i - y) for each dish in a set to determine unique outcomes.\n- If multiple ways yield the same minimal unique outcomes, any of those configurations can be chosen for output.\n- Use a greedy approach to prioritize configurations where potential future dishes will match existing ones.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'variety'\n    Explanation: In this context, variety refers to the number of different dishes after the taster has eaten a specified amount from each dish. The goal is to minimize this variety by making dishes as similar as possible.\n\n    'equal dishes'\n    Explanation: Two dishes are considered equal if they have the same amount of fish and meat remaining after the taster has eaten.\n\n# [phrase showing quantity relationship]\n    'exactly m_i grams'\n    Explanation: The taster must eat exactly m_i grams from each dish, which means the sum of fish and meat eaten from each dish must equal m_i. This can be implemented in code by ensuring that for each dish, x_i + y_i = m_i, where x_i is the grams of fish eaten and y_i is the grams of meat eaten.\n\n# [degree adverb]\n    'minimum'\n    Explanation: The goal is to achieve the minimum possible variety, meaning the smallest number of unique dishes after the taster has eaten. This can be implemented by tracking unique combinations of remaining fish and meat and choosing configurations that minimize this count.\n\n# [code logic]\n    The steps of calculating optimal consumption and tracking unique outcomes should be considered simultaneously. This involves iterating through each dish and evaluating all possible (x, y) combinations that satisfy the condition x + y = m_i, while simultaneously updating a set or dictionary to track unique outcomes.\n\n# [edge case]\n    1. Input: 1\n       1\n       0 0 0\n       Output: \n       1\n       0 0\n       Explanation: With no fish or meat to begin with and no grams to eat, the variety remains 1 with no change.\n       \n    2. Input: 1\n       1\n       10 10 20\n       Output:\n       1\n       10 10\n       Explanation: The taster eats all available fish and meat, leaving no variety.\n       \n    3. Input: 1\n       2\n       5 5 5\n       5 5 5\n       Output:\n       1\n       5 0\n       5 0\n       Explanation: By eating all fish from both dishes, they become identical, minimizing variety to 1.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating through possible (x, y) combinations and tracking unique outcomes will naturally handle these scenarios.", '- name: \nHash Map for Tracking and Reducing Dish Variety\n\n- content: \nThis approach focuses on using a hash map to efficiently track and reduce the dish variety by keeping track of possible resulting dish configurations.\n\nSteps:\n1. Initialize a hash map to store the frequency of each resulting dish configuration.\n2. For each dish, calculate all possible (x_i, y_i) pairs where x_i + y_i = m_i.\n3. For each pair, compute the resulting (a_i - x_i, b_i - y_i).\n4. Insert these results into the hash map and update their frequency count.\n5. Choose a configuration that maximizes existing frequencies in the map to reduce variety.\n6. After processing all dishes, determine the number of unique configurations in the map to find the minimum variety.\n7. Print the minimum variety and chosen (x_i, y_i) for each dish.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'variety\'\n    Explanation: In the context of this requirement, "variety" refers to the number of different dish configurations after the taster has eaten a specified amount from each dish. The goal is to minimize this variety.\n\n    \'equal dishes\'\n    Explanation: Two dishes are considered equal if they have the same amount of fish and meat remaining after the taster has eaten.\n\n# [phrase showing quantity relationship]\n    \'exactly m_i grams\'\n    Explanation: This means that for each dish, the sum of fish and meat eaten by the taster must be exactly m_i grams. In code, this can be implemented by ensuring that for each dish, x_i + y_i = m_i.\n\n# [degree adverb]\n    \'minimum\'\n    Explanation: The requirement is to achieve the minimum possible variety of dishes. This means finding a configuration that results in the fewest number of unique dish types after the taster has eaten.\n\n# [code logic]\n    Steps 2-5 should be considered simultaneously:\n    - For each dish, calculate all possible (x_i, y_i) pairs where x_i + y_i = m_i.\n    - Compute the resulting (a_i - x_i, b_i - y_i) for each pair.\n    - Insert these results into the hash map and update their frequency count.\n    - Choose a configuration that maximizes existing frequencies in the map to reduce variety.\n    These steps can be implemented in a single loop iterating over each dish.\n\n# [edge case]\n    Case 1: n = 1, a_1 = 0, b_1 = 0, m_1 = 0\n    Expected output: 1\n    Explanation: With no fish or meat and no grams to eat, there\'s only one configuration (0, 0).\n\n    Case 2: n = 2, a_1 = 5, b_1 = 5, m_1 = 10; a_2 = 5, b_2 = 5, m_2 = 10\n    Expected output: 1\n    Explanation: Both dishes can be made identical by eating all available grams, resulting in (0, 0) for both.\n\n    Case 3: n = 3, a_1 = 10, b_1 = 10, m_1 = 0; a_2 = 10, b_2 = 10, m_2 = 0; a_3 = 10, b_3 = 10, m_3 = 0\n    Expected output: 1\n    Explanation: No grams are eaten from any dish, so all remain identical with (10, 10).\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of calculating possible configurations and choosing the one that maximizes frequency will naturally handle these cases.', "- name: \nSimulation: Exhaustive Search with Constraints\n\n- content: \n- For each test case, initialize a list to store all possible configurations for each dish after consuming m_i grams.\n- For each dish, generate all valid configurations (x_i, y_i) such that x_i + y_i = m_i, 0 <= x_i <= a_i, and 0 <= y_i <= b_i.\n- For each configuration, store it in a list with tuples representing (a'_i = a_i - x_i, b'_i = b_i - y_i).\n- Use a set to track all unique tuples across all dishes to determine how many different types of adjusted dishes exist.\n- Choose configurations that minimize the number of unique tuples (adjusted dish types).\n- Iterate through all configurations and select one that minimizes the variety effectively.\n- Output the number of unique dish types and the distribution of fish and meat eaten for each dish.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'variety'\n    Explanation: In the requirement, variety refers to the number of different dishes after the taster has eaten a specified amount from each dish. The goal is to minimize this variety.\n\n# [phrase showing quantity relationship]\n    'exactly m_i grams': means that the taster must eat precisely m_i grams from each dish, which is a constraint that must be satisfied in the code.\n    Implementation: Ensure that for each dish, the sum of fish and meat eaten equals m_i.\n\n# [degree adverb] \n    'minimum': means that the goal is to achieve the smallest possible variety of dishes after the taster has eaten.\n    Implementation: Use a method to track and minimize the number of unique dish configurations.\n\n# [code logic]\n    The steps involving generating configurations and tracking unique tuples should be considered simultaneously.\n    Explanation: Generating all valid configurations and tracking them in a set can be done in one loop for efficiency.\n\n# [edge case] \n    Test case with all dishes having m_i = 0 = 0\n    Explanation: Since no grams are eaten, the variety remains unchanged, and the output should reflect the original dish configuration.\n    \n    Test case with n = 1 and m_i = a_i + b_i = 1\n    Explanation: The taster eats all available grams, resulting in only one possible configuration, minimizing variety to 1.\n    \n    Test case with a_i = b_i = m_i = 0 = 0\n    Explanation: No grams are available to eat, so the variety remains unchanged, and the output should reflect the original dish configuration.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if m_i == 0:\n            x_i, y_i = 0, 0\n        elif m_i == a_i + b_i:\n            x_i, y_i = a_i, b_i\n        (other code)", '- name: \nGreedy Approach with Sorting\n\n- content: \nA greedy solution that sorts dishes based on possible adjusted configurations and attempts to minimize dish variety by grouping similar configurations.\n\nSteps:\n1. Initialize an array `adjusted_dishes` to store possible configurations of each dish.\n2. For each dish (i-th dish):\n   - Generate all possible configurations of (remaining fish, remaining meat) after consuming exactly `m_i` grams.\n   - Store each configuration in `adjusted_dishes`.\n3. Sort `adjusted_dishes` by the number of remaining fish and meat, prioritizing configurations that lead to more common pairs.\n4. Traverse the sorted list to count distinct pairs, keeping track of maximum occurrences of identical configurations.\n5. The maximum number of identical configurations represents the minimum variety achievable.\n6. Output this minimum variety and any one valid configuration for each dish.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'variety\'\n    Explanation: In this context, variety refers to the number of distinct dishes based on their fish and meat content after the taster has eaten. The goal is to minimize this variety by making dishes as similar as possible.\n\n    \'equal dishes\'\n    Explanation: Two dishes are considered equal if they have the same amount of fish and meat after the taster has eaten.\n\n# [phrase showing quantity relationship]\n    \'exactly m_i grams\'\n    Explanation: The taster must eat exactly m_i grams from each dish, which is a strict requirement. This means that the sum of fish and meat eaten from each dish must equal m_i. In code, this can be implemented by ensuring x_i + y_i = m_i for each dish.\n\n# [degree adverb]\n    \'minimum\'\n    Explanation: The requirement is to achieve the minimum possible variety of dishes. This means finding a configuration that results in the fewest distinct dishes. In code, this involves finding the configuration with the maximum number of identical pairs.\n\n# [code logic]\n    Steps 3 and 4 should be considered simultaneously.\n    "Sort `adjusted_dishes` by the number of remaining fish and meat, prioritizing configurations that lead to more common pairs."\n    "Traverse the sorted list to count distinct pairs, keeping track of maximum occurrences of identical configurations."\n    These steps can be implemented together by sorting and then iterating through the sorted list to count distinct configurations.\n\n# [edge case]\n    Case 1: n = 1, a_1 = 0, b_1 = 0, m_1 = 0\n    Expected output: 1\n    Explanation: With only one dish and no grams to eat, the variety is inherently 1.\n\n    Case 2: n = 2, a_1 = 5, b_1 = 5, m_1 = 10; a_2 = 5, b_2 = 5, m_2 = 10\n    Expected output: 1\n    Explanation: Both dishes can be made identical by eating all available grams, resulting in a single variety.\n\n    Case 3: n = 3, a_1 = 10, b_1 = 0, m_1 = 5; a_2 = 0, b_2 = 10, m_2 = 5; a_3 = 5, b_3 = 5, m_3 = 5\n    Expected output: 3\n    Explanation: Each dish has a unique configuration after eating, resulting in maximum variety.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of sorting and counting distinct configurations will naturally handle these scenarios.']
----------
True
----------
8
multi-gen-prompt:
You are given an array a of n integers, and another integer k such that 2k ≤ n.

You have to perform exactly k operations with this array. In one operation, you have to choose two elements of the array (let them be a_i and a_j; they can be equal or different, but their positions in the array must not be the same). You then remove them from the array, and add ⌊ (a_i)/(a_j) ⌋ to your score, where ⌊ x/y ⌋ is the maximum integer not exceeding x/y.

Initially, your score is 0. After you perform exactly k operations, you add all the remaining elements of the array to the score.

Calculate the minimum possible score you can get.

Input

The first line of the input contains one integer t (1 ≤ t ≤ 500) — the number of test cases.

Each test case consists of two lines. The first line contains two integers n and k (1 ≤ n ≤ 100; 0 ≤ k ≤ ⌊ n/2 ⌋).

The second line contains n integers a_1, a_2, ..., a_n (1 ≤ a_i ≤ 2 ⋅ 10^5).

Output

Print one integer — the minimum possible score you can get.

Example

Input


5
7 3
1 1 1 2 1 3 1
5 1
5 5 5 5 5
4 2
1 3 3 7
2 0
4 2
9 2
1 10 10 1 10 2 7 10 3


Output


2
16
0
6
16

Note

Let's consider the example test.

In the first test case, one way to obtain a score of 2 is the following one:

  1. choose a_7 = 1 and a_4 = 2 for the operation; the score becomes 0 + ⌊ 1/2 ⌋ = 0, the array becomes [1, 1, 1, 1, 3]; 
  2. choose a_1 = 1 and a_5 = 3 for the operation; the score becomes 0 + ⌊ 1/3 ⌋ = 0, the array becomes [1, 1, 1]; 
  3. choose a_1 = 1 and a_2 = 1 for the operation; the score becomes 0 + ⌊ 1/1 ⌋ = 1, the array becomes [1]; 
  4. add the remaining element 1 to the score, so the resulting score is 2. 



In the second test case, no matter which operations you choose, the resulting score is 16.

In the third test case, one way to obtain a score of 0 is the following one:

  1. choose a_1 = 1 and a_2 = 3 for the operation; the score becomes 0 + ⌊ 1/3 ⌋ = 0, the array becomes [3, 7]; 
  2. choose a_1 = 3 and a_2 = 7 for the operation; the score becomes 0 + ⌊ 3/7 ⌋ = 0, the array becomes empty; 
  3. the array is empty, so the score doesn't change anymore. 



In the fourth test case, no operations can be performed, so the score is the sum of the elements of the array: 4 + 2 = 6.
multi-gen-prompt:
You are given an array a of n integers, and another integer k such that 2k ≤ n.

You have to perform exactly k operations with this array, and in one operation, you have to choose two elements of the array (let them be a_i and a_j; they can be equal or different, but their positions in the array must not be the same), remove them from the array, and add ⌊ (a_i)/(a_j) ⌋ to your score, where ⌊ x/y ⌋ is the maximum integer not exceeding x/y.

Initially, your score is 0, and after you perform exactly k operations, you add all the remaining elements of the array to the score.

Calculate the minimum possible score you can get.

Input

The first line of the input contains one integer t (1 ≤ t ≤ 500) — the number of test cases.

Each test case consists of two lines. The first line contains two integers n and k (1 ≤ n ≤ 100; 0 ≤ k ≤ ⌊ n/2 ⌋).

The second line contains n integers a_1, a_2, ..., a_n (1 ≤ a_i ≤ 2 ⋅ 10^5).

Output

Print one integer — the minimum possible score you can get.

Example

Input


5
7 3
1 1 1 2 1 3 1
5 1
5 5 5 5 5
4 2
1 3 3 7
2 0
4 2
9 2
1 10 10 1 10 2 7 10 3


Output


2
16
0
6
16

Note

Let's consider the example test.

In the first test case, one way to obtain a score of 2 is the following one:

  1. choose a_7 = 1 and a_4 = 2 for the operation; the score becomes 0 + ⌊ 1/2 ⌋ = 0, the array becomes [1, 1, 1, 1, 3]; 
  2. choose a_1 = 1 and a_5 = 3 for the operation; the score becomes 0 + ⌊ 1/3 ⌋ = 0, the array becomes [1, 1, 1]; 
  3. choose a_1 = 1 and a_2 = 1 for the operation; the score becomes 0 + ⌊ 1/1 ⌋ = 1, the array becomes [1]; 
  4. add the remaining element 1 to the score, so the resulting score is 2. 



In the second test case, no matter which operations you choose, the resulting score is 16.

In the third test case, one way to obtain a score of 0 is the following one:

  1. choose a_1 = 1 and a_2 = 3 for the operation; the score becomes 0 + ⌊ 1/3 ⌋ = 0, the array becomes [3, 7]; 
  2. choose a_1 = 3 and a_2 = 7 for the operation; the score becomes 0 + ⌊ 3/7 ⌋ = 0, the array becomes empty; 
  3. the array is empty, so the score doesn't change anymore. 



In the fourth test case, no operations can be performed, so the score is the sum of the elements of the array: 4 + 2 = 6.
generating with gpt-4o
----------
['def calculate_minimum_score(t, test_cases):\n    results = []\n    for case in test_cases:\n        n, k, array = case\n        if k == 0:\n            results.append(sum(array))\n            continue\n        \n        # Sort array in ascending order to facilitate optimal pair selection\n        array.sort()\n        score = 0\n        \n        # Perform k operations\n        for i in range(k):\n            # Choose the smallest available element as a_i\n            a_i = array[i]\n            # Choose the largest available element as a_j\n            a_j = array[n - k + i]\n            score += a_i // a_j\n        \n        # Add remaining elements to score\n        score += sum(array[:n-2*k])\n        results.append(score)\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        k = int(data[index + 1])\n        array = list(map(int, data[index + 2:index + 2 + n]))\n        test_cases.append((n, k, array))\n        index += 2 + n\n    \n    results = calculate_minimum_score(t, test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimum_score(n, k, array):\n    # Sort the array in non-decreasing order\n    array.sort()\n    \n    # Initialize score\n    score = 0\n    \n    # Perform k operations\n    for i in range(k):\n        # Pair the i-th smallest element with the (n-k+i)-th largest element\n        # This minimizes the floor division result\n        score += array[i] // array[n-k+i]\n    \n    # Add remaining elements to the score\n    for i in range(n - 2*k):\n        score += array[k + i]\n    \n    return score\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        k = int(data[index + 1])\n        index += 2\n        \n        array = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = calculate_minimum_score(n, k, array)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_minimum_score(n, k, array):\n    # Sort the array in non-decreasing order\n    array.sort()\n    \n    score = 0\n    \n    # Perform k operations\n    for i in range(k):\n        # Choose a_i as the smallest element from the first k elements\n        # Choose a_j as the largest element from the next k elements\n        a_i = array[i]\n        a_j = array[n - k + i]\n        \n        # Calculate the floor division and add it to the score\n        score += a_i // a_j\n    \n    # Add the remaining elements to the score\n    score += sum(array[k:n - k])\n    \n    return score\n\ndef process_test_cases(test_cases):\n    results = []\n    for n, k, array in test_cases:\n        result = calculate_minimum_score(n, k, array)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        k = int(data[index + 1])\n        array = list(map(int, data[index + 2:index + 2 + n]))\n        test_cases.append((n, k, array))\n        index += 2 + n\n    \n    results = process_test_cases(test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimum_score(t, test_cases):\n    results = []\n    for n, k, array in test_cases:\n        if k == 0:\n            results.append(sum(array))\n        else:\n            # Sort the array to facilitate optimal pairing\n            array.sort()\n            \n            # Calculate the score from the k operations\n            score = 0\n            for i in range(k):\n                # Pair the smallest element with the largest available element\n                score += array[i] // array[n - k + i]\n            \n            # Add the sum of the smallest n-2k elements to the score\n            score += sum(array[0:n-2*k])\n            \n            results.append(score)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        k = int(data[index + 1])\n        array = list(map(int, data[index + 2:index + 2 + n]))\n        test_cases.append((n, k, array))\n        index += 2 + n\n    \n    results = calculate_minimum_score(t, test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimum_score(n, k, array):\n    # Sort the array to facilitate pairing\n    array.sort()\n    \n    score = 0\n    \n    # Perform k operations\n    for i in range(k):\n        # Pair the i-th smallest element with the corresponding large element\n        score += array[i] // array[n - k + i]\n    \n    # Add the remaining elements to the score\n    # Correctly add the sum of the first n-2k smallest elements\n    score += sum(array[0:n-2*k])\n    \n    return score\n\ndef process_test_cases(test_cases):\n    results = []\n    for n, k, array in test_cases:\n        result = calculate_minimum_score(n, k, array)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        k = int(data[index + 1])\n        array = list(map(int, data[index + 2:index + 2 + n]))\n        test_cases.append((n, k, array))\n        index += 2 + n\n    \n    results = process_test_cases(test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimum_score(n, k, array):\n    # Sort the array in descending order\n    array.sort(reverse=True)\n    \n    score = 0\n    \n    # Perform k operations\n    for i in range(k):\n        # Pair the largest available element with the smallest available element\n        score += array[i + k] // array[i]\n    \n    # Add all remaining elements to the score\n    score += sum(array[2 * k:])\n    \n    return score\n\ndef process_test_cases(t, test_cases):\n    results = []\n    for i in range(t):\n        n, k = test_cases[i][0]\n        array = test_cases[i][1]\n        result = calculate_minimum_score(n, k, array)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    \n    for _ in range(t):\n        n, k = int(data[index]), int(data[index + 1])\n        index += 2\n        array = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append(((n, k), array))\n    \n    results = process_test_cases(t, test_cases)\n    \n    for result in results:\n        print(result)', 'import heapq\n\ndef calculate_minimum_score(n, k, array):\n    # Sort the array to facilitate the selection of optimal pairs\n    array.sort()\n    \n    # Initialize score\n    score = 0\n    \n    # Perform k operations\n    for i in range(k):\n        # Select the smallest element and the largest element from the remaining array\n        a_i = array[i]\n        a_j = array[n - k + i]\n        \n        # Calculate the floor division and add to score\n        score += a_i // a_j\n    \n    # Add remaining elements to the score\n    for i in range(n - 2 * k):\n        score += array[k + i]\n    \n    return score\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        k = int(data[index + 1])\n        index += 2\n        \n        array = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = calculate_minimum_score(n, k, array)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_minimum_score(n, k, array):\n    # Sort the array in non-decreasing order\n    array.sort()\n    \n    # Initialize score\n    score = 0\n    \n    # Perform k operations\n    for i in range(k):\n        # Pair the largest available elements with each other\n        a_i = array[n - k + i]\n        a_j = array[n - 2 * k + i]\n        score += a_i // a_j\n    \n    # Add remaining elements to the score\n    for i in range(n - 2 * k):\n        score += array[i]\n    \n    return score\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        k = int(data[index + 1])\n        index += 2\n        \n        array = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = calculate_minimum_score(n, k, array)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_minimum_score(n, k, array):\n    # Sort the array in ascending order\n    array.sort()\n    \n    # Initialize score\n    score = 0\n    \n    # Perform k operations\n    for i in range(k):\n        # Choose the smallest element a_i and the largest element a_j\n        a_i = array[i]\n        a_j = array[n - k + i]\n        # Add floor division result to score\n        score += a_i // a_j\n    \n    # Add the remaining elements to the score\n    for i in range(n - 2 * k):\n        score += array[k + i]\n    \n    return score\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        k = int(data[index + 1])\n        index += 2\n        \n        array = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = calculate_minimum_score(n, k, array)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def calculate_minimum_score(n, k, array):\n    # Sort the array in descending order\n    array.sort(reverse=True)\n    \n    # Initialize score\n    score = 0\n    \n    # Perform k operations\n    for i in range(k):\n        # Pair the largest available element with the second largest available element\n        # Pair array[i] with array[k+i] to minimize the division result\n        score += array[k+i] // array[i]\n    \n    # Add remaining elements to the score\n    score += sum(array[2*k:])\n    \n    return score\n\ndef process_test_cases(test_cases):\n    results = []\n    for n, k, array in test_cases:\n        result = calculate_minimum_score(n, k, array)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        k = int(data[index + 1])\n        array = list(map(int, data[index + 2:index + 2 + n]))\n        test_cases.append((n, k, array))\n        index += 2 + n\n    \n    results = process_test_cases(test_cases)\n    \n    for result in results:\n        print(result)']
----------
["- name: \nOptimized Pair Selection Using Priority Queue\n\n- content: \nUtilize a priority queue (min-heap) to efficiently select pairs for operations. First, insert all elements into a min-heap. For each operation, extract two smallest elements from the heap, compute ⌊ a_i / a_j ⌋ where a_i is always the smaller one, add it to the score, and discard these elements. This guarantees minimal contribution from each operation since smaller numbers yield lesser floor division results. After k operations, sum all remaining elements for the final score. This approach leverages efficient data structure operations to minimize the score effectively.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'array', 'integer', 'operation', 'score'\n    Explanation: The requirement involves performing operations on an array of integers to calculate a score. The operations involve selecting pairs of integers, removing them, and adding the floor division result to the score. The final score includes the sum of remaining elements after all operations.\n\n# [phrase showing quantity relationship]\n    '2k ≤ n': This indicates that the number of operations (k) is constrained by the size of the array (n), specifically that twice the number of operations must be less than or equal to the number of elements in the array.\n    Implementation: Ensure that k operations are performed, and check that 2k is less than or equal to n before proceeding.\n\n# [degree adverb]\n    'minimum': The requirement is to calculate the minimum possible score after performing the operations.\n    Implementation: Use a strategy that minimizes the score, such as selecting pairs with the smallest possible floor division results.\n\n# [code logic]\n    The plan suggests using a priority queue to select pairs for operations. The steps of extracting two smallest elements, computing the floor division, and discarding them should be implemented simultaneously within a loop for k operations.\n\n# [edge case]\n    Case 1: n = 1, k = 0, array = [5] = 5\n    Explanation: No operations can be performed, so the score is simply the sum of the array elements.\n    \n    Case 2: n = 2, k = 1, array = [1, 2] = 1\n    Explanation: Perform one operation with elements 1 and 2, resulting in ⌊1/2⌋ = 0. Remaining element is 1, so score is 1.\n    \n    Case 3: n = 4, k = 2, array = [1, 1, 1, 1] = 0\n    Explanation: Perform two operations with pairs (1, 1), resulting in ⌊1/1⌋ = 1 each time. No remaining elements, so score is 0.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using priority queue handles these cases by ensuring minimal score through efficient pair selection and floor division calculation.", "- name: \nSimulation with Priority Queue\n\n- content: \n- Use a priority queue (min-heap) to always access the smallest elements efficiently.\n- Insert all array elements into a min-heap.\n- Initialize score to 0.\n- Perform k operations:\n  - Extract two smallest elements from the heap.\n  - Calculate ⌊ smallest1 / smallest2 ⌋ and add it to the score.\n  - Discard these two elements as they are now used.\n- After k operations, sum all remaining elements in the heap and add to the score.\n- This method ensures that the smallest elements are always used first, leveraging their small value for division, thereby reducing ⌊ x/y ⌋ contributions effectively. This approach is particularly useful when handling dynamic element selection from a collection.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'array', 'integer', 'operation', 'score'\n    Explanation: The requirement involves performing operations on an array of integers to calculate a score. The operations involve selecting pairs of integers, removing them, and adding a calculated value to the score. The goal is to minimize the score after performing a fixed number of operations.\n\n# [phrase showing quantity relationship]\n    '2k ≤ n': This indicates that the number of operations (k) is constrained by the size of the array (n), specifically that twice the number of operations must be less than or equal to the number of elements in the array.\n    Implementation: Ensure that k operations can be performed by checking if 2k ≤ n before proceeding with the operations.\n\n# [degree adverb]\n    'minimum': The requirement is to calculate the minimum possible score after performing the operations.\n    Implementation: Use a strategy that minimizes the score, such as using a priority queue to always select the smallest elements for division.\n\n# [code logic]\n    The steps involving extracting two smallest elements and calculating ⌊ smallest1 / smallest2 ⌋ should be implemented simultaneously within each iteration of k operations. This can be done using a loop that performs these actions in sequence for each operation.\n\n# [edge case]\n    Case 1: n = 1, k = 0, array = [5] = 5\n    Explanation: No operations can be performed, so the score is simply the sum of the array elements, which is 5.\n    \n    Case 2: n = 2, k = 1, array = [1, 2] = 1\n    Explanation: Perform one operation with elements 1 and 2, resulting in ⌊ 1/2 ⌋ = 0. The remaining element is added to the score, resulting in a score of 1.\n    \n    Case 3: n = 4, k = 2, array = [1, 1, 1, 1] = 0\n    Explanation: Perform two operations with pairs (1, 1) twice, resulting in ⌊ 1/1 ⌋ = 1 each time. The array becomes empty, so no additional elements are added to the score.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using a priority queue and performing operations as described will naturally handle these cases correctly.", "- name: \nSimulation with Priority Queue\n- content: \n- Use a priority queue (min-heap) to efficiently track and pair the smallest elements with other elements in the array.\n- Insert all elements into the min-heap initially.\n- For each of the k operations, extract the two smallest elements, compute the floor division, and continue processing.\n- After k operations, sum up all remaining elements in the heap to calculate the final score.\n- This method ensures pairing of smallest elements in every step to minimize contributions to the score.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'array', 'integer', 'operation', 'score'\n    Explanation: The requirement involves performing operations on an array of integers to calculate a score. The operations involve removing pairs of elements and adding the floor division result to the score.\n\n# [phrase showing quantity relationship]\n    '2k ≤ n': This indicates that the number of operations (k) is constrained by the size of the array (n), specifically that twice the number of operations must be less than or equal to the number of elements in the array.\n    Implementation: Ensure that k operations are performed, and each operation involves removing two elements from the array.\n\n# [degree adverb]\n    'minimum': The goal is to calculate the minimum possible score after performing the operations.\n    Implementation: Use a strategy that minimizes the score, such as pairing the smallest elements first.\n\n# [code logic]\n    The steps involving extracting two smallest elements and computing floor division should be implemented simultaneously within a loop for k operations. This can be done using a priority queue to efficiently manage and extract elements.\n\n# [edge case]\n    Case 1: n = 1, k = 0, array = [5] = 5\n    Explanation: No operations can be performed, so the score is simply the sum of the array, which is 5.\n    \n    Case 2: n = 2, k = 1, array = [1, 2] = 0\n    Explanation: Perform one operation with elements 1 and 2, resulting in ⌊1/2⌋ = 0. The array becomes empty, so the score remains 0.\n    \n    Case 3: n = 4, k = 2, array = [1, 1, 1, 1] = 0\n    Explanation: Perform two operations with pairs (1, 1) each time, resulting in ⌊1/1⌋ = 1 for each pair. The array becomes empty, so the score is 0.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using a priority queue will naturally handle these scenarios by ensuring that operations are performed correctly and remaining elements are summed up.", "- name: \nReverse Simulation for Optimal Pairing\n\n- content: \nSimulate the process in reverse by determining which pairs would leave behind the optimal elements for a minimal score.\nSteps:\n1. Consider possible pairings from the array and calculate potential division results.\n2. Use dynamic programming or memoization to track optimal pairings leading to minimal scores.\n3. Reverse-simulate by finding which elements should optimally be left to sum at the end.\n4. Implement efficient searching over potential operations for best results.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'array', 'integer', 'operation', 'score'\n    Explanation: The requirement involves performing operations on an array of integers to calculate a score. The operations involve choosing pairs of integers, removing them, and adding the result of their division to the score. The goal is to minimize the score.\n\n# [phrase showing quantity relationship]\n    '2k ≤ n': This indicates that the number of operations (k) is constrained by the size of the array (n). Specifically, k must be less than or equal to half of n.\n    '⌊ (a_i)/(a_j) ⌋': This represents the floor division of two integers, meaning the largest integer not exceeding the division result.\n    Implementation: Use integer division in Python with `//` to achieve floor division.\n\n# [degree adverb]\n    'minimum': The requirement is to calculate the minimum possible score after performing the operations.\n    Implementation: Use strategies to minimize the score, such as choosing pairs that result in zero or low division results.\n\n# [code logic]\n    Steps 1 and 2 should be considered simultaneously as they both involve evaluating pairings and tracking scores. Dynamic programming or memoization can be used to efficiently manage these calculations.\n\n# [edge case]\n    Test case: n = 2, k = 0, array = [1, 1] = 2\n    Explanation: No operations can be performed, so the score is simply the sum of the array elements.\n    \n    Test case: n = 3, k = 1, array = [1, 2, 3] = 3\n    Explanation: Choose pair (1, 2) for operation; score becomes 0 + ⌊1/2⌋ = 0. Remaining elements are [3], so final score is 3.\n    \n    Test case: n = 4, k = 2, array = [1, 1, 1, 1] = 0\n    Explanation: Choose pairs (1, 1) twice; each operation results in ⌊1/1⌋ = 1. Remaining elements are empty, so final score is 0.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        def calculate_minimum_score(t, test_cases):\n            results = []\n            for n, k, array in test_cases:\n                if k == 0:\n                    results.append(sum(array))\n                else:\n                    # Implement logic for pairing and calculating minimum score\n                    # Consider dynamic programming or memoization for efficiency\n                    pass\n            return results", "- name: \nGreedy Pairing with Sorting\n\n- content: \nThe main idea is to perform operations in a way that minimizes the floor division result during each pairing. This can be achieved by pairing smaller elements with larger elements. Here's how:\n1. Sort the array in non-decreasing order.\n2. Initialize a score variable to 0.\n3. Perform k operations by pairing the smallest available element with one of the largest available ones (smallest first, largest next).\n   - For each operation, compute the floor division of the smaller number by the larger one and add the result to the score.\n   - Specifically, pair element at index i (smallest) with element at index n-1-i (largest).\n4. After completing k operations, add the remaining elements in the array to the score.\n5. Return the final score.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'array of n integers'\n    Explanation: This refers to the list of integers provided as input for each test case.\n\n    'k operations'\n    Explanation: This refers to the number of operations you must perform, where each operation involves selecting two elements from the array and performing a specific calculation.\n\n    'minimum possible score'\n    Explanation: The goal is to achieve the lowest score possible after performing the specified operations and adding the remaining elements.\n\n# [phrase showing quantity relationship]\n    '2k ≤ n': \n    Explanation: This indicates that the number of operations (k) is constrained such that twice the number of operations is less than or equal to the number of elements in the array. This ensures there are enough elements to perform k operations.\n\n# [degree adverb] \n    'minimum': \n    Explanation: The task is to find the smallest possible score after performing the operations and adding remaining elements. This involves strategic pairing to minimize the floor division results.\n\n# [code logic]\n    Steps 1 and 3 should be considered simultaneously.\n    - Sort the array in non-decreasing order.\n    - Perform k operations by pairing the smallest available element with one of the largest available ones (smallest first, largest next).\n    These steps can be implemented in a single loop where you iterate over the first k elements and pair them with the last k elements.\n\n# [edge case] \n    Case 1: n = 2, k = 1, array = [1, 2]\n    Expected output = 0\n    Explanation: Pair 1 and 2, floor division result is 0, no elements remain.\n\n    Case 2: n = 4, k = 0, array = [5, 5, 5, 5]\n    Expected output = 20\n    Explanation: No operations are performed, so the score is simply the sum of all elements.\n\n    Case 3: n = 6, k = 3, array = [1, 1, 1, 1, 1, 1]\n    Expected output = 0\n    Explanation: Pair all elements with each other, each operation results in a floor division of 0, no elements remain.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of sorting and pairing ensures that all edge cases are handled correctly.", "- name: \nSimulation with Priority Queue\n- content: \nThis approach uses a priority queue (min-heap) to efficiently manage and access the smallest and largest elements, which are critical for pairing operations to minimize division results.\n\nSteps:\n1. Build a min-heap from the array elements.\n2. Create a max-heap (using negative values) to maintain access to the largest elements efficiently.\n3. Initialize the score to 0.\n4. For each of the k operations, remove the smallest element and remove the largest element using the heaps.\n5. Compute the score increment as ⌊smallest/largest⌋ and add it to the score.\n6. After k operations, sum up all remaining elements in the heap and add it to the score.\n7. Return this as the minimum score.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'array of n integers'\n    Explanation: This refers to a list of integers with a specified length n.\n\n    'k operations'\n    Explanation: This means you need to perform exactly k operations as described in the requirement.\n\n    'minimum possible score'\n    Explanation: The goal is to achieve the lowest score possible after performing the operations and summing the remaining elements.\n\n# [phrase showing quantity relationship]\n    '2k ≤ n': This means that twice the number of operations (2 times k) is less than or equal to the number of elements in the array. This ensures that there are enough elements to perform k operations.\n    Implementation: Ensure that the loop for operations does not exceed k and that there are enough elements to perform these operations.\n\n# [degree adverb]\n    'minimum': This indicates that the goal is to achieve the lowest possible score.\n    Implementation: Use strategies like pairing the smallest and largest elements to minimize the division result.\n\n# [code logic]\n    Steps 4 and 5 should be implemented simultaneously. \n    Explanation: In each operation, you need to remove both the smallest and largest elements, compute the score increment, and update the score. This can be done in a single loop iteration for each operation.\n\n# [edge case]\n    Case 1: n = 2, k = 1, array = [1, 1]\n    Expected output: 0\n    Explanation: The only operation results in ⌊1/1⌋ = 1, and no elements remain, so the score is 0.\n\n    Case 2: n = 4, k = 2, array = [1, 2, 3, 4]\n    Expected output: 0\n    Explanation: Pair (1, 4) and (2, 3) both result in a score increment of 0, leaving no elements.\n\n    Case 3: n = 5, k = 0, array = [5, 5, 5, 5, 5]\n    Expected output: 25\n    Explanation: No operations are performed, so the score is simply the sum of all elements.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of using heaps to manage element selection and ensuring operations are performed correctly will naturally handle these cases.", "- name: \nDirect Simulation with Priority Queue\n- content: \nSimulate the process by prioritizing operations that yield minimal scores using a priority queue.\nSteps:\n1. Initialize a priority queue with all elements.\n2. For each operation, select two elements a_i and a_j such that ⌊a_i/a_j⌋ is minimized.\n   - Prioritize pairs where a_i is small and a_j is large.\n   - Use a max-heap for larger elements and min-heap for smaller ones to decide efficiently.\n3. Perform k operations by removing selected pairs and calculating score contributions.\n4. Sum remaining elements in the priority queue for the final score.\n5. Return the minimized score after all calculations.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'array', 'operations', 'score', 'minimum possible score'\n    Explanation: \n    - 'array': A collection of integers that we will manipulate through operations.\n    - 'operations': Actions where two elements are chosen, removed, and their division contributes to the score.\n    - 'score': The cumulative result of operations and remaining elements.\n    - 'minimum possible score': The goal is to achieve the lowest score possible after performing the operations.\n\n# [phrase showing quantity relationship]\n    '2k ≤ n': This means that the number of operations (k) is at most half of the number of elements (n) in the array.\n    '⌊ (a_i)/(a_j) ⌋': This represents the floor division of a_i by a_j, which is the largest integer not exceeding the division result.\n\n# [degree adverb] \n    'minimum': The goal is to achieve the smallest possible score after all operations and summing remaining elements.\n\n# [code logic]\n    Steps 2 and 3 should be considered simultaneously:\n    - Selecting two elements a_i and a_j such that ⌊a_i/a_j⌋ is minimized and performing k operations by removing selected pairs and calculating score contributions can be done in a loop where each iteration selects the optimal pair and updates the score.\n\n# [edge case] \n    Case 1: n = 2, k = 1, array = [1, 2] => Expected output: 0\n    Explanation: Only one operation can be performed, choosing (1, 2) results in ⌊1/2⌋ = 0, leaving no elements to add to the score.\n\n    Case 2: n = 4, k = 2, array = [1, 1, 1, 1] => Expected output: 0\n    Explanation: All operations result in ⌊1/1⌋ = 1, but since we perform exactly k operations, the array becomes empty with no remaining elements to add.\n\n    Case 3: n = 5, k = 0, array = [5, 5, 5, 5, 5] => Expected output: 25\n    Explanation: No operations are performed, so the score is simply the sum of all elements.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of selecting pairs to minimize ⌊a_i/a_j⌋ and summing remaining elements will naturally handle these scenarios.", "- name: \nPriority Queue for Pairing\n\n- content: \nUse a priority queue (min-heap) to facilitate optimal pairing of elements:\n1. Sort the array in descending order.\n2. Initialize a priority queue with the smallest elements (the last k elements of the sorted array).\n3. For k operations:\n   - Pop the smallest element from the priority queue (min element).\n   - Pair this min element with the largest unpaired element from the sorted array (the first unpaired element).\n   - Calculate ⌊min_element/largest_unpaired_element⌋ and add it to the score.\n   - After pairing, add the next smallest unpaired element back into the priority queue for future pairing.\n4. After performing k operations, sum all remaining unpaired elements from the sorted array and add them to the score.\nThis approach leverages a priority queue to manage dynamic element selection for optimal pairing.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'array of n integers'\n    Explanation: This refers to a list of integers with a specified length n.\n\n    'k operations'\n    Explanation: This means you need to perform exactly k operations as described in the requirement.\n\n    '⌊ (a_i)/(a_j) ⌋'\n    Explanation: This is the floor division of a_i by a_j, which means the largest integer not greater than the division result.\n\n# [phrase showing quantity relationship]\n    '2k ≤ n': \n    Explanation: This indicates that the number of operations k is constrained such that twice k is less than or equal to n. In code, this can be checked with an if statement to ensure the condition is met before proceeding with operations.\n\n# [degree adverb] \n    'minimum possible score':\n    Explanation: This means the goal is to achieve the lowest score possible after performing the operations and summing the remaining elements. In code, this involves choosing operations that minimize the score incrementally.\n\n# [code logic]\n    Steps 1 and 2 should be implemented simultaneously:\n    - Sort the array in descending order.\n    - Initialize a priority queue with the smallest elements (the last k elements of the sorted array).\n    These steps can be combined into one block where you sort the array and then immediately initialize the priority queue.\n\n# [edge case] \n    Case 1: n = 2, k = 1, array = [1, 1]\n    Expected output: 0\n    Explanation: The only operation possible is ⌊1/1⌋ = 1, and no elements remain to add to the score.\n\n    Case 2: n = 4, k = 2, array = [1, 1, 1, 1]\n    Expected output: 0\n    Explanation: Each operation results in ⌊1/1⌋ = 1, but since we perform two operations, all elements are removed, leaving no elements to add to the score.\n\n    Case 3: n = 5, k = 0, array = [5, 4, 3, 2, 1]\n    Expected output: 15\n    Explanation: No operations are performed, so the score is simply the sum of all elements.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where k = 0.\n        if k == 0:\n            return sum(array)\n        (other code)", "- name: \nSimulation with Priority Queue\n\n- content: \nUse a priority queue to efficiently manage and simulate the operations, focusing on minimizing ⌊a_i/a_j⌋ during each operation.\nSteps:\n1. Insert all elements into a min-heap (priority queue).\n2. Perform k operations:\n   - Extract the smallest element from the heap and pair it with the next smallest element that is larger.\n   - Calculate ⌊a_i/a_j⌋ for each operation, aiming for zero or minimal addition to score.\n   - Remove these paired elements from consideration.\n3. Sum the remaining elements in the priority queue for the final score.\nUsing a priority queue allows efficient selection of pairs that will minimize score additions.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'array', 'integer', 'operation', 'score'\n    Explanation: The requirement involves performing operations on an array of integers to calculate a score. The operations involve removing pairs of elements and adding a calculated value to the score.\n\n# [phrase showing quantity relationship]\n    '2k ≤ n': This indicates that the number of operations (k) is constrained by the size of the array (n), specifically that twice the number of operations must be less than or equal to the number of elements in the array.\n    Implementation: Ensure that k operations are performed, and each operation involves removing two elements from the array.\n\n# [degree adverb]\n    'minimum': The goal is to calculate the minimum possible score after performing the operations.\n    Implementation: Use a strategy that minimizes the score additions during operations, such as pairing elements to achieve the smallest possible division result.\n\n# [code logic]\n    Steps 1 and 2 should be implemented simultaneously as they involve managing the priority queue and performing operations in a loop. This can be done using a while loop or for loop to extract elements and perform calculations.\n\n# [edge case]\n    Test case: n = 1, k = 0, array = [1] = 1\n    Explanation: No operations can be performed, so the score is simply the sum of the array, which is 1.\n    \n    Test case: n = 2, k = 1, array = [1, 2] = 1\n    Explanation: Perform one operation with elements 1 and 2, resulting in ⌊1/2⌋ = 0. The remaining element is added to the score, resulting in a score of 1.\n    \n    Test case: n = 3, k = 1, array = [3, 3, 3] = 6\n    Explanation: Perform one operation with any two elements (e.g., 3 and 3), resulting in ⌊3/3⌋ = 1. The remaining element is added to the score, resulting in a score of 6.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of using a priority queue and performing operations will naturally handle these scenarios.", '- name: \nGreedy Pairing with Sorting\n\n- content: \nTo minimize the score, we should try to make the floor division result as small as possible during k operations. This can be effectively done by:\n1. Sorting the array in ascending order.\n2. For each of the k operations, choose the smallest element and pair it with one of the largest elements that haven\'t been removed yet. Specifically, pair the smallest element with the next largest available element from the end of the sorted list.\n3. Remove these two elements from further consideration.\n4. The floor division of a smaller element by a larger one will always yield zero, minimizing the score during these operations.\n5. After k operations, sum the remaining elements in the array to get the final score.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'array\', \'integer\', \'operation\', \'score\', \'minimum possible score\'\n    Explanation: The requirement involves performing operations on an array of integers to calculate a score. The goal is to minimize this score by strategically choosing pairs of elements for division operations.\n\n# [phrase showing quantity relationship]\n    \'2k ≤ n\': This indicates that the number of operations (k) is constrained by the size of the array (n), specifically that twice the number of operations must be less than or equal to the number of elements in the array.\n    Implementation: Ensure that the number of operations does not exceed half the size of the array.\n\n# [degree adverb]\n    \'minimum\': The requirement is to find the smallest possible score after performing the specified operations.\n    Implementation: Use a strategy that minimizes the score, such as pairing smaller elements with larger ones to ensure floor division results in zero.\n\n# [code logic]\n    Steps 1-3 should be implemented simultaneously:\n    "Sorting the array in ascending order",\n    "Choosing pairs for floor division",\n    "Removing elements from consideration"\n    This can be done by sorting the array first, then iterating through it to perform k operations, and finally summing the remaining elements.\n\n# [edge case]\n    Case 1: n = 1, k = 0, array = [1] => Expected output: 1\n    Explanation: No operations can be performed, so the score is simply the sum of the array elements.\n    \n    Case 2: n = 2, k = 1, array = [1, 2] => Expected output: 0\n    Explanation: Pair 1 with 2 for floor division, resulting in a score of 0. No elements remain to add to the score.\n    \n    Case 3: n = 3, k = 1, array = [1, 1, 2] => Expected output: 1\n    Explanation: Pair one of the 1s with 2 for floor division, resulting in a score of 0. The remaining element (1) is added to the score.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of sorting and pairing ensures that edge cases are handled correctly by minimizing the score through strategic pairing and summing remaining elements.']
----------
True
----------
2
multi-gen-prompt:
You are given two positive integers x and y. You are allowed to perform a specific operation on x. You can write it in its binary form without leading zeros. After that, you can add 0 or 1 to the right side of the digits in the binary form, reverse all the digits in the binary form and turn it into a decimal number which becomes the new value of x.

For example: 

  * 34 can be turned into 81 via one operation: the binary form of 34 is 100010, if you add 1, reverse it and remove leading zeros, you will get 1010001, which is the binary form of 81. 
  * 34 can be turned into 17 via one operation: the binary form of 34 is 100010, if you add 0, reverse it and remove leading zeros, you will get 10001, which is the binary form of 17. 
  * 81 can be turned into 69 via one operation: the binary form of 81 is 1010001, if you add 0, reverse it and remove leading zeros, you will get 1000101, which is the binary form of 69. 
  * 34 can be turned into 69 via two operations: first you turn 34 into 81 and then 81 into 69. 

Your task is to find out whether x can be turned into y after a certain number of operations (possibly zero).

Input

The only line of the input contains two integers x and y (1 ≤ x, y ≤ 10^{18}).

Output

Print YES if you can make x equal to y and NO if you can't.

Examples

Input


3 3


Output


YES


Input


7 4


Output


NO


Input


2 8


Output


NO


Input


34 69


Output


YES


Input


8935891487501725 71487131900013807


Output


YES

Note

In the first example, you don't even need to do anything.

The fourth example is described in the statement.
multi-gen-prompt:
You are given two positive integers x and y. You can perform the following operation with x: write it in its binary form without leading zeros, add 0 or 1 to the right of it, reverse the binary form and turn it into a decimal number which is assigned as the new value of x. For example: 

  * 34 can be turned into 81 via one operation: the binary form of 34 is 100010, if you add 1, reverse it and remove leading zeros, you will get 1010001, which is the binary form of 81. 
  * 34 can be turned into 17 via one operation: the binary form of 34 is 100010, if you add 0, reverse it and remove leading zeros, you will get 10001, which is the binary form of 17. 
  * 81 can be turned into 69 via one operation: the binary form of 81 is 1010001, if you add 0, reverse it and remove leading zeros, you will get 1000101, which is the binary form of 69.
  * 34 can be turned into 69 via two operations by first turning 34 into 81 and then 81 into 69.

Your task is to find out whether x can be turned into y after a certain number of operations (possibly zero).

Input

The only line of the input contains two integers x and y (1 ≤ x, y ≤ 10^{18}).

Output

Print YES if you can make x equal to y and NO if you can't.

Examples

Input


3 3


Output


YES


Input


7 4


Output


NO


Input


2 8


Output


NO


Input


34 69


Output


YES


Input


8935891487501725 71487131900013807


Output


YES

Note

In the first example, you don't even need to do anything.

The fourth example is described in the statement.
generating with gpt-4o
----------
['def can_transform(x, y):\n    if x == y:\n        return "YES"\n    \n    x_bin = bin(x)[2:]\n    y_bin = bin(y)[2:]\n    \n    if len(y_bin) < len(x_bin):\n        return "NO"\n    \n    # Start from the end of y\'s binary representation\n    y_index = len(y_bin) - 1\n    x_index = len(x_bin) - 1\n    \n    while y_index >= 0:\n        if x_index >= 0 and y_bin[y_index] == x_bin[x_index]:\n            # If the current bits match, move both indices\n            x_index -= 1\n        elif y_bin[y_index] == \'1\':\n            # If the current bit in y is \'1\', we can only match it by appending \'1\' to x\n            pass\n        else:\n            # If the current bit in y is \'0\', we can only match it by appending \'0\' to x\n            if x_index >= 0 and x_bin[x_index] == \'1\':\n                return "NO"\n        \n        # Move the y index\n        y_index -= 1\n    \n    # If we have matched all bits of x, then transformation is possible\n    if x_index < 0:\n        return "YES"\n    \n    return "NO"\n\nif __name__ == "__main__":\n    x, y = map(int, input().split())\n    result = can_transform(x, y)\n    print(result)', 'from collections import deque\n\ndef can_transform(x, y):\n    if x == y:\n        return True\n    \n    visited = set()\n    queue = deque([x])\n    \n    while queue:\n        current = queue.popleft()\n        \n        # If the current number is greater than y, skip further processing\n        if current > y:\n            continue\n        \n        # Convert current number to binary string\n        binary_str = bin(current)[2:]\n        \n        # Try appending \'0\' and \'1\', then reverse and convert back to decimal\n        for bit in [\'0\', \'1\']:\n            new_binary_str = binary_str + bit\n            reversed_binary_str = new_binary_str[::-1]\n            new_number = int(reversed_binary_str, 2)\n            \n            if new_number == y:\n                return True\n            \n            if new_number not in visited and new_number <= y:\n                visited.add(new_number)\n                queue.append(new_number)\n    \n    return False\n\nif __name__ == "__main__":\n    x, y = map(int, input().split())\n    if can_transform(x, y):\n        print("YES")\n    else:\n        print("NO")', 'from collections import deque\n\ndef can_transform(x, y):\n    if x == y:\n        return "YES"\n    \n    visited = set()\n    queue = deque([x])\n    \n    while queue:\n        current = queue.popleft()\n        if current == y:\n            return "YES"\n        \n        if current not in visited:\n            visited.add(current)\n            bin_str = bin(current)[2:]  # Get binary representation without \'0b\'\n            \n            # Try appending \'0\' and \'1\'\n            for bit in [\'0\', \'1\']:\n                new_bin_str = bin_str + bit\n                new_number = int(new_bin_str, 2)  # Convert to decimal without reversing\n                if new_number not in visited and new_number <= y:\n                    queue.append(new_number)\n    \n    return "NO"\n\nif __name__ == "__main__":\n    x, y = map(int, input().split())\n    result = can_transform(x, y)\n    print(result)', 'from collections import deque\n\ndef binary_transform(x):\n    # Convert x to binary string without \'0b\' prefix\n    return bin(x)[2:]\n\ndef perform_operation(binary_str, bit):\n    # Append the bit, reverse the string, and convert to decimal\n    new_binary = binary_str + bit\n    reversed_binary = new_binary[::-1]\n    return int(reversed_binary, 2)\n\ndef can_transform(x, y):\n    if x == y:\n        return "YES"\n    \n    # Initialize BFS queue\n    queue = deque([binary_transform(x)])\n    seen = set(queue)\n    \n    # Limit the depth of the search to prevent infinite loops\n    max_depth = 1000\n    \n    while queue and max_depth > 0:\n        current = queue.popleft()\n        \n        # Try appending \'0\' and \'1\'\n        for bit in [\'0\', \'1\']:\n            new_value = perform_operation(current, bit)\n            \n            if new_value == y:\n                return "YES"\n            \n            new_binary = binary_transform(new_value)\n            if new_binary not in seen:\n                seen.add(new_binary)\n                queue.append(new_binary)\n        \n        max_depth -= 1\n    \n    return "NO"\n\nif __name__ == "__main__":\n    x, y = map(int, input().split())\n    result = can_transform(x, y)\n    print(result)', 'def can_transform(x, y):\n    if x == y:\n        return True\n    if x > y:\n        return False\n    \n    # Memoization dictionary\n    visited = {}\n    \n    def recursive_check(current):\n        if current == y:\n            return True\n        if current > y or current in visited:\n            return False\n        \n        visited[current] = True\n        \n        # Convert to binary, append \'0\' and \'1\', reverse, convert back to decimal\n        bin_str = bin(current)[2:]\n        \n        # Append \'0\', reverse, and convert back to decimal\n        new_num_0 = int(bin_str + \'0\'[::-1], 2)\n        \n        # Append \'1\', reverse, and convert back to decimal\n        new_num_1 = int(bin_str + \'1\'[::-1], 2)\n        \n        return recursive_check(new_num_0) or recursive_check(new_num_1)\n    \n    return recursive_check(x)\n\nif __name__ == "__main__":\n    x, y = map(int, input().split())\n    print("YES" if can_transform(x, y) else "NO")', 'from collections import deque\n\ndef can_transform(x, y, max_depth=1000):\n    # Use a set to track visited numbers to avoid infinite loops\n    visited = set()\n    \n    # Use a deque for BFS approach\n    queue = deque([(x, 0)])  # Store tuples of (current_value, current_depth)\n    \n    while queue:\n        current, depth = queue.popleft()\n        \n        # If current equals y, return "YES"\n        if current == y:\n            return "YES"\n        \n        # Limit the depth of exploration to prevent infinite loops\n        if depth >= max_depth:\n            continue\n        \n        # Convert current to binary\n        current_binary = bin(current)[2:]\n        \n        # Try adding \'0\' and \'1\', reverse, and convert back to decimal\n        for bit in [\'0\', \'1\']:\n            new_binary = current_binary + bit\n            reversed_binary = new_binary[::-1]\n            new_value = int(reversed_binary, 2)\n            \n            # If new_value has not been visited, add it to the queue\n            if new_value not in visited:\n                visited.add(new_value)\n                queue.append((new_value, depth + 1))\n    \n    return "NO"\n\nif __name__ == "__main__":\n    # Read input\n    x, y = map(int, input().split())\n    \n    # Determine if x can be transformed into y\n    result = can_transform(x, y)\n    \n    # Print the result\n    print(result)', 'from collections import deque\n\ndef binary_reverse_transform(x):\n    # Convert x to binary, reverse it, and return the decimal value\n    binary_x = bin(x)[2:]  # Get binary representation without \'0b\' prefix\n    reversed_binary_x = binary_x[::-1]  # Reverse the binary string\n    return int(reversed_binary_x, 2)  # Convert back to decimal\n\ndef can_transform(x, y):\n    if x == y:\n        return True\n    \n    visited = set()\n    queue = deque([x])\n    \n    while queue:\n        current = queue.popleft()\n        \n        # Generate two possible transformations\n        for bit in [\'0\', \'1\']:\n            new_binary = bin(current)[2:] + bit\n            \n            # Ensure the binary representation is not empty\n            if new_binary:\n                new_value = int(new_binary[::-1], 2)\n                \n                # Prevent generating numbers larger than y\n                if new_value > y:\n                    continue\n                \n                if new_value == y:\n                    return True\n                \n                if new_value not in visited:\n                    visited.add(new_value)\n                    queue.append(new_value)\n    \n    return False\n\nif __name__ == "__main__":\n    x, y = map(int, input().split())\n    if can_transform(x, y):\n        print("YES")\n    else:\n        print("NO")', 'from collections import deque\n\ndef can_transform(x, y, max_depth=1000):\n    # Use a queue to perform a breadth-first search (BFS)\n    queue = deque([(x, 0)])  # Store tuples of (current number, current depth)\n    visited = set([x])\n    \n    while queue:\n        current, depth = queue.popleft()\n        \n        # If we reach y, return True\n        if current == y:\n            return True\n        \n        # Limit the depth to prevent infinite loops\n        if depth >= max_depth:\n            continue\n        \n        # Convert current number to binary string\n        current_bin = bin(current)[2:]\n        \n        # Try appending \'0\' and \'1\', then reverse and convert back to decimal\n        for bit in [\'0\', \'1\']:\n            new_bin = current_bin + bit\n            new_bin_reversed = new_bin[::-1]\n            new_number = int(new_bin_reversed, 2)\n            \n            # If the new number is not visited, add it to the queue\n            if new_number not in visited:\n                visited.add(new_number)\n                queue.append((new_number, depth + 1))\n    \n    # If we exhaust the queue without finding y, return False\n    return False\n\nif __name__ == "__main__":\n    # Read input\n    x, y = map(int, input().split())\n    \n    # Check if we can transform x into y\n    if can_transform(x, y):\n        print("YES")\n    else:\n        print("NO")', 'from collections import deque\n\ndef binary_representation(n):\n    """Convert a number to its binary representation as a string."""\n    return bin(n)[2:]\n\ndef can_transform(x, y):\n    """Check if x can be transformed into y using the described operations."""\n    # Initialize a queue for BFS and a set for visited states\n    queue = deque([x])\n    visited = set()\n    \n    # Define a reasonable limit to prevent infinite loops\n    limit = max(x, y) * 2\n\n    while queue:\n        current = queue.popleft()\n        \n        # If current equals y, transformation is possible\n        if current == y:\n            return True\n        \n        # Convert current to binary representation\n        current_bin = binary_representation(current)\n        \n        # Generate new states by adding \'0\' or \'1\' and reversing\n        for bit in [\'0\', \'1\']:\n            new_bin = current_bin + bit\n            new_bin_reversed = new_bin[::-1]\n            new_value = int(new_bin_reversed, 2)\n            \n            # If new_value has not been visited and is within the limit, add it to the queue\n            if new_value not in visited and new_value <= limit:\n                visited.add(new_value)\n                queue.append(new_value)\n    \n    return False\n\nif __name__ == "__main__":\n    # Read input values\n    x, y = map(int, input().split())\n    \n    # Validate input values\n    if x <= 0 or y <= 0:\n        print("NO")\n    else:\n        # Determine if transformation is possible\n        result = can_transform(x, y)\n        \n        # Print the result\n        print("YES" if result else "NO")', 'def can_transform(x, y):\n    # Edge case: if x is already equal to y\n    if x == y:\n        return "YES"\n    \n    # If y is less than x, transformation is not possible\n    if y < x:\n        return "NO"\n    \n    # Initialize the set with the starting number x\n    current_set = {x}\n    visited = set()  # To keep track of visited numbers to prevent infinite loops\n    \n    # While there are numbers to process\n    while current_set:\n        next_set = set()\n        \n        for num in current_set:\n            # Convert the number to binary without leading zeros\n            binary_form = bin(num)[2:]\n            \n            # Generate two new numbers by appending \'0\' and \'1\'\n            for bit in [\'0\', \'1\']:\n                new_binary = binary_form + bit\n                reversed_binary = new_binary[::-1]\n                new_num = int(reversed_binary, 2)\n                \n                # If the new number is equal to y, return "YES"\n                if new_num == y:\n                    return "YES"\n                \n                # Add the new number to the next set if it\'s less than or equal to y\n                if new_num <= y and new_num not in visited:\n                    next_set.add(new_num)\n                    visited.add(new_num)\n        \n        # Move to the next set of numbers\n        current_set = next_set\n    \n    # If we exhaust all possibilities without finding y, return "NO"\n    return "NO"\n\nif __name__ == "__main__":\n    # Read input values\n    x, y = map(int, input().split())\n    \n    # Output the result of the transformation check\n    print(can_transform(x, y))']
----------
['- name: \nGreedy Binary Manipulation\n\n- content: \nThis approach exploits binary properties to check whether transformations are possible through direct comparison.\nSteps:\n1. Convert x and y to their binary representations.\n2. Check if the length of y\'s binary representation is greater than or equal to x\'s.\n3. Traverse from the least significant bit (rightmost) of y backwards, applying transformations:\n   - If appending a \'1\' to x\'s binary form leads to a match with the current prefix of y\'s binary form, continue.\n   - If appending a \'0\' leads to a match, continue.\n   - At each step, ensure that no unmatched bits remain that cannot be reversed and matched through valid operations.\n4. If you match all bits successfully in order, print "YES"; otherwise, print "NO".\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'binary form\'\n    Explanation: This refers to the representation of a number in base-2 numeral system, which uses only two symbols: 0 and 1.\n\n    \'reverse\'\n    Explanation: This means to flip the order of the binary digits, so the last digit becomes the first and vice versa.\n\n# [phrase showing quantity relationship]\n    \'without leading zeros\': This means that any zeros at the beginning of the binary representation should be removed.\n    Implementation: When converting a binary string back to a decimal, ensure that leading zeros are not included.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps 3-4 should be implemented simultaneously:\n    "Traverse from the least significant bit (rightmost) of y backwards, applying transformations"\n    "At each step, ensure that no unmatched bits remain that cannot be reversed and matched through valid operations"\n    This can be done by iterating through y\'s binary representation and checking if appending \'0\' or \'1\' to x\'s binary form can match the current prefix of y.\n\n# [edge case] \n    Input: 1 1 = YES\n    Explanation: No operation is needed as x is already equal to y.\n    \n    Input: 2 3 = NO\n    Explanation: The binary form of 2 is \'10\', and no single operation can transform it into \'11\', which is the binary form of 3.\n    \n    Input: 4 8 = NO\n    Explanation: The binary form of 4 is \'100\', and no single operation can transform it into \'1000\', which is the binary form of 8.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if x == y:\n            print("YES")\n            return\n        x_bin = bin(x)[2:]\n        y_bin = bin(y)[2:]\n        if len(y_bin) < len(x_bin):\n            print("NO")\n            return\n        # Additional logic to check transformations\n        # (other code)', '- name: \nRecursive Backtracking with Pruning\n\n- content: \nUtilize recursive backtracking with pruning to attempt transforming x into y:\n1. Create a recursive function that takes the current number and its binary representation as arguments.\n2. Base case: If the current number equals y, return True (success).\n3. Recursive case:\n   - Attempt appending \'0\' and \'1\' to the binary form of the current number.\n   - Reverse each resultant binary string, convert it to decimal, and recursively call the function with this new number.\n   - Implement pruning by avoiding numbers that have been previously attempted or exceed practical limits (e.g., bit length considerations).\n4. If all recursive paths fail to result in y, return False and print "NO".\nThis solution explores paths recursively, leveraging pruning techniques for efficiency in handling large numbers.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'binary form\'\n    Explanation: This refers to representing a number in base-2 numeral system, which uses only two symbols: 0 and 1.\n\n    \'reverse the binary form\'\n    Explanation: This means to take the binary representation of a number and reverse the order of its digits.\n\n    \'turn it into a decimal number\'\n    Explanation: This means converting the reversed binary string back into a base-10 integer.\n\n# [phrase showing quantity relationship]\n    \'add 0 or 1\'\n    Explanation: This indicates that you can append either a \'0\' or a \'1\' to the binary representation of x. In code, this can be implemented by concatenating \'0\' or \'1\' to the binary string.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Attempt appending \'0\' and \'1\' to the binary form of the current number.\n    - Reverse each resultant binary string, convert it to decimal, and recursively call the function with this new number.\n    These steps are part of the recursive exploration and should be handled together within each recursive call.\n\n# [edge case]\n    x = 1, y = 1 -> YES\n    Explanation: No operations are needed as x is already equal to y.\n\n    x = 2, y = 2 -> YES\n    Explanation: No operations are needed as x is already equal to y.\n\n    x = 1, y = 2 -> NO\n    Explanation: Starting from 1, you cannot reach 2 by appending and reversing binary digits.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The recursive backtracking approach with pruning inherently handles these cases by checking if the current number equals y or if further operations are possible.', '- name: \nReverse Transformation Check\n\n- content: \nThis solution involves checking if y can be transformed into x by reversing the operations:\n1. Convert y to its binary representation.\n2. Try appending \'0\' or \'1\' to the binary form of y, then reverse it to see if it matches x\'s binary form.\n3. If a match is found during this process, output "YES".\n4. If no match is found after attempting all possible operations, output "NO".\n5. This approach leverages the fact that reversing the transformation might be simpler in some cases.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'binary form\'\n    Explanation: This refers to representing a number in base-2 numeral system, which uses only two symbols: 0 and 1.\n\n    \'reverse\'\n    Explanation: This means to reverse the order of the digits in the binary representation.\n\n    \'decimal number\'\n    Explanation: This refers to converting a binary number back into a base-10 numeral system.\n\n# [phrase showing quantity relationship]\n    \'add 0 or 1\'\n    Explanation: This means appending either a \'0\' or \'1\' to the end of the binary representation of x. In code, this can be done by concatenating \'0\' or \'1\' to the binary string.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps 2 and 3 in the plan should be considered simultaneously:\n    "Try appending \'0\' or \'1\' to the binary form of y, then reverse it to see if it matches x\'s binary form."\n    This can be implemented in a loop where for each iteration, you append \'0\' or \'1\', reverse the string, and check for a match.\n\n# [edge case]\n    3 3 = YES\n    Explanation: No operation is needed as x is already equal to y.\n    \n    1 2 = NO\n    Explanation: The binary of 1 is \'1\', and no matter what you append and reverse, you cannot get the binary of 2 (\'10\').\n\n    4 8 = NO\n    Explanation: The binary of 4 is \'100\', and no operation will transform it into the binary of 8 (\'1000\').\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where x is already equal to y.\n        if x == y:\n            print("YES")\n            return\n        (other code)', '- name: \nIterative BFS Approach\n\n- content: \nUse a breadth-first search (BFS) approach to iteratively explore all possible transformations from x to y.\n1. Convert x and y to their binary forms.\n2. Initialize a queue with the binary form of x.\n3. While the queue is not empty, perform the following:\n   - Dequeue an element, representing the current state.\n   - For each possible operation (append \'0\' or \'1\'), perform the transformation:\n     - Append the bit, reverse the string, and convert to decimal.\n     - If this transformation matches y, return "YES".\n     - If not yet seen, enqueue this new state for further exploration.\n4. If the queue is exhausted without finding y, return "NO".\nBFS ensures that we explore transformations in order of increasing complexity, effectively finding the shortest path to reach y if possible.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'binary form\'\n    Explanation: This refers to representing a number in base-2 numeral system, which uses only two symbols: 0 and 1.\n\n    \'reverse\'\n    Explanation: This means to reverse the order of the digits in the binary representation.\n\n    \'decimal number\'\n    Explanation: This refers to converting the binary form back into a base-10 numeral system, which is the standard system for denoting integer and non-integer numbers.\n\n# [phrase showing quantity relationship]\n    \'certain number of operations\': This implies that there is a finite number of operations that can be performed to transform x into y. In code, this can be implemented by iterating through possible transformations until y is reached or all possibilities are exhausted.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented in sequence, but the operations of appending \'0\' or \'1\', reversing, and converting to decimal should be considered simultaneously within each iteration of the BFS loop. This can be done by performing both possible transformations for each state in the queue.\n\n# [edge case] \n    1 1 = YES\n    Explanation: No operation is needed as x is already equal to y.\n    \n    2 2 = YES\n    Explanation: No operation is needed as x is already equal to y.\n    \n    1 2 = NO\n    Explanation: It is impossible to transform 1 into 2 using the described operations.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The BFS approach inherently handles these cases by checking if x is already equal to y before performing any operations. If they are equal, it returns "YES" immediately.', '- name: \nBinary Transformation Simulation\n\n- content: \nThis approach involves simulating the transformation process iteratively. Start with x, convert it to its binary form, and attempt to transform it step-by-step to match y\'s binary form. The process involves:\n1. Convert both x and y to their binary representations without leading zeros.\n2. Use a loop to perform operations on x\'s binary form:\n   - Append \'0\' or \'1\' to x\'s binary string.\n   - Reverse the binary string.\n   - Convert the reversed binary string back to a decimal number.\n3. Check if the transformed decimal number equals y.\n4. If x matches y at any point, output "YES". If the loop exhausts all possibilities without a match, output "NO".\nThis approach might require optimization to handle large numbers due to the constraints.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'binary form\'\n    Explanation: The binary form of a number is its representation using base 2, consisting of only 0s and 1s.\n\n    \'reverse\'\n    Explanation: Reversing a binary string means flipping the order of the digits from end to start.\n\n# [phrase showing quantity relationship]\n    \'certain number of operations\': This implies that the transformation from x to y can occur in zero or more operations, meaning we need to check all possible transformations until a match is found or all possibilities are exhausted.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps 2-4 should be implemented simultaneously. Specifically, the loop should handle appending \'0\' or \'1\', reversing the string, converting it back to decimal, and checking for equality with y in one iteration.\n\n# [edge case] \n    Input: 1 1 = YES\n    Explanation: No operation is needed as x is already equal to y.\n    \n    Input: 2 1 = NO\n    Explanation: The binary form of 2 is \'10\'. Adding any digit and reversing will not result in \'1\'.\n    \n    Input: 3 5 = NO\n    Explanation: The binary form of 3 is \'11\'. Adding any digit and reversing will not result in \'5\'.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if x == y:\n            print("YES")\n            return\n        # Implement the transformation logic here\n        # (other code)', '- name: \nReverse Simulation Approach\n\n- content: \nThis approach simulates the reverse of the operation described in the problem, starting from y and attempting to reach x.\n\n1. Convert y into its binary representation.\n2. While y is greater than or equal to x, perform the following steps:\n   - If the last bit of the binary representation of y is 0, remove it (this simulates reversing an operation that added 0).\n   - Otherwise, if the last bit of the binary representation of y is 1, remove it and add a 0 at the beginning (this simulates reversing an operation that added 1 and then reversed).\n   - Convert the new binary string back to a decimal number.\n   - Check if the new number is equal to x; if yes, print "YES" and terminate.\n3. If you exit the loop without finding x, print "NO".\n\nThis approach works because it attempts to reverse the operations used to potentially transform x into y.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'binary form\'\n    Explanation: This refers to representing a number in base-2 numeral system, which uses only two symbols: typically 0 and 1.\n\n    \'reverse\'\n    Explanation: This means to change the order of the digits in the binary representation, so the first digit becomes the last and vice versa.\n\n# [phrase showing quantity relationship]\n    \'certain number of operations\'\n    Explanation: This implies that there is no fixed number of operations, and it could be zero or more. In code, this means we need a loop to attempt multiple operations until a condition is met or all possibilities are exhausted.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented in a loop where each iteration attempts to reverse the operation on y. The steps "If the last bit of the binary representation of y is 0, remove it" and "Otherwise, if the last bit of the binary representation of y is 1, remove it and add a 0 at the beginning" should be considered simultaneously within an if-else block.\n\n# [edge case]\n    x = 1, y = 1 -> YES\n    Explanation: No operation is needed as x is already equal to y.\n\n    x = 2, y = 1 -> NO\n    Explanation: It\'s impossible to transform 2 into 1 using the described operations.\n\n    x = 1, y = 2 -> NO\n    Explanation: It\'s impossible to transform 1 into 2 using the described operations.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of reversing operations from y to x inherently handles these cases by checking if y can be reduced to x through valid operations.', '- name: \nBinary Pattern Matching\n\n- content: \nThe solution involves analyzing and matching patterns in the binary representations of x and y. The goal is to determine if there exists a sequence of binary reversals and appends that can transform x into y without exhaustive simulation. The steps include:\n1. Convert x and y to their binary strings.\n2. Compare lengths; if y has fewer bits than x, immediately return "NO" since appending increases length.\n3. Generate possible transformations by appending \'0\' or \'1\', reversing, and comparing with the target binary string of y.\n4. Utilize recursive pattern matching or dynamic programming to efficiently track sequences that could match y from x.\n5. If any sequence aligns perfectly with y\'s binary representation during the exploration, print "YES". If no sequence matches after exploring all possibilities, print "NO".\nThis approach leverages pattern recognition and binary string manipulation to reduce computation time compared to a brute force simulation.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'binary form\'\n    Explanation: This refers to representing a number in base-2 numeral system, which uses only two symbols: typically 0 and 1.\n\n    \'reverse the binary form\'\n    Explanation: This means to reverse the order of bits in the binary representation of a number.\n\n    \'turn it into a decimal number\'\n    Explanation: This means converting the binary representation back into a base-10 numeral system.\n\n# [phrase showing quantity relationship]\n    \'add 0 or 1\'\n    Explanation: This indicates that you can append either a \'0\' or a \'1\' to the binary representation of x. In code, this can be implemented by concatenating \'0\' or \'1\' to the binary string of x.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 3 and 4 should be considered simultaneously. \n    "Generate possible transformations by appending \'0\' or \'1\', reversing, and comparing with the target binary string of y."\n    "Utilize recursive pattern matching or dynamic programming to efficiently track sequences that could match y from x."\n    These steps involve generating transformations and checking them, which can be done in a recursive function or loop that tracks possible sequences.\n\n# [edge case]\n    1 1 = YES\n    Explanation: No operation is needed as x is already equal to y.\n    \n    2 1 = NO\n    Explanation: The binary form of 2 is \'10\'. Any operation will increase its value, so it cannot become 1.\n    \n    4 8 = NO\n    Explanation: The binary form of 4 is \'100\'. Any operation will not result in the binary form of 8 (\'1000\').\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n    The code should check if x is already equal to y at the start and return "YES" immediately. Additionally, it should handle cases where y has fewer bits than x by returning "NO" immediately.\n    \n```python\ndef can_transform(x, y):\n    if x == y:\n        return "YES"\n    \n    x_bin = bin(x)[2:]\n    y_bin = bin(y)[2:]\n    \n    if len(y_bin) < len(x_bin):\n        return "NO"\n    \n    # Recursive function or dynamic programming logic to check transformations\n    # (This part would involve implementing the transformation logic)\n    \n    return "NO"  # Default return if no transformation matches\n```', '- name: \nReverse Simulation of Binary Operations\n\n- content: \nTo determine if we can transform x into y using the defined operations, we can perform a reverse simulation by starting from y and attempting to reach x. The reverse operation involves determining the previous state of the binary number by considering possible appended bits. The steps are as follows:\n1. Convert y into its binary representation.\n2. Perform a loop to simulate the reverse process:\n   - Check if the last bit could have been appended during a valid transformation.\n   - Remove the last bit and reverse the remaining bits to obtain a new number.\n   - Convert this new binary number back to a decimal.\n3. Check if this new number is equal to x.\n4. Repeat the process until either x is reached or no further valid transformations are possible.\n5. If x is reached, print "YES"; otherwise, print "NO".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'binary form\'\n    Explanation: The binary form of a number is its representation in base-2 numeral system, which uses only two symbols: typically 0 and 1.\n\n    \'reverse\'\n    Explanation: Reversing the binary form means flipping the order of the bits in the binary representation of a number.\n\n# [phrase showing quantity relationship]\n    \'add 0 or 1\'\n    Explanation: This means appending either a 0 or a 1 to the right end of the binary representation of x. In code, this can be done by shifting the binary number left by one position and adding the desired bit.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps 2-4 in the plan should be implemented simultaneously in a loop:\n    - Check if the last bit could have been appended during a valid transformation.\n    - Remove the last bit and reverse the remaining bits to obtain a new number.\n    - Convert this new binary number back to a decimal.\n    This can be done in a while loop that continues until y is reduced to x or no further transformations are possible.\n\n# [edge case]\n    Input: 1 1 = YES\n    Explanation: Since x and y are already equal, no operations are needed.\n\n    Input: 2 1 = NO\n    Explanation: The binary form of 2 is \'10\'. Reversing it gives \'01\', which is 1, but appending any bit to \'10\' and reversing will not yield 1.\n\n    Input: 1 2 = NO\n    Explanation: Starting from 2, reversing and removing bits will not yield 1.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of reverse simulation will naturally handle these cases by checking if y can be reduced to x through valid transformations.', "- name: \nReverse Simulation from Target to Source\n\n- content: \nSimulate transformations in reverse from y back to x:\n1. Convert y to its binary representation.\n2. Attempt to reverse operations by considering the last bit appended (0 or 1) and reversing the string.\n3. For each step, if the reversed transformation matches the binary form of x, return YES.\n4. If no valid operation leads back to x, return NO.\nThis approach effectively reduces the search space by targeting specific operations that could result in y from x.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'binary form'\n    Explanation: The binary form is a representation of numbers using only two digits, 0 and 1. In this requirement, the binary form of a number is used to perform operations by appending digits and reversing the sequence.\n\n    'reverse'\n    Explanation: Reversing refers to flipping the order of digits in the binary representation of a number. This operation is crucial in transforming x into y.\n\n# [phrase showing quantity relationship]\n    'add 0 or 1'\n    Explanation: This indicates that during the operation, either a 0 or a 1 can be appended to the binary form of x. In code, this can be implemented by concatenating '0' or '1' to the binary string.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Convert y to its binary representation.\n    - Attempt to reverse operations by considering the last bit appended (0 or 1) and reversing the string.\n    These steps can be implemented in a loop where each iteration checks if reversing the transformation matches the binary form of x.\n\n# [edge case] \n    1 1 = YES\n    Explanation: Since x and y are already equal, no operations are needed, hence the output is YES.\n\n    2 1 = NO\n    Explanation: The binary form of 2 is '10'. No operation can transform it into '1', hence the output is NO.\n\n    4 8 = NO\n    Explanation: The binary form of 4 is '100'. No sequence of operations can transform it into '1000', which is the binary form of 8, hence the output is NO.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of reversing operations from y back to x inherently handles these cases by checking if transformations can lead back to x.", '- name: \nForward Simulation with Constraints\n\n- content: \nThis approach involves simulating the operations but with a focus on constraint checking to prevent exponential growth in possibilities:\n1. Convert x to its binary form.\n2. Use a set to keep track of possible numbers we can reach, initialized with x.\n3. For each number in the current set, generate two new numbers by appending \'0\' and \'1\' to its binary form, reversing it, and converting back to decimal.\n4. Add these new numbers to a temporary set if they are less than or equal to y.\n5. If y is reached during any iteration, output "YES".\n6. If the set becomes empty or no new numbers can be added without exceeding y, output "NO".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'binary form\'\n    Explanation: This refers to representing a number in base-2 numeral system, which uses only two symbols: typically 0 and 1.\n\n    \'reverse\'\n    Explanation: This means to reverse the order of the digits in the binary representation of a number.\n\n# [phrase showing quantity relationship]\n    \'without leading zeros\': This means that when converting a binary number back to decimal, any zeros at the start of the binary number should be ignored.\n    \'less than or equal to y\': This means that during the operations, any generated number should not exceed the value of y.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 3 and 4 should be implemented simultaneously. \n    "For each number in the current set, generate two new numbers by appending \'0\' and \'1\' to its binary form, reversing it, and converting back to decimal."\n    "Add these new numbers to a temporary set if they are less than or equal to y."\n    This can be done by iterating over the current set, performing the operations, and checking the condition in one loop.\n\n# [edge case]\n    3 3 = YES\n    Explanation: No operation is needed as x is already equal to y.\n    \n    1 2 = NO\n    Explanation: The binary form of 1 is \'1\'. Adding \'0\' or \'1\' and reversing will not result in 2.\n    \n    34 17 = YES\n    Explanation: The binary form of 34 is \'100010\'. Adding \'0\', reversing it gives \'10001\', which is 17 in decimal.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where x is already equal to y.\n        if x == y:\n            print("YES")\n            return\n        (other code)']
----------
True
----------
1
multi-gen-prompt:
You are given n lengths of segments that need to be placed on an infinite axis with coordinates.

The first segment is placed on the axis so that one of its endpoints lies at the point with coordinate 0. Let's call this endpoint the "start" of the first segment. The endpoint that is not the start can be called the "end" of this first segment.

The "start" of each following segment must coincide with the "end" of the previous one. Thus, if the length of the next segment is d and the "end" of the previous one has the coordinate x, the segment can be placed either on the coordinates [x-d, x], and then the coordinate of its "end" is x - d, or on the coordinates [x, x+d], in which case its "end" coordinate is x + d.

The total coverage of the axis by these segments is defined as their overall union which is basically the set of points covered by at least one of the segments. It's easy to show that the coverage will also be a segment on the axis. Determine the minimal possible length of the coverage that can be obtained by placing all the segments on the axis without changing their order.

Input

The first line contains an integer t (1 ≤ t ≤ 1000) — the number of test cases.

The next 2t lines contain descriptions of the test cases. 

The first line of each test case description contains an integer n (1 ≤ n ≤ 10^4) — the number of segments. The second line of the description contains n space-separated integers a_i (1 ≤ a_i ≤ 1000) — lengths of the segments in the same order they should be placed on the axis.

It is guaranteed that the sum of n over all test cases does not exceed 10^4.

Output

Print t lines, each line containing the answer to the corresponding test case. The answer to a test case should be a single integer — the minimal possible length of the axis coverage.

Example

Input


6
2
1 3
3
1 2 3
4
6 2 3 9
4
6 8 4 5
7
1 2 4 6 7 7 3
8
8 6 5 1 2 2 3 6


Output


3
3
9
9
7
8

Note

In the third sample test case the segments should be arranged as follows: [0, 6] → [4, 6] → [4, 7] → [-2, 7]. As you can see, the last segment [-2, 7] covers all the previous ones, and the total length of coverage is 9.

In the fourth sample test case the segments should be arranged as [0, 6] → [-2, 6] → [-2, 2] → [2, 7]. The union of these segments also occupies the area [-2, 7] and has the length of 9.
multi-gen-prompt:
You are given n lengths of segments that need to be placed on an infinite axis with coordinates. The first segment is placed on the axis so that one of its endpoints lies at the point with coordinate 0, and we call this endpoint the "start" of the first segment while the "end" is that endpoint that is not the start. The "start" of each following segment must coincide with the "end" of the previous one; thus, if the length of the next segment is d and the "end" of the previous one has the coordinate x, the segment can be placed either on the coordinates [x-d, x], and then the coordinate of its "end" is x - d, or on the coordinates [x, x+d], in which case its "end" coordinate is x + d. The total coverage of the axis by these segments is defined as their overall union which is basically the set of points covered by at least one of the segments. It's easy to show that the coverage will also be a segment on the axis. Determine the minimal possible length of the coverage that can be obtained by placing all the segments on the axis without changing their order.

Input

The first line contains an integer t (1 ≤ t ≤ 1000) — the number of test cases.

The next 2t lines contain descriptions of the test cases. 

The first line of each test case description contains an integer n (1 ≤ n ≤ 10^4) — the number of segments. The second line of the description contains n space-separated integers a_i (1 ≤ a_i ≤ 1000) — lengths of the segments in the same order they should be placed on the axis.

It is guaranteed that the sum of n over all test cases does not exceed 10^4.

Output

Print t lines, each line containing the answer to the corresponding test case. The answer to a test case should be a single integer — the minimal possible length of the axis coverage.

Example

Input


6
2
1 3
3
1 2 3
4
6 2 3 9
4
6 8 4 5
7
1 2 4 6 7 7 3
8
8 6 5 1 2 2 3 6


Output


3
3
9
9
7
8

Note

In the third sample test case the segments should be arranged as follows: [0, 6] → [4, 6] → [4, 7] → [-2, 7]. As you can see, the last segment [-2, 7] covers all the previous ones, and the total length of coverage is 9.

In the fourth sample test case the segments should be arranged as [0, 6] → [-2, 6] → [-2, 2] → [2, 7]. The union of these segments also occupies the area [-2, 7] and has the length of 9.
generating with gpt-4o
----------
['def calculate_minimal_coverage(n, segments):\n    # Initialize the min and max pointers\n    min_coord = 0\n    max_coord = 0\n    \n    # Current end of the last placed segment\n    current_end = 0\n    \n    for length in segments:\n        # Calculate potential new ends\n        forward_end = current_end + length\n        backward_end = current_end - length\n        \n        # Choose the placement that minimizes the coverage\n        if abs(forward_end - min_coord) < abs(max_coord - backward_end):\n            current_end = forward_end\n        else:\n            current_end = backward_end\n        \n        # Update min and max coordinates\n        min_coord = min(min_coord, current_end)\n        max_coord = max(max_coord, current_end)\n    \n    # The minimal coverage is the difference between max and min coordinates\n    return max_coord - min_coord\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        segments = list(map(int, data[index:index + n]))\n        index += n\n        \n        result = calculate_minimal_coverage(n, segments)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def minimal_coverage_length(n, segments):\n    current_position = 0\n    min_position = 0\n    max_position = 0\n    \n    for length in segments:\n        # Calculate potential new positions\n        left_position = current_position - length\n        right_position = current_position + length\n        \n        # Choose the position that minimizes the range\n        if abs(left_position - min_position) < abs(right_position - max_position):\n            current_position = left_position\n        else:\n            current_position = right_position\n        \n        # Update min and max positions\n        min_position = min(min_position, current_position)\n        max_position = max(max_position, current_position)\n    \n    return max_position - min_position\n\ndef process_test_cases(test_cases):\n    results = []\n    for n, segments in test_cases:\n        result = minimal_coverage_length(n, segments)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        segments = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, segments))\n    \n    results = process_test_cases(test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimal_coverage(n, segments):\n    # Initialize the current position and coverage range\n    current_position = 0\n    min_position = 0\n    max_position = 0\n    \n    # Iterate through each segment\n    for length in segments:\n        # Decide whether to place the segment to the left or right\n        # We choose the direction that minimizes the overall coverage\n        if abs(current_position + length) < abs(current_position - length):\n            current_position += length\n        else:\n            current_position -= length\n        \n        # Update the min and max positions based on the current position\n        min_position = min(min_position, current_position)\n        max_position = max(max_position, current_position)\n    \n    # The minimal coverage is the difference between max and min positions\n    return max_position - min_position\n\ndef process_test_cases(test_cases):\n    results = []\n    for n, segments in test_cases:\n        result = calculate_minimal_coverage(n, segments)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        segments = list(map(int, data[index:index+n]))\n        index += n\n        test_cases.append((n, segments))\n    \n    results = process_test_cases(test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimal_coverage(n, segments):\n    # Initialize start and end pointers\n    start = 0\n    end = 0\n    \n    for length in segments:\n        # Calculate two potential new endpoints\n        new_end1 = end + length\n        new_end2 = end - length\n        \n        # Choose the placement that provides minimal coverage\n        if new_end1 - start < end - new_end2:\n            end = new_end1\n        else:\n            end = new_end2\n    \n    # Calculate the total coverage\n    return abs(end - start)\n\ndef process_test_cases(test_cases):\n    results = []\n    for n, segments in test_cases:\n        result = calculate_minimal_coverage(n, segments)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        segments = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, segments))\n    \n    results = process_test_cases(test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimal_coverage(n, segments):\n    # Initialize the DP table to track the minimum and maximum possible positions\n    dp = [[0, segments[0]] for _ in range(n)]\n    \n    # Fill the DP table\n    for i in range(1, n):\n        length = segments[i]\n        \n        # Extend to the left: new start is previous end minus current segment length\n        new_start_left = dp[i-1][1] - length\n        new_end_left = dp[i-1][1]\n        \n        # Extend to the right: new end is previous start plus current segment length\n        new_start_right = dp[i-1][0]\n        new_end_right = dp[i-1][0] + length\n        \n        # Update the DP table with the minimal start and maximal end\n        dp[i][0] = min(new_start_left, new_start_right)\n        dp[i][1] = max(new_end_left, new_end_right)\n    \n    # The minimal coverage is the difference between the last segment\'s max end and min start\n    return dp[n-1][1] - dp[n-1][0]\n\ndef process_test_cases(test_cases):\n    results = []\n    for n, segments in test_cases:\n        result = calculate_minimal_coverage(n, segments)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        segments = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, segments))\n    \n    results = process_test_cases(test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimal_coverage(n, segments):\n    current_position = 0\n    min_position = 0\n    max_position = 0\n    \n    for segment in segments:\n        # Calculate potential new positions\n        new_position_plus = current_position + segment\n        new_position_minus = current_position - segment\n        \n        # Choose the position that minimizes the coverage\n        if abs(new_position_plus) < abs(new_position_minus):\n            current_position = new_position_plus\n        else:\n            current_position = new_position_minus\n        \n        # Update min and max positions\n        min_position = min(min_position, current_position)\n        max_position = max(max_position, current_position)\n    \n    # Calculate the total coverage length\n    return max_position - min_position\n\ndef process_test_cases(test_cases):\n    results = []\n    for n, segments in test_cases:\n        result = calculate_minimal_coverage(n, segments)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        segments = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, segments))\n    \n    results = process_test_cases(test_cases)\n    \n    for result in results:\n        print(result)', 'def minimal_coverage(t, test_cases):\n    results = []\n    \n    for n, segments in test_cases:\n        # Initialize coverage and position\n        coverage = float(\'inf\')\n        \n        # Recursive function for backtracking\n        def place_segments(index, current_position, current_coverage):\n            nonlocal coverage\n            if index == n:\n                coverage = min(coverage, current_coverage)\n                return\n            \n            # Place segment to the right\n            new_position_right = current_position + segments[index]\n            place_segments(index + 1, new_position_right, max(current_coverage, new_position_right))\n            \n            # Place segment to the left\n            new_position_left = current_position - segments[index]\n            place_segments(index + 1, new_position_left, max(current_coverage, -new_position_left))\n        \n        # Start recursion from first segment placed at [0, a_1]\n        place_segments(1, segments[0], segments[0])\n        \n        results.append(coverage)\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        segments = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, segments))\n    \n    results = minimal_coverage(t, test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimal_coverage(n, segments):\n    # Initialize prefix and suffix sums\n    prefix_sum = 0\n    suffix_sum = sum(segments)\n    \n    # Initialize the minimal coverage length\n    min_coverage = suffix_sum\n    \n    # Iterate over each segment\n    for i in range(n):\n        # Update prefix sum by adding the current segment length\n        prefix_sum += segments[i]\n        \n        # Update suffix sum by subtracting the current segment length\n        suffix_sum -= segments[i]\n        \n        # Calculate the potential coverage if placed to the left or right\n        left_coverage = max(prefix_sum, suffix_sum)\n        \n        # Update the minimal coverage length\n        min_coverage = min(min_coverage, left_coverage)\n    \n    return min_coverage\n\ndef process_test_cases(t, test_cases):\n    results = []\n    for i in range(t):\n        n, segments = test_cases[i]\n        result = calculate_minimal_coverage(n, segments)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        segments = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, segments))\n    \n    results = process_test_cases(t, test_cases)\n    \n    for result in results:\n        print(result)', 'def calculate_minimal_coverage(n, lengths):\n    # Initialize the current position and coverage boundaries\n    current_pos = 0\n    min_pos = 0\n    max_pos = 0\n    \n    for length in lengths:\n        # Decide whether to place the segment to the left or right\n        # We choose the direction that minimizes the coverage extension\n        if current_pos - length < min_pos:\n            current_pos += length\n        else:\n            current_pos -= length\n        \n        # Update the min and max positions based on the new current position\n        min_pos = min(min_pos, current_pos)\n        max_pos = max(max_pos, current_pos)\n    \n    # The minimal coverage is the distance between the min and max positions\n    return max_pos - min_pos\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        lengths = list(map(int, data[index:index+n]))\n        index += n\n        \n        result = calculate_minimal_coverage(n, lengths)\n        results.append(result)\n    \n    for res in results:\n        print(res)', 'def minimal_coverage(t, test_cases):\n    results = []\n    for n, segments in test_cases:\n        # Initialize the starting position\n        min_position = 0\n        max_position = 0\n        current_position = 0\n\n        for length in segments:\n            # Decide to extend to the right\n            if current_position + length <= max_position:\n                current_position += length\n            else:\n                # Extend to the left\n                current_position -= length\n\n            # Update the min and max positions\n            min_position = min(min_position, current_position)\n            max_position = max(max_position, current_position)\n\n        # Calculate the minimal coverage\n        results.append(max_position - min_position)\n    \n    return results\n\ndef parse_input():\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    t = int(data[0])\n    index = 1\n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        index += 1\n        segments = list(map(int, data[index:index + n]))\n        index += n\n        test_cases.append((n, segments))\n    \n    return t, test_cases\n\nif __name__ == "__main__":\n    t, test_cases = parse_input()\n    results = minimal_coverage(t, test_cases)\n    for result in results:\n        print(result)']
----------
["- name: \nTwo-Pointer Technique with Coverage Calculation\n\n- content: \nUse a two-pointer technique to continuously adjust minimum and maximum coverage as segments are placed.\nSteps:\n1. Initialize two pointers, one for tracking minimum coverage coordinate and one for maximum.\n2. Start placing segments from coordinate 0.\n3. For each segment:\n   - Calculate two new potential endpoints (forward and backward).\n   - Decide on placement based on minimizing the overall difference between min and max pointers after placing the segment.\n   - Update min and max pointers based on chosen placement.\n4. After all segments are placed, compute coverage length as difference between max and min pointers.\n5. Return this computed length for each test case, ensuring optimal placement has been achieved at each step.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'segments', 'axis', 'coverage'\n    Explanation: The requirement involves placing segments on an axis, where each segment has a start and end point. The goal is to determine the minimal possible length of the coverage of the axis by these segments, which is the union of all points covered by at least one segment.\n\n# [phrase showing quantity relationship]\n    'minimal possible length': This means finding the smallest length of the axis that can be covered by the segments when placed optimally.\n    Implementation: This can be implemented by calculating the difference between the maximum and minimum coordinates covered by the segments.\n\n# [degree adverb]\n    'minimal': This indicates that we need to find the smallest possible coverage length.\n    Implementation: Use a strategy that minimizes the difference between the maximum and minimum coordinates after placing all segments.\n\n# [code logic]\n    Steps 3 and 4 should be considered simultaneously:\n    - For each segment, calculate potential endpoints and decide on placement to minimize coverage.\n    - Update min and max pointers based on chosen placement.\n    This can be implemented in a loop where each segment's placement is decided based on minimizing the overall coverage.\n\n# [edge case]\n    Test case: 1\n    Input: 1\n           1000\n    Expected output: 1000\n    Explanation: With only one segment of length 1000, the minimal coverage is simply the length of that segment.\n\n    Test case: 2\n    Input: 2\n           1 1\n    Expected output: 1\n    Explanation: Two segments of length 1 can overlap completely, resulting in a minimal coverage of 1.\n\n    Test case: 3\n    Input: 3\n           1 1 1\n    Expected output: 1\n    Explanation: Three segments of length 1 can overlap completely, resulting in a minimal coverage of 1.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of calculating minimal coverage by adjusting min and max pointers will naturally handle these cases.", "- name: \nGreedy Approach with Prefix Sum\n\n- content: \nTo achieve the minimal possible coverage length, we can use a greedy strategy combined with prefix sums to calculate the optimal overlap of segments:\n1. Initialize a variable `current_position` to keep track of the end coordinate of the last placed segment, starting from 0.\n2. Initialize variables `min_position` and `max_position` both set to 0 to track the range of coverage.\n3. Iterate through each segment length:\n   - For each segment, consider placing it either left or right of `current_position`.\n   - Update `current_position` to the position that maintains a shorter range between `min_position` and `max_position`.\n   - Update `min_position` and `max_position` accordingly based on the new `current_position`.\n4. The minimal coverage length after placing all segments is given by `max_position - min_position`.\nThis approach ensures that each segment is placed in a way that minimizes the expansion of the overall coverage range.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'segments', 'axis', 'coverage'\n    Explanation: Segments are the lengths that need to be placed on an axis. The axis is an infinite line where these segments are placed. Coverage refers to the total length of the axis that is covered by these segments.\n\n# [phrase showing quantity relationship]\n    'minimal possible length': means finding the smallest length of coverage that can be achieved by optimally placing the segments.\n    'sum of n over all test cases does not exceed 10^4': indicates a constraint on the total number of segments across all test cases, which affects performance considerations.\n\n# [degree adverb] \n    'minimal': means the smallest possible value, in this context, the shortest length of coverage.\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Initialize `current_position`, `min_position`, and `max_position`.\n    - Iterate through each segment and decide placement.\n    - Update positions accordingly.\n    These steps can be implemented in a single loop where decisions are made based on current positions.\n\n# [edge case] \n    Test case with all segments of length 1: \n    Input: 3, 1 1 1\n    Output: 1\n    Explanation: All segments can overlap completely, resulting in a coverage length of 1.\n    \n    Test case with segments of increasing lengths:\n    Input: 3, 1 2 3\n    Output: 3\n    Explanation: The optimal placement results in a coverage length equal to the largest segment length.\n    \n    Test case with segments of decreasing lengths:\n    Input: 3, 3 2 1\n    Output: 3\n    Explanation: The largest segment dictates the minimal coverage length.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of iterating through segments and updating positions will naturally handle these scenarios.", '- name: \nBacktracking with Pruning\n\n- content: \nUse backtracking to explore all possible placements with pruning to avoid unnecessary computations.\n\nSteps:\n1. Define a recursive function that attempts to place each segment either to the left or right.\n2. Maintain a global variable for storing the minimum coverage found.\n3. For each segment, recursively try both placements:\n   - Calculate new coverage if placed on the left.\n   - Calculate new coverage if placed on the right.\n   - Use pruning to skip placements that exceed current known minimum coverage.\n4. After exploring all placements for a test case, update the global variable if a new minimum is found.\n5. Return the global variable holding the minimal coverage after all segments are processed.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'segments\', \'axis\', \'coverage\'\n    Explanation: Segments are the lengths that need to be placed on an axis. The axis is an infinite line where these segments are placed. Coverage refers to the total length of the axis that is covered by these segments.\n\n# [phrase showing quantity relationship]\n    \'minimal possible length\': means finding the smallest length of coverage that can be achieved by placing all segments on the axis.\n    Implementation: This involves calculating the union of all segments and finding the smallest possible coverage.\n\n# [degree adverb] \n    \'minimal\': means the smallest possible value.\n    Implementation: Use a variable to track the smallest coverage found during the placement of segments.\n\n# [code logic]\n    The steps 3-5 should be implemented simultaneously.\n    "Calculate new coverage if placed on the left",\n    "Calculate new coverage if placed on the right",\n    "Use pruning to skip placements that exceed current known minimum coverage"\n    This can be done by writing a recursive function that tries both placements and updates the minimum coverage variable accordingly.\n\n# [edge case] \n    Test case with all segments having length 1: minimal coverage = n (where n is the number of segments)\n    Explanation: Since each segment has length 1, they can be placed consecutively without overlap, resulting in a total coverage equal to the number of segments.\n    \n    Test case with segments having alternating large and small lengths: minimal coverage = sum of all segment lengths\n    Explanation: Alternating large and small lengths may lead to overlapping, but the minimal coverage will still be the sum of all lengths due to placement constraints.\n    \n    Test case with a single segment: minimal coverage = length of that segment\n    Explanation: With only one segment, the coverage is simply its length.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        def calculate_minimal_coverage(segments):\n            if len(segments) == 1:\n                return segments[0]\n            # Implement logic for alternating large and small lengths\n            # Implement logic for all segments having length 1\n            # Other code for general cases', "- name: \nDynamic Programming Approach\n\n- content: \nThe solution involves using dynamic programming to keep track of the minimal possible length of the coverage for different placements of each segment.\n\nSteps:\n1. Define a DP table where dp[i][0] represents the minimal coverage when the i-th segment is placed backward, and dp[i][1] when placed forward.\n2. Initialize dp[0][0] and dp[0][1] with the length of the first segment since it starts at 0.\n3. For each subsequent segment, calculate:\n   - dp[i][0] = min(dp[i-1][0] - length[i], dp[i-1][1] - length[i]) \n   - dp[i][1] = min(dp[i-1][0] + length[i], dp[i-1][1] + length[i])\n4. The final answer is min(dp[n-1][0], dp[n-1][1]) which gives the minimal possible coverage after all segments are placed.\n5. Output this value for each test case.\n\nThis approach uses dynamic programming to systematically explore all possible placements and select the optimal one for minimal coverage.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'segments'\n    Explanation: In the requirement, segments refer to the lengths that need to be placed on an axis. Each segment can be placed either forward or backward from the endpoint of the previous segment.\n\n    'coverage'\n    Explanation: Coverage refers to the total length of the axis that is covered by at least one segment. The goal is to minimize this coverage.\n\n# [phrase showing quantity relationship]\n    'minimal possible length'\n    Explanation: This means finding the smallest possible length of the axis that can be covered by the segments. In code, this is achieved by calculating the minimum coverage using dynamic programming.\n\n# [degree adverb] \n    'minimal'\n    Explanation: The requirement is to find the smallest possible coverage length. In code, this is implemented by taking the minimum value from possible coverage lengths calculated using dynamic programming.\n\n# [code logic]\n    Steps 3 and 4 in the plan should be considered simultaneously. The calculation of dp[i][0] and dp[i][1] for each segment should be done in one loop iteration, as they depend on the previous segment's placement.\n\n# [edge case] \n    Test case with a single segment: \n    Input: 1\n           1\n    Expected output: 1\n    Explanation: With only one segment, the coverage is simply its length.\n\n    Test case with all segments of length 1:\n    Input: 3\n           1 1 1\n    Expected output: 1\n    Explanation: All segments can overlap completely, resulting in a minimal coverage of 1.\n\n    Test case with increasing segment lengths:\n    Input: 3\n           1 2 3\n    Expected output: 3\n    Explanation: The segments can be placed such that they overlap optimally, resulting in a minimal coverage of 3.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The dynamic programming approach inherently considers all possible placements and finds the minimal coverage.", "- name: \nTwo-Pointer Optimization\n\n- content: \nA two-pointer technique can be used to optimize segment placements in such a way that minimizes overlap and maximizes union efficiency.\nThe approach involves:\n1. Start with two pointers, one at the beginning and another at the current endpoint.\n2. Iterate over each segment while keeping track of potential movements to either extend left or right.\n3. Use the pointers to dynamically adjust segment placements, aiming to minimize coverage by choosing directions with less overlap.\n4. Compare potential placements for each segment and move pointers accordingly, updating the total coverage range.\n5. After processing all segments, calculate the minimal possible coverage from pointer positions.\nThis technique leverages dual pointers to dynamically adapt and optimize decisions based on real-time information during iteration.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'segment', 'axis', 'coverage'\n    Explanation: \n    - 'segment': Refers to a part of the axis with a defined length that needs to be placed on the axis.\n    - 'axis': The infinite line on which segments are placed, with coordinates determining positions.\n    - 'coverage': The total length of the axis covered by the union of all segments.\n\n# [phrase showing quantity relationship]\n    'minimal possible length': Refers to the smallest length of the axis that can be covered by the union of all segments.\n    Implementation: This involves calculating the union of segments and finding the smallest possible coverage.\n\n# [degree adverb] \n    'minimal': Indicates the smallest or least amount possible.\n    Implementation: The code should aim to find the smallest coverage length by optimizing segment placement.\n\n# [code logic]\n    Steps 2-5 should be considered simultaneously as they involve dynamic adjustment and optimization during iteration.\n    Implementation: Use a loop to iterate over segments, adjusting pointers and calculating coverage in real-time.\n\n# [edge case] \n    Test case with one segment: \n    Input: 1\n           5\n    Expected output: 5\n    Explanation: With only one segment, the coverage is simply its length.\n\n    Test case with all segments of length 1:\n    Input: 3\n           1 1 1\n    Expected output: 3\n    Explanation: Each segment can be placed consecutively without overlap, resulting in total coverage equal to the sum of lengths.\n\n    Test case with segments that can fully overlap:\n    Input: 2\n           5 5\n    Expected output: 5\n    Explanation: The second segment can completely overlap the first, resulting in coverage equal to one segment's length.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of using two pointers and dynamic adjustment will naturally handle these scenarios.", "- name: \nDynamic Programming Approach\n- content: \n- Use dynamic programming to find the minimal coverage by considering both directions for placing each segment.\n- Initialize a DP array `dp[i][j]` where `i` is the index of the segment and `j` indicates direction (0 for left, 1 for right).\n- Set initial conditions: `dp[0][0] = 0` and `dp[0][1] = a_0` (length of the first segment).\n- Iterate over segments starting from the second one:\n  - For each segment, update `dp[i][0]` as the minimum possible position when placing the segment in the negative direction.\n  - Update `dp[i][1]` for placement in the positive direction.\n  - Use previous segment's values from `dp[i-1]` to compute current possibilities.\n- The result is the minimum between `dp[n-1][0]` and `dp[n-1][1]`, which gives minimal coverage length.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'segments', 'axis', 'coverage'\n    Explanation: The requirement involves placing segments on an axis to determine the minimal coverage. A segment is a part of a line defined by two endpoints. The axis is an infinite line where these segments are placed. Coverage refers to the total length of the axis that is covered by at least one segment.\n\n# [phrase showing quantity relationship]\n    'minimal possible length': This means finding the smallest length of the axis that can be covered by the segments.\n    'sum of n over all test cases does not exceed 10^4': This indicates a constraint on the total number of segments across all test cases, which affects performance considerations.\n\n# [degree adverb]\n    'minimal': This indicates that we need to find the smallest possible coverage length.\n    Implementation: This can be achieved using dynamic programming to explore both placement directions for each segment and choose the one that results in the smallest coverage.\n\n# [code logic]\n    The steps for updating `dp[i][0]` and `dp[i][1]` should be implemented simultaneously within a loop iterating over each segment. This involves calculating both possible placements (left and right) for each segment and updating the DP table accordingly.\n\n# [edge case]\n    Test case with a single segment: \n    Input: 1\n           1\n    Output: 1\n    Explanation: With only one segment, the minimal coverage is simply its length.\n\n    Test case with segments of equal length:\n    Input: 3\n           2 2 2\n    Output: 2\n    Explanation: All segments can overlap completely, resulting in a minimal coverage equal to the length of one segment.\n\n    Test case with alternating long and short segments:\n    Input: 4\n           5 1 5 1\n    Output: 5\n    Explanation: The long segments can cover the short ones, resulting in a minimal coverage equal to the length of one long segment.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The dynamic programming approach inherently considers all possible placements and will naturally handle these scenarios by finding the minimal coverage.", "- name: \nBacktracking with Pruning\n- content: \n- Use a backtracking approach with pruning to explore all possible placements:\n  - Define a recursive function that tries placing each segment either to the left or right of the previous segment.\n  - Maintain a record of the current minimal coverage found.\n  - Prune branches that exceed the minimal coverage found so far.\n- Start by placing the first segment at [0, a_1].\n- Recursively try placing subsequent segments, updating the minimum coverage based on valid placements.\n- Return the smallest coverage length obtained after exploring all valid configurations.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'segments', 'axis', 'coverage'\n    Explanation: \n    - 'segments': Refers to the individual lengths that need to be placed on the axis.\n    - 'axis': The infinite line on which the segments are placed.\n    - 'coverage': The total length of the axis that is covered by the union of all segments.\n\n# [phrase showing quantity relationship]\n    'minimal possible length': Refers to finding the smallest length of coverage that can be achieved by optimally placing the segments.\n    Implementation: This involves calculating the union of all segments and finding the smallest possible coverage.\n\n# [degree adverb] \n    'minimal': Refers to the smallest possible length of coverage.\n    Implementation: Use a backtracking approach to explore all possible placements and prune branches that exceed the current minimal coverage.\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Define a recursive function for backtracking.\n    - Maintain a record of the current minimal coverage.\n    - Prune branches during recursion.\n    This can be done by integrating these steps into a single recursive function that handles placement and pruning.\n\n# [edge case] \n    Test case with one segment: \n    1\n    1\n    Expected output = 1\n    Explanation: With only one segment, the coverage is simply its length.\n\n    Test case with all segments of length 1:\n    3\n    1 1 1\n    Expected output = 3\n    Explanation: Each segment can be placed consecutively, resulting in a total coverage equal to the sum of their lengths.\n\n    Test case with segments of increasing lengths:\n    3\n    1 2 3\n    Expected output = 3\n    Explanation: The optimal placement results in a coverage equal to the largest segment length.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        def minimal_coverage(t, test_cases):\n            results = []\n            for n, segments in test_cases:\n                # Initialize coverage and position\n                coverage = 0\n                position = 0\n                \n                # Place first segment\n                position += segments[0]\n                coverage = position\n                \n                # Recursive function for backtracking\n                def place_segments(index, current_position, current_coverage):\n                    nonlocal coverage\n                    if index == n:\n                        coverage = min(coverage, current_coverage)\n                        return\n                    \n                    # Place segment to the right\n                    new_position = current_position + segments[index]\n                    place_segments(index + 1, new_position, max(current_coverage, new_position))\n                    \n                    # Place segment to the left\n                    new_position = current_position - segments[index]\n                    place_segments(index + 1, new_position, max(current_coverage, new_position))\n                \n                # Start recursion from second segment\n                place_segments(1, position, coverage)\n                \n                results.append(coverage)\n            \n            return results", '- name: \nGreedy Approach with Prefix Sums\n- content: \nThis solution uses a greedy algorithm combined with prefix sums to determine the minimal coverage length. The key idea is to maintain a running total of the segment lengths and decide the placement direction that minimizes coverage based on the accumulated lengths.\n\nSteps:\n1. Initialize a variable `total_length` to 0 to keep track of the overall length.\n2. For each test case, read the number of segments `n` and the list of segment lengths.\n3. Initialize two pointers: `prefix_sum` and `suffix_sum`, both set to 0 initially. These will track the sum of segment lengths as we consider placing them to the left or right.\n4. For each segment `i` from 1 to n, decide whether to place it to the left or right based on minimizing the total coverage:\n   - Update `prefix_sum` and `suffix_sum` by adding the current segment length.\n   - Calculate potential new coverage lengths if placing left or right.\n   - Choose the placement that results in a lower total coverage length.\n5. After processing all segments for the current test case, compute and store the minimal total coverage.\n6. Output the minimal coverage for each test case.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'segments\', \'axis\', \'coverage\'\n    Explanation: Segments are the lengths given that need to be placed on an axis. The axis is an infinite line where these segments are placed. Coverage refers to the total length of the axis that is covered by these segments.\n\n# [phrase showing quantity relationship]\n    \'minimal possible length\': means finding the smallest length of coverage that can be achieved by placing all segments on the axis.\n    Implementation: This can be achieved by strategically placing segments either to the left or right to minimize overlap and maximize coverage efficiency.\n\n# [degree adverb] \n    \'minimal\': means the smallest possible value.\n    Implementation: Use a greedy approach to ensure that each placement decision minimizes the total coverage length.\n\n# [code logic]\n    Steps 3 and 4 should be considered simultaneously.\n    "Initialize two pointers: `prefix_sum` and `suffix_sum`, both set to 0 initially."\n    "For each segment `i` from 1 to n, decide whether to place it to the left or right based on minimizing the total coverage."\n    This can be implemented in a loop where both prefix and suffix sums are updated simultaneously as each segment is considered.\n\n# [edge case] \n    Test case with all segments of length 1: \n    Input: 3\n           1 1 1\n    Output: 3\n    Explanation: Each segment can be placed consecutively without overlap, resulting in a total coverage of 3.\n\n    Test case with segments of varying lengths:\n    Input: 2\n           5 5\n    Output: 5\n    Explanation: Both segments can be placed such that they overlap completely, resulting in a total coverage of 5.\n\n    Test case with a single segment:\n    Input: 1\n           10\n    Output: 10\n    Explanation: Only one segment is present, so the coverage is equal to its length.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of using prefix and suffix sums with greedy placement decisions will naturally handle these scenarios.', "- name: \nTwo-Pointer Simulated Placement\n- content: \nThis solution uses a two-pointer technique to simulate segment placement, ensuring minimal overlap and coverage expansion.\nSteps:\n1. Use two pointers to track the minimum and maximum boundaries of the current coverage.\n2. Start by placing the first segment from [0, a_1].\n3. For each subsequent segment, decide placement such that it reduces overlap with existing coverage:\n   - If placing on the left decreases coverage more than placing on the right, place it on the left; otherwise, place it on the right.\n4. Continuously adjust the minimum and maximum pointers based on new placements.\n5. The minimal coverage is calculated as `max_pointer - min_pointer` after all segments are placed.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'segment placement'\n    Explanation: The requirement involves placing segments on an axis in a way that minimizes the total coverage length. Each segment can be placed either to the left or right of the previous segment's endpoint.\n\n# [phrase showing quantity relationship]\n    'minimal possible length': The goal is to find the smallest length of the axis that can be covered by the segments.\n    Implementation: This involves calculating the difference between the maximum and minimum pointers after all segments are placed.\n\n# [degree adverb] \n    'minimal': Refers to the smallest possible length of coverage on the axis.\n    Implementation: Use logic to decide placement of segments to minimize overlap and maximize efficient coverage.\n\n# [code logic]\n    Steps 1-5 should be implemented simultaneously as they involve continuous adjustment of pointers during segment placement. This can be done using a loop that iterates through each segment, updating the pointers based on placement decisions.\n\n# [edge case] \n    Test case with one segment: \n    Input: 1\n           5\n    Expected output: 5\n    Explanation: With only one segment, the coverage is simply the length of that segment.\n\n    Test case with all segments of length 1:\n    Input: 3\n           1 1 1\n    Expected output: 3\n    Explanation: Each segment can be placed consecutively without overlap, resulting in a total coverage equal to the sum of lengths.\n\n    Test case with alternating large and small segments:\n    Input: 4\n           10 1 10 1\n    Expected output: 20\n    Explanation: The large segments cover most of the axis, and small segments can be placed without increasing total coverage significantly.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of using two pointers to track minimum and maximum boundaries will naturally handle these scenarios.", "- name: \nTwo-Pointer Technique with Segmentation\n\n- content: \nImplement a two-pointer approach to manage segment coverage:\n- Start with pointers at 0 for both ends of the axis.\n- For each segment, compute both potential placements (left and right).\n- Use two pointers to track the current coverage interval `[min_pointer, max_pointer]`.\n- For each segment length `a_i`, choose a placement such that it extends the current interval minimally.\n- Update pointers accordingly: \n  - If placing left results in a smaller range, update `min_pointer`.\n  - Otherwise, update `max_pointer`.\n- The result is calculated as `max_pointer - min_pointer` after processing all segments.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'segments'\n    Explanation: Segments refer to the lengths that need to be placed on an axis, with each segment having a start and an end point.\n\n    'coverage'\n    Explanation: Coverage refers to the total length of the axis that is covered by at least one segment.\n\n# [phrase showing quantity relationship]\n    'minimal possible length'\n    Explanation: This means finding the smallest length of the axis that can be covered by arranging the segments optimally. In code, this involves calculating the difference between the maximum and minimum pointers after placing all segments.\n\n# [degree adverb]\n    'minimal'\n    Explanation: This indicates that the goal is to achieve the smallest possible coverage length. In code, this is achieved by choosing placements that extend the current interval minimally.\n\n# [code logic]\n    The steps involving updating `min_pointer` and `max_pointer` should be considered simultaneously. For each segment, both potential placements (left and right) should be evaluated in one code block to decide which placement results in minimal coverage extension.\n\n# [edge case]\n    Test case with a single segment: \n    Input: 1\n           1\n    Expected output: 1\n    Explanation: With only one segment of length 1, the minimal coverage is simply the length of that segment.\n\n    Test case with all segments of length 1:\n    Input: 3\n           1 1 1\n    Expected output: 3\n    Explanation: Each segment can be placed consecutively, resulting in a total coverage of 3.\n\n    Test case with segments of increasing lengths:\n    Input: 3\n           1 2 3\n    Expected output: 3\n    Explanation: The segments can be placed such that they overlap optimally, resulting in a minimal coverage of 3.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of using two pointers to track the minimal and maximal coverage will naturally handle these cases."]
----------
False
----------
0
multi-gen-prompt:
Lord Omkar would like to have a tree with n nodes (3 ≤ n ≤ 10^5) and has asked his disciples to construct the tree. However, Lord Omkar has created m (1 ≤ m < n) restrictions to ensure that the tree will be as heavenly as possible.

A tree with n nodes is an undirected graph that is connected, and it has n nodes and n-1 edges. Note that for any two nodes, there is exactly one simple path between them, where a simple path is a path between two nodes that does not contain any node more than once.

Here is an example of a tree:

<image>

A restriction consists of 3 pairwise distinct integers, a, b, and c (1 ≤ a,b,c ≤ n). This restriction signifies that node b cannot lie on the simple path between node a and node c. 

Can you help Lord Omkar and become his most trusted disciple? You will need to find heavenly trees for multiple sets of restrictions. It can be shown that a heavenly tree will always exist for any set of restrictions under the given constraints.

Input

Each test contains multiple test cases. The first line contains the number of test cases t (1 ≤ t ≤ 10^4). Description of the test cases follows.

The first line of each test case contains two integers, n and m (3 ≤ n ≤ 10^5, 1 ≤ m < n), representing the size of the tree and the number of restrictions.

The i-th of the next m lines contains three integers a_i, b_i, c_i (1 ≤ a_i, b_i, c_i ≤ n, a, b, c are distinct), signifying that node b_i cannot lie on the simple path between nodes a_i and c_i. 

It is guaranteed that the sum of n across all test cases will not exceed 10^5.

Output

For each test case, output n-1 lines representing the n-1 edges in the tree. On each line, output two integers u and v (1 ≤ u, v ≤ n, u ≠ v) signifying that there is an edge between nodes u and v. Given edges have to form a tree that satisfies Omkar's restrictions.

Example

Input


2
7 4
1 2 3
3 4 5
5 6 7
6 5 4
5 3
1 2 3
2 3 4
3 4 5


Output


1 2
1 3
3 5
3 4
2 7
7 6
5 1
1 3
3 2
2 4

Note

The output of the first sample case corresponds to the following tree: 

<image> For the first restriction, the simple path between 1 and 3 is 1, 3, which doesn't contain 2. The simple path between 3 and 5 is 3, 5, which doesn't contain 4. The simple path between 5 and 7 is 5, 3, 1, 2, 7, which doesn't contain 6. The simple path between 6 and 4 is 6, 7, 2, 1, 3, 4, which doesn't contain 5. Thus, this tree meets all of the restrictions.

The output of the second sample case corresponds to the following tree: 

<image>
multi-gen-prompt:
Lord Omkar would like to have a tree with n nodes (3 ≤ n ≤ 10^5) and m (1 ≤ m < n) restrictions to ensure that the tree will be as heavenly as possible. A tree with n nodes is an connected undirected graph with n nodes and n-1 edges, and for any two nodes, there is exactly one simple path between them, where a simple path is a path between two nodes that does not contain any node more than once.

Here is an example of a tree: 

<image>

A restriction consists of 3 pairwise distinct integers, a, b, and c (1 ≤ a,b,c ≤ n). It signifies that node b cannot lie on the simple path between node a and node c. 

Can you help Lord Omkar and become his most trusted disciple? You will need to find heavenly trees for multiple sets of restrictions. It can be shown that a heavenly tree will always exist for any set of restrictions under the given constraints.

Input

Each test contains multiple test cases. The first line contains the number of test cases t (1 ≤ t ≤ 10^4). Description of the test cases follows.

The first line of each test case contains two integers, n and m (3 ≤ n ≤ 10^5, 1 ≤ m < n), representing the size of the tree and the number of restrictions.

The i-th of the next m lines contains three integers a_i, b_i, c_i (1 ≤ a_i, b_i, c_i ≤ n, a, b, c are distinct), signifying that node b_i cannot lie on the simple path between nodes a_i and c_i. 

It is guaranteed that the sum of n across all test cases will not exceed 10^5.

Output

For each test case, output n-1 lines representing the n-1 edges in the tree. On each line, output two integers u and v (1 ≤ u, v ≤ n, u ≠ v) signifying that there is an edge between nodes u and v. Given edges have to form a tree that satisfies Omkar's restrictions.

Example

Input


2
7 4
1 2 3
3 4 5
5 6 7
6 5 4
5 3
1 2 3
2 3 4
3 4 5


Output


1 2
1 3
3 5
3 4
2 7
7 6
5 1
1 3
3 2
2 4

Note

The output of the first sample case corresponds to the following tree: 

<image> For the first restriction, the simple path between 1 and 3 is 1, 3, which doesn't contain 2. The simple path between 3 and 5 is 3, 5, which doesn't contain 4. The simple path between 5 and 7 is 5, 3, 1, 2, 7, which doesn't contain 6. The simple path between 6 and 4 is 6, 7, 2, 1, 3, 4, which doesn't contain 5. Thus, this tree meets all of the restrictions.

The output of the second sample case corresponds to the following tree: 

<image>
generating with gpt-4o
----------
['def construct_star_tree(n):\n    # Create a star-shaped tree with node 1 as the center\n    edges = []\n    for i in range(2, n + 1):\n        edges.append((1, i))\n    return edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2 + 3 * m  # Skip over the restrictions\n        \n        # Construct the star-shaped tree for this test case\n        edges = construct_star_tree(n)\n        results.append(edges)\n    \n    for edges in results:\n        for u, v in edges:\n            print(u, v)', 'def construct_heavenly_tree(n, m, restrictions):\n    # We will use node 1 as the central node for simplicity\n    central_node = 1\n    edges = []\n    \n    # Connect the central node to all other nodes\n    for node in range(2, n + 1):\n        edges.append((central_node, node))\n    \n    return edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        restrictions = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            c = int(data[index + 2])\n            restrictions.append((a, b, c))\n            index += 3\n        \n        # Construct the tree for this test case\n        edges = construct_heavenly_tree(n, m, restrictions)\n        results.append(edges)\n    \n    # Output all results\n    for edges in results:\n        for u, v in edges:\n            print(u, v)', 'def construct_tree(n):\n    # Select node 1 as the root and connect all other nodes to it\n    edges = []\n    for i in range(2, n + 1):\n        edges.append((1, i))\n    return edges\n\ndef solve(test_cases):\n    results = []\n    for n, m, restrictions in test_cases:\n        # Construct the tree for each test case\n        tree_edges = construct_tree(n)\n        results.append(tree_edges)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        restrictions = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            c = int(data[index + 2])\n            restrictions.append((a, b, c))\n            index += 3\n        \n        test_cases.append((n, m, restrictions))\n    \n    results = solve(test_cases)\n    \n    for result in results:\n        for u, v in result:\n            print(u, v)', 'def construct_tree(n, m, restrictions):\n    # Select node 1 as the central node\n    central_node = 1\n    edges = []\n    \n    # Connect the central node to all other nodes\n    for node in range(2, n + 1):\n        edges.append((central_node, node))\n    \n    return edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        restrictions = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            c = int(data[index + 2])\n            restrictions.append((a, b, c))\n            index += 3\n        \n        # Construct the tree for this test case\n        edges = construct_tree(n, m, restrictions)\n        results.append(edges)\n    \n    # Output the results\n    for edges in results:\n        for u, v in edges:\n            print(u, v)', 'def construct_star_tree(n):\n    # Construct a star tree with node 1 as the center\n    edges = []\n    for i in range(2, n + 1):\n        edges.append((1, i))\n    return edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2 + 3 * m  # Skip over the restrictions as they are not needed\n        \n        # Construct the star tree for this test case\n        edges = construct_star_tree(n)\n        results.append(edges)\n    \n    # Output all results\n    for edges in results:\n        for u, v in edges:\n            print(u, v)', 'def construct_tree(n, m, restrictions):\n    # We will use node 1 as the central node and connect it to all other nodes\n    edges = []\n    for i in range(2, n + 1):\n        edges.append((1, i))\n    return edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        restrictions = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            c = int(data[index + 2])\n            restrictions.append((a, b, c))\n            index += 3\n        \n        # Construct the tree for this test case\n        edges = construct_tree(n, m, restrictions)\n        results.append(edges)\n    \n    for result in results:\n        for u, v in result:\n            print(u, v)', 'def solve_heavenly_tree(test_cases):\n    results = []\n    for n, m, restrictions in test_cases:\n        # Select node 1 as the central node\n        central_node = 1\n        edges = []\n        # Connect all other nodes directly to the central node\n        for node in range(2, n + 1):\n            edges.append((central_node, node))\n        results.append(edges)\n    return results\n\ndef parse_input():\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        restrictions = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            c = int(data[index + 2])\n            restrictions.append((a, b, c))\n            index += 3\n        \n        test_cases.append((n, m, restrictions))\n    \n    return test_cases\n\nif __name__ == "__main__":\n    test_cases = parse_input()\n    results = solve_heavenly_tree(test_cases)\n    \n    for edges in results:\n        for u, v in edges:\n            print(u, v)', 'def construct_tree(n, restrictions):\n    edges = []\n    central_node = 1\n    # Connect the central node to every other node\n    for i in range(2, n + 1):\n        edges.append((central_node, i))\n    # The star-like structure inherently satisfies all restrictions\n    return edges\n\ndef solve(test_cases):\n    results = []\n    for n, m, restrictions in test_cases:\n        edges = construct_tree(n, restrictions)\n        results.append(edges)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        restrictions = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            c = int(data[index + 2])\n            index += 3\n            restrictions.append((a, b, c))\n        \n        test_cases.append((n, m, restrictions))\n    \n    results = solve(test_cases)\n    \n    for edges in results:\n        for u, v in edges:\n            print(u, v)', 'def construct_tree(n):\n    # Choose node 1 as the central node and connect all other nodes to it\n    edges = []\n    for i in range(2, n + 1):\n        edges.append((1, i))\n    return edges\n\ndef solve(test_cases):\n    results = []\n    for n, m, restrictions in test_cases:\n        # We don\'t need to use restrictions as the central node approach satisfies all\n        edges = construct_tree(n)\n        results.append(edges)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        restrictions = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            c = int(data[index + 2])\n            restrictions.append((a, b, c))\n            index += 3\n        \n        test_cases.append((n, m, restrictions))\n    \n    results = solve(test_cases)\n    \n    for edges in results:\n        for u, v in edges:\n            print(u, v)', 'def construct_tree(n, m, restrictions):\n    # We will use node 1 as the central node and connect it to all other nodes\n    edges = []\n    for i in range(2, n + 1):\n        edges.append((1, i))\n    return edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        restrictions = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            c = int(data[index + 2])\n            restrictions.append((a, b, c))\n            index += 3\n        \n        # Construct the tree for this test case\n        edges = construct_tree(n, m, restrictions)\n        results.append(edges)\n    \n    # Output all results\n    for edges in results:\n        for u, v in edges:\n            print(u, v)']
----------
['- name: \nUse a star-shaped tree centered at node 1\n\n- content: \nTo ensure the restrictions are met, construct a star-shaped tree with node 1 as the center. Connect all other nodes directly to node 1. This structure guarantees that for any restriction (a, b, c), the node b cannot lie on the path between a and c because all paths go through node 1, thereby isolating node b from the paths between any other pair of nodes. This approach is efficient given the constraints.\nSteps:\n1. For each test case, select node 1 as the central node.\n2. For each node from 2 to n, create an edge connecting it to node 1.\n3. Output the n-1 edges for each test case.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected undirected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    \'restriction\'\n    Explanation: A restriction is a condition where a specific node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    \'n nodes and n-1 edges\': This indicates that the tree must have exactly n-1 edges for n nodes.\n    Implementation: Ensure that the output contains exactly n-1 edges for each test case.\n\n# [degree adverb]\n    \'exactly\': This means there is only one simple path between any two nodes in the tree.\n    Implementation: The tree structure inherently ensures this property, so no additional code is needed.\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - "For each test case, select node 1 as the central node."\n    - "For each node from 2 to n, create an edge connecting it to node 1."\n    These steps can be implemented in a single loop that iterates over nodes from 2 to n, creating edges with node 1.\n\n# [edge case]\n    Edge Case 1: n = 3, m = 1, restriction = (1, 2, 3)\n    Expected Output: \n    1 3\n    1 2\n    Explanation: The star-shaped tree with node 1 as the center satisfies the restriction since node 2 is not on the path between nodes 1 and 3.\n\n    Edge Case 2: n = 4, m = 2, restrictions = (1, 2, 3), (3, 4, 2)\n    Expected Output:\n    1 2\n    1 3\n    1 4\n    Explanation: The star-shaped tree with node 1 as the center satisfies both restrictions since node 2 is not on the path between nodes 1 and 3, and node 4 is not on the path between nodes 3 and 2.\n\n    Edge Case 3: n = 5, m = 0\n    Expected Output:\n    1 2\n    1 3\n    1 4\n    1 5\n    Explanation: With no restrictions, any tree structure is valid. The star-shaped tree is a simple solution.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The star-shaped tree structure inherently satisfies all restrictions by isolating each node from paths between other pairs of nodes.', "- name: \nCentral Node Strategy\n\n- content: \nThe idea is to construct a tree by selecting a central node that is connected to all other nodes, which simplifies satisfying restrictions.\n1. For each test case, select an arbitrary node as the central node (e.g., node 1).\n2. Connect this central node to all other nodes in the graph. This results in a star-shaped tree where the central node is connected directly to all other nodes.\n3. This configuration ensures that any node specified in the restrictions cannot lie on the path between two other nodes since the path will always go through the central node and directly to another node.\n4. Output the edges of this star-shaped tree.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected undirected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    'restriction'\n    Explanation: A restriction specifies that a particular node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    'n nodes and n-1 edges': This indicates the relationship between the number of nodes and edges in a tree. In code, this can be implemented by ensuring the output has exactly n-1 edges for n nodes.\n\n# [degree adverb]\n    'heavenly': This implies the tree must satisfy all given restrictions, ensuring no node lies on a restricted path.\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Select a central node.\n    - Connect this central node to all other nodes.\n    This can be done in a single loop where each node is connected to the central node.\n\n# [edge case]\n    Test case with minimum nodes and restrictions:\n    3 1\n    1 2 3\n    Expected output:\n    1 2\n    1 3\n    Explanation: With only three nodes, the central node (1) connects directly to the other two nodes (2 and 3), satisfying the restriction.\n\n    Test case with maximum nodes and minimum restrictions:\n    100000 1\n    1 2 3\n    Expected output:\n    1 2\n    1 3\n    ...\n    1 100000\n    Explanation: The central node (1) connects directly to all other nodes, ensuring no node lies on a restricted path.\n\n    Test case with multiple restrictions:\n    5 3\n    1 2 3\n    2 3 4\n    3 4 5\n    Expected output:\n    1 2\n    1 3\n    1 4\n    1 5\n    Explanation: The central node (1) connects directly to all other nodes, satisfying all restrictions.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The central node strategy inherently satisfies all restrictions by design.", "- name: \nCentral Node Approach\n\n- content: \nThe goal is to construct a tree that satisfies given restrictions. One straightforward approach is to select a central node (typically the root) and connect all other nodes directly to this node. This ensures that no node lies on the simple path between two other nodes, satisfying all restrictions by default. Here's how to implement this approach:\n\n1. Select an arbitrary node as the root. For simplicity, choose node 1.\n2. Connect all other nodes (2 to n) directly to node 1, forming a star-shaped tree.\n3. Return the edges connecting each node to the root.\n\nThis approach guarantees that the tree satisfies all restrictions, as no intermediate node exists on any path between two non-root nodes.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected undirected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    'restriction'\n    Explanation: A restriction specifies that a particular node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    'n nodes': The tree must have exactly n nodes.\n    'n-1 edges': The tree must have exactly n-1 edges to be a valid tree.\n    '1 ≤ m < n': The number of restrictions is less than the number of nodes.\n\n# [degree adverb]\n    'most trusted': This implies the solution should be optimal and correct under all constraints.\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Select an arbitrary node as the root (e.g., node 1).\n    - Connect all other nodes directly to this root node.\n    This can be done in a single loop where each node from 2 to n is connected to node 1.\n\n# [edge case]\n    Case 1: n = 3, m = 1, restrictions = [(1, 2, 3)]\n    Expected output: \n    1 2\n    1 3\n    Explanation: With only three nodes, connecting both nodes directly to node 1 satisfies the restriction.\n\n    Case 2: n = 4, m = 3, restrictions = [(1, 2, 3), (2, 3, 4), (3, 4, 1)]\n    Expected output:\n    1 2\n    1 3\n    1 4\n    Explanation: Connecting all nodes directly to node 1 ensures no node lies on the path between any two other nodes.\n\n    Case 3: n = 5, m = 4, restrictions = [(1, 2, 3), (2, 3, 4), (3, 4, 5), (4, 5, 1)]\n    Expected output:\n    1 2\n    1 3\n    1 4\n    1 5\n    Explanation: Again, connecting all nodes directly to node 1 satisfies all restrictions.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The central node approach inherently satisfies all restrictions by design.", '- name: \nCentral Node Strategy\n\n- content: \nTo construct the tree that adheres to the restrictions, we can identify a central node that will connect to all other nodes. This ensures that any path from one node to another will necessarily go through the central node, allowing us to easily satisfy any restrictions.\n\nSteps:\n1. Select a node (e.g., node 1) as the central node.\n2. Connect this central node to all other nodes in the tree.\n3. This forms a star-like structure with the central node at the center.\n4. For each restriction (a_i, b_i, c_i), confirm that node b_i is not on the direct path between a_i and c_i (since all paths pass through the central node, b_i won\'t be on the path unless it\'s one of a_i or c_i).\n5. Output the edges between the central node and all other nodes.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    \'restriction\'\n    Explanation: A restriction specifies that a particular node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    \'n nodes and n-1 edges\': This indicates the relationship between the number of nodes and edges in a tree. In code, this can be implemented by ensuring the number of edges is always one less than the number of nodes.\n\n# [degree adverb] \n    \'most trusted\': This implies achieving the best possible solution that adheres to all restrictions.\n\n# [code logic]\n    Steps 1 and 2 should be implemented simultaneously:\n    "Select a node (e.g., node 1) as the central node" and "Connect this central node to all other nodes in the tree" can be done in one loop where we iterate over all nodes and connect them to the central node.\n\n# [edge case] \n    Test case with minimum nodes and restrictions:\n    Input: 3 1\n           1 2 3\n    Expected Output: \n    1 3\n    Explanation: With only three nodes, the only possible tree structure is connecting node 1 to node 3 directly, satisfying the restriction.\n\n    Test case with maximum nodes and minimum restrictions:\n    Input: 100000 1\n           1 2 3\n    Expected Output: \n    1 2\n    1 3\n    ...\n    Explanation: The central node connects to all other nodes, ensuring no restrictions are violated.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The central node strategy inherently handles all restrictions by ensuring paths go through the central node, thus avoiding any restricted paths.', "- name: \nCentralized Star Tree Approach\n\n- content: \n- We can construct a tree with a star-like structure where one central node is connected to all other nodes.\n- Choose any node, say node 1, as the center of the tree.\n- Connect node 1 to all other nodes (2, 3, ..., n) to form the edges.\n- This ensures that for any restriction (a, b, c), node b will not lie on the simple path between a and c because all paths go through the center node.\n- This approach is efficient with O(n) complexity per test case and satisfies all given constraints.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    'restriction'\n    Explanation: A restriction specifies that a particular node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    'n nodes and n-1 edges': This indicates the relationship between the number of nodes and edges in a tree. In code, this can be implemented by ensuring the output has n-1 edges for n nodes.\n\n# [degree adverb] \n    'heavenly': This implies that the tree must satisfy all given restrictions to be considered optimal or ideal.\n\n# [code logic]\n    The plan suggests constructing a centralized star tree, where one node is connected to all other nodes. This ensures that no node lies on the path between any two other nodes, satisfying all restrictions simultaneously.\n\n# [edge case] \n    Test case with minimum nodes and restrictions:\n    3 1\n    1 2 3\n    Expected output:\n    1 2\n    1 3\n    Explanation: With only three nodes, the simplest tree is a star with node 1 as the center, satisfying the restriction.\n\n    Test case with maximum nodes and minimum restrictions:\n    10^5 1\n    1 2 3\n    Expected output:\n    1 2\n    1 3\n    ...\n    1 100000\n    Explanation: The centralized star approach works efficiently even with maximum nodes, ensuring node 2 is not on the path between node 1 and node 3.\n\n    Test case with multiple restrictions:\n    5 4\n    1 2 3\n    2 3 4\n    3 4 5\n    4 5 1\n    Expected output:\n    1 2\n    1 3\n    1 4\n    1 5\n    Explanation: The centralized star approach ensures no restricted node lies on the path between any two other nodes.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The centralized star approach inherently satisfies all restrictions by design.", "- name: \nCentral Node Approach\n\n- content: \nTo construct a tree while satisfying restrictions, start by choosing a central node that will be connected to all other nodes. This ensures that there can be no node b in the path between any two other nodes a and c, as the path between a and c will always pass through the central node.\n1. For each test case, select a central node, say node 1.\n2. Connect node 1 to all other nodes (from 2 to n). This creates a star-like structure.\n3. For each restriction (a_i, b_i, c_i), since node b_i can't lie on the simple path between a_i and c_i, ensure that a_i and c_i are directly connected to the central node, making node b_i irrelevant on their path.\n4. Output the edges connecting node 1 with all other nodes.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected, undirected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    'restriction'\n    Explanation: A restriction specifies that a particular node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    'n nodes and n-1 edges': This indicates the relationship between the number of nodes and edges in a tree. In code, this can be implemented by ensuring that the number of edges is always one less than the number of nodes.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Select a central node (e.g., node 1).\n    - Connect this central node to all other nodes to form a star-like structure.\n    This can be done in a single loop that iterates over all nodes from 2 to n, creating an edge between node 1 and each of these nodes.\n\n# [edge case]\n    Test case with minimum nodes and restrictions:\n    Input: 3 1\n           1 2 3\n    Expected Output:\n    1 2\n    1 3\n    Explanation: With only three nodes, the only possible tree structure is connecting both nodes 2 and 3 to node 1, which satisfies the restriction.\n\n    Test case with maximum nodes and minimum restrictions:\n    Input: 100000 1\n           1 2 3\n    Expected Output: \n    (Output will be a star-like structure with node 1 connected to all other nodes)\n    Explanation: The central node approach ensures that any single restriction is satisfied by connecting all nodes directly to node 1.\n\n    Test case with maximum nodes and maximum restrictions:\n    Input: 100000 99999\n           (restrictions are such that they do not affect the central node approach)\n    Expected Output:\n    (Output will be a star-like structure with node 1 connected to all other nodes)\n    Explanation: The central node approach inherently satisfies all restrictions by design.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The central node approach inherently satisfies all possible restrictions by ensuring that no node b can lie on the path between any two other nodes a and c, as all paths go through the central node.", "- name: \nCentral Node Strategy\n\n- content: \nThis approach leverages the idea of selecting a central node and connecting all other nodes directly to it, ensuring no restricted nodes lie on any paths.\n- Select a node (e.g., node 1) as the central node.\n- For each node from 2 to n, connect it directly to the central node. This guarantees that any path between two non-central nodes goes through the central node.\n- Check each restriction (a, b, c). Since node b is not directly connected between a and c due to the central hub structure, all restrictions are inherently satisfied.\n- Output all the edges from the central node to every other node. This results in a star-like tree structure.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected undirected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    'restriction'\n    Explanation: A restriction specifies that a particular node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    'n nodes and n-1 edges': This indicates the relationship between the number of nodes and edges in a tree. In code, this can be implemented by ensuring that the output contains exactly n-1 edges for n nodes.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Select a central node.\n    - Connect all other nodes directly to this central node.\n    This can be done in a single loop where each node from 2 to n is connected to the central node.\n\n# [edge case]\n    Case 1: n = 3, m = 1, restriction = [(1, 2, 3)]\n    Expected output: \n    1 3\n    1 2\n    Explanation: With only three nodes, the simplest tree structure is a star with one central node. The restriction is inherently satisfied as node 2 is not on the path between nodes 1 and 3.\n\n    Case 2: n = 4, m = 2, restrictions = [(1, 2, 3), (3, 4, 1)]\n    Expected output:\n    1 2\n    1 3\n    1 4\n    Explanation: By connecting all nodes to node 1, both restrictions are satisfied as node 2 is not on the path between nodes 1 and 3, and node 4 is not on the path between nodes 3 and 1.\n\n    Case 3: n = 5, m = 0\n    Expected output:\n    1 2\n    1 3\n    1 4\n    1 5\n    Explanation: With no restrictions, any star-like structure with a central node satisfies the tree condition.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The central node strategy inherently satisfies all restrictions by design.", '- name: \nCentral Node Strategy\n\n- content: \nThis approach involves selecting a central node and constructing a star-like structure that satisfies all the given restrictions.\nSteps:\n1. Choose a central node arbitrarily, say node 1.\n2. Connect node 1 to every other node (from 2 to n) directly.\n3. For each restriction (a, b, c):\n   - Ensure node b is not on the direct path between nodes a and c by leveraging the star-like structure.\n   - Since all nodes except the central node are leaf nodes, the simple path between any two nodes is direct without involving other nodes.\n4. Output all the edges forming the tree as specified.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected undirected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    \'restriction\'\n    Explanation: A restriction specifies that a particular node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    \'n nodes and n-1 edges\': This indicates the relationship between the number of nodes and edges in a tree. In code, this can be implemented by ensuring the output has exactly n-1 edges for n nodes.\n\n# [degree adverb] \n    \'most trusted\': This implies the need for a solution that meets all restrictions effectively, ensuring the tree is constructed correctly according to the given constraints.\n\n# [code logic]\n    The steps 2 and 3 should be considered simultaneously:\n    "Connect node 1 to every other node (from 2 to n) directly" and "Ensure node b is not on the direct path between nodes a and c by leveraging the star-like structure."\n    This can be implemented by iterating through all nodes and connecting them to the central node, while checking each restriction to ensure compliance.\n\n# [edge case] \n    Test case with minimum nodes and restrictions:\n    Input: 3 1\n           1 2 3\n    Expected Output: \n    1 3\n    Explanation: With only three nodes, the only possible edge that satisfies the restriction is between nodes 1 and 3, as node 2 cannot be on the path between nodes 1 and 3.\n\n    Test case with maximum nodes and no restrictions:\n    Input: 100000 0\n    Expected Output: \n    (Output should contain edges forming a star-like structure with node 1 connected to all other nodes)\n    Explanation: With no restrictions, a simple star-like structure can be formed with node 1 connected to all other nodes.\n\n    Test case with multiple restrictions affecting the same node:\n    Input: 5 3\n           1 2 3\n           2 3 4\n           3 4 5\n    Expected Output: \n    (Output should ensure node 2 is not on paths between specified pairs)\n    Explanation: The output should ensure that node 2 is not on the path between nodes specified in each restriction.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        def construct_tree(n, restrictions):\n            edges = []\n            central_node = 1\n            for i in range(2, n+1):\n                edges.append((central_node, i))\n            for a, b, c in restrictions:\n                # Ensure compliance with restrictions\n                if b == central_node:\n                    # Adjust connections if necessary\n                    pass\n            return edges', '- name: \nCentral Node Approach\n\n- content: \nTo construct the tree satisfying the restrictions, we can employ a simple approach by making one node the "central" node and connecting all other nodes directly to this central node. This ensures that no node lies on a path between any two other nodes, thus satisfying all restrictions:\n1. Choose any node (for example, node 1) as the central node.\n2. For each of the other nodes from 2 to n, create an edge between this node and the central node.\n3. Output these edges. Since every node is directly connected to the central node, no node can lie on a path between any other two nodes, satisfying all restrictions.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected undirected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    \'restriction\'\n    Explanation: A restriction specifies that a particular node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    \'n nodes\': The tree has n nodes.\n    \'n-1 edges\': The tree has n-1 edges, which is a characteristic of a tree.\n    \'1 ≤ m < n\': The number of restrictions is less than the number of nodes.\n    \'1 ≤ a, b, c ≤ n\': The values for nodes in restrictions are within the range of node indices.\n\n# [degree adverb]\n    \'most trusted\': Indicates the highest level of trust or reliability.\n    \'heavenly\': Implies the best or most ideal form of the tree under given constraints.\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously:\n    - Choose a central node.\n    - Connect all other nodes directly to this central node.\n    This can be done in a single loop where each node from 2 to n is connected to the central node.\n\n# [edge case]\n    Case 1: n = 3, m = 1, restriction = (1, 2, 3)\n    Expected output: \n    1 3\n    1 2\n    Explanation: Node 2 cannot lie on the path between nodes 1 and 3. Connecting both nodes directly to node 1 satisfies this restriction.\n\n    Case 2: n = 4, m = 2, restrictions = (1, 2, 3), (3, 4, 1)\n    Expected output:\n    1 2\n    1 3\n    1 4\n    Explanation: Node 2 cannot lie on the path between nodes 1 and 3, and node 4 cannot lie on the path between nodes 3 and 1. Connecting all nodes directly to node 1 satisfies both restrictions.\n\n    Case 3: n = 5, m = 3, restrictions = (2, 3, 4), (4, 5, 2), (5, 1, 3)\n    Expected output:\n    1 2\n    1 3\n    1 4\n    1 5\n    Explanation: Each restriction is satisfied by connecting all nodes directly to node 1.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The central node approach inherently satisfies all restrictions by ensuring no node lies on a path between any two other nodes.', '- name: \nCentral Node Selection\n\n- content: \nThe goal is to construct a tree such that each restriction is satisfied. A tree structure can be formed by selecting a central node and connecting it to all other nodes, which ensures that many restrictions can be inherently satisfied since paths tend to avoid intermediate nodes. Here\'s the approach:\n1. Choose a node to act as the central node; often node 1 is a good choice due to simplicity.\n2. Connect this central node to all other nodes directly.\n3. Check the restrictions: By connecting directly, it ensures that if a node b cannot lie on the path between nodes a and c, then it\'s possible to reroute the path through the central node to avoid b.\n4. Output the edges formed by directly connecting every other node to the central node.\n5. This solution is efficient since forming n-1 edges is linear, and checking m restrictions also remains linear.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected undirected graph with n nodes and n-1 edges, where there is exactly one simple path between any two nodes.\n\n    \'restriction\'\n    Explanation: A restriction specifies that a particular node cannot lie on the simple path between two other nodes.\n\n# [phrase showing quantity relationship]\n    \'n nodes and n-1 edges\': This indicates that the tree must have exactly n-1 edges to be a valid tree with n nodes.\n    \n    \'1 ≤ m < n\': This specifies that the number of restrictions is at least 1 and less than the number of nodes.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 1 and 2 should be implemented simultaneously:\n    "Choose a node to act as the central node; often node 1 is a good choice due to simplicity."\n    "Connect this central node to all other nodes directly."\n    These steps can be implemented in a single loop where you iterate over all nodes and connect them to the central node.\n\n# [edge case] \n    Case 1: n = 3, m = 1, restrictions = [(1, 2, 3)]\n    Expected output: 1 3, 3 2\n    Explanation: The only restriction is that node 2 cannot be on the path between nodes 1 and 3. By connecting node 1 to node 3 and node 3 to node 2, the restriction is satisfied.\n\n    Case 2: n = 4, m = 2, restrictions = [(1, 2, 3), (3, 4, 1)]\n    Expected output: 1 3, 3 2, 3 4\n    Explanation: Node 2 cannot be on the path between nodes 1 and 3, and node 4 cannot be on the path between nodes 3 and 1. By connecting node 1 to node 3, node 3 to node 2, and node 3 to node 4, both restrictions are satisfied.\n\n    Case 3: n = 5, m = 0\n    Expected output: Any valid tree structure with n-1 edges\n    Explanation: With no restrictions, any valid tree structure is acceptable.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of connecting all nodes to a central node inherently satisfies the restrictions by rerouting paths through the central node.']
----------
False
----------
0
multi-gen-prompt:
On an endless checkered sheet of paper, n cells are chosen and colored in three colors, where n is divisible by 3. It turns out that there are exactly n/3 marked cells of each of three colors! This means that each color is evenly represented. Each color has exactly one-third of the total number of marked cells.

Find the largest such k that it's possible to choose k/3 cells of each color, remove all other marked cells, and then select three rectangles with sides parallel to the grid lines so that the following conditions hold:

  * No two rectangles can intersect (but they can share a part of the boundary). In other words, the area of intersection of any two of these rectangles must be 0.
  * The i-th rectangle contains all the chosen cells of the i-th color and no chosen cells of other colors, for i = 1, 2, 3. 

Input

The first line of the input contains a single integer n — the number of the marked cells (3 ≤ n ≤ 10^5, n is divisible by 3).

The i-th of the following n lines contains three integers x_i, y_i, c_i (|x_i|,|y_i| ≤ 10^9; 1 ≤ c_i ≤ 3), where (x_i, y_i) are the coordinates of the i-th marked cell and c_i is its color.

It's guaranteed that all cells (x_i, y_i) in the input are distinct, and that there are exactly n/3 cells of each color.

Output

Output a single integer k — the largest number of cells you can leave.

Examples

Input


9
2 3 1
4 1 2
2 1 3
3 4 1
5 3 2
4 4 3
2 4 1
5 2 2
3 5 3


Output


6


Input


3
1 1 1
2 2 2
3 3 3


Output


3

Note

In the first sample, it's possible to leave 6 cells with indexes 1, 5, 6, 7, 8, 9.

In the second sample, it's possible to leave 3 cells with indexes 1, 2, 3.
multi-gen-prompt:
On an endless checkered sheet of paper, n cells are chosen and colored in three colors, where n is divisible by 3, turning out that there are exactly n/3 marked cells of each of three colors. Find the largest such k that it's possible to choose k/3 cells of each color, remove all other marked cells, and then select three rectangles with sides parallel to the grid lines so that the following conditions hold:

  * No two rectangles can intersect (but they can share a part of the boundary). In other words, the area of intersection of any two of these rectangles must be 0.
  * The i-th rectangle contains all the chosen cells of the i-th color and no chosen cells of other colors, for i = 1, 2, 3.

Input

The first line of the input contains a single integer n — the number of the marked cells (3 ≤ n ≤ 10^5, n is divisible by 3).

The i-th of the following n lines contains three integers x_i, y_i, c_i (|x_i|,|y_i| ≤ 10^9; 1 ≤ c_i ≤ 3), where (x_i, y_i) are the coordinates of the i-th marked cell and c_i is its color.

It's guaranteed that all cells (x_i, y_i) in the input are distinct, and that there are exactly n/3 cells of each color.

Output

Output a single integer k — the largest number of cells you can leave.

Examples

Input


9
2 3 1
4 1 2
2 1 3
3 4 1
5 3 2
4 4 3
2 4 1
5 2 2
3 5 3


Output


6


Input


3
1 1 1
2 2 2
3 3 3


Output


3

Note

In the first sample, it's possible to leave 6 cells with indexes 1, 5, 6, 7, 8, 9.

In the second sample, it's possible to leave 3 cells with indexes 1, 2, 3.
generating with gpt-4o
----------
['def can_form_rectangles(k, color_cells):\n    # For each color, try to form a rectangle that contains exactly k/3 cells\n    for color in range(1, 4):\n        cells = color_cells[color]\n        if len(cells) < k // 3:\n            return False\n        \n        # Try to find a rectangle that contains exactly k/3 cells\n        for i in range(len(cells)):\n            for j in range(i + k // 3 - 1, len(cells)):\n                min_x = min(cells[i][0], cells[j][0])\n                max_x = max(cells[i][0], cells[j][0])\n                min_y = min(cells[i][1], cells[j][1])\n                max_y = max(cells[i][1], cells[j][1])\n                \n                count = 0\n                for x, y in cells:\n                    if min_x <= x <= max_x and min_y <= y <= max_y:\n                        count += 1\n                    if count == k // 3:\n                        break\n                \n                if count == k // 3:\n                    break\n            \n            if count == k // 3:\n                break\n        \n        if count < k // 3:\n            return False\n    \n    return True\n\ndef find_max_k(n, cells):\n    # Separate cells by color\n    color_cells = {1: [], 2: [], 3: []}\n    for x, y, c in cells:\n        color_cells[c].append((x, y))\n    \n    # Binary search for the largest k\n    left, right = 0, n\n    while left < right:\n        mid = (left + right) // 3 * 3\n        \n        if mid < 3:\n            right = mid - 1\n            continue\n        \n        if can_form_rectangles(mid, color_cells):\n            left = mid\n        else:\n            right = mid - 3\n    \n    return left\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    cells = [(int(data[i*3+1]), int(data[i*3+2]), int(data[i*3+3])) for i in range(n)]\n    \n    result = find_max_k(n, cells)\n    print(result)', 'def handle_large_coordinates_and_no_overlap(cells):\n    # Sort cells by color and coordinates to simplify rectangle formation\n    cells.sort(key=lambda x: (x[2], x[0], x[1]))\n    \n    # Implement logic to form non-overlapping rectangles and maximize k\n    # This involves checking boundaries and ensuring no intersection between rectangles\n    \n    # Example placeholder logic:\n    max_k = 0\n    # Iterate through possible configurations and update max_k accordingly\n    \n    return max_k\n\ndef find_largest_k(n, cells):\n    # Sort cells by color and coordinates to simplify rectangle formation\n    cells.sort(key=lambda x: (x[2], x[0], x[1]))\n    \n    # Initialize DP table with empty rectangles\n    dp = {\n        ((float(\'inf\'), float(\'inf\'), -float(\'inf\'), -float(\'inf\')),\n         (float(\'inf\'), float(\'inf\'), -float(\'inf\'), -float(\'inf\')),\n         (float(\'inf\'), float(\'inf\'), -float(\'inf\'), -float(\'inf\'))): 0\n    }\n    \n    # Iterate over each cell\n    for x, y, c in cells:\n        new_dp = {}\n        for (r1, r2, r3), k in dp.items():\n            if c == 1:\n                new_r1 = (min(r1[0], x), min(r1[1], y), max(r1[2], x), max(r1[3], y))\n                new_key = (new_r1, r2, r3)\n                if new_key not in new_dp or new_dp[new_key] < k + 1:\n                    new_dp[new_key] = k + 1\n            elif c == 2:\n                new_r2 = (min(r2[0], x), min(r2[1], y), max(r2[2], x), max(r2[3], y))\n                new_key = (r1, new_r2, r3)\n                if new_key not in new_dp or new_dp[new_key] < k + 1:\n                    new_dp[new_key] = k + 1\n            elif c == 3:\n                new_r3 = (min(r3[0], x), min(r3[1], y), max(r3[2], x), max(r3[3], y))\n                new_key = (r1, r2, new_r3)\n                if new_key not in new_dp or new_dp[new_key] < k + 1:\n                    new_dp[new_key] = k + 1\n        \n        dp.update(new_dp)\n    \n    # Find the maximum k ensuring no overlap\n    max_k = 0\n    for (r1, r2, r3), k in dp.items():\n        if r1[2] < r2[0] and r2[2] < r3[0] and r3[2] < r1[0]:  # Ensure no overlap\n            max_k = max(max_k, k)\n    \n    return max_k\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    cells = []\n    \n    index = 1\n    for _ in range(n):\n        x = int(data[index])\n        y = int(data[index + 1])\n        c = int(data[index + 2])\n        cells.append((x, y, c))\n        index += 3\n    \n    result = find_largest_k(n, cells)\n    print(result)', 'def parse_input():\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    n = int(data[0])\n    cells = []\n    index = 1\n    for _ in range(n):\n        x = int(data[index])\n        y = int(data[index + 1])\n        c = int(data[index + 2])\n        cells.append((x, y, c))\n        index += 3\n    return n, cells\n\ndef find_largest_k(n, cells):\n    from collections import defaultdict\n    \n    # Separate cells by color\n    color_cells = defaultdict(list)\n    for x, y, c in cells:\n        color_cells[c].append((x, y))\n    \n    # Sort cells within each color by coordinates\n    for c in color_cells:\n        color_cells[c].sort()\n    \n    # Function to check if k cells can be selected for a given color\n    def can_select_k(color_cells, k):\n        # Find the smallest rectangle that can contain k cells\n        x_coords = [x for x, y in color_cells[:k]]\n        y_coords = [y for x, y in color_cells[:k]]\n        \n        min_x, max_x = min(x_coords), max(x_coords)\n        min_y, max_y = min(y_coords), max(y_coords)\n        \n        # Check if the rectangle contains only k cells\n        count = 0\n        for x, y in color_cells:\n            if min_x <= x <= max_x and min_y <= y <= max_y:\n                count += 1\n            if count > k:\n                return False\n        return count == k\n    \n    # Binary search to find the largest k\n    low, high = 1, n // 3\n    best_k = 0\n    \n    while low <= high:\n        mid = (low + high) // 2\n        if all(can_select_k(color_cells[c], mid) for c in range(1, 4)):\n            best_k = mid\n            low = mid + 1\n        else:\n            high = mid - 1\n    \n    return best_k * 3\n\nif __name__ == "__main__":\n    n, cells = parse_input()\n    result = find_largest_k(n, cells)\n    print(result)', 'def separate_by_color(cells):\n    color1, color2, color3 = [], [], []\n    for x, y, c in cells:\n        if c == 1:\n            color1.append((x, y))\n        elif c == 2:\n            color2.append((x, y))\n        elif c == 3:\n            color3.append((x, y))\n    return color1, color2, color3\n\ndef find_min_rectangle(cells):\n    min_x = min(x for x, y in cells)\n    max_x = max(x for x, y in cells)\n    min_y = min(y for x, y in cells)\n    max_y = max(y for x, y in cells)\n    return min_x, max_x, min_y, max_y\n\ndef can_adjust_rectangles(rect1, rect2, rect3):\n    # Check if rectangles can be adjusted to be non-overlapping\n    # This is a simplified check assuming rectangles are axis-aligned\n    # and can be adjusted by moving boundaries.\n    # More complex checks can be added if needed.\n    return not (rect1[0] <= rect2[1] and rect2[0] <= rect1[1] and\n                rect1[2] <= rect2[3] and rect2[2] <= rect1[3]) and \\\n           not (rect1[0] <= rect3[1] and rect3[0] <= rect1[1] and\n                rect1[2] <= rect3[3] and rect3[2] <= rect1[3]) and \\\n           not (rect2[0] <= rect3[1] and rect3[0] <= rect2[1] and\n                rect2[2] <= rect3[3] and rect3[2] <= rect2[3])\n\ndef max_cells_in_rectangles(n, cells):\n    color1, color2, color3 = separate_by_color(cells)\n    \n    # Find the smallest rectangle for each color\n    rect1 = find_min_rectangle(color1)\n    rect2 = find_min_rectangle(color2)\n    rect3 = find_min_rectangle(color3)\n    \n    # Check if rectangles can be adjusted to be non-overlapping\n    if can_adjust_rectangles(rect1, rect2, rect3):\n        return len(color1) + len(color2) + len(color3)\n    \n    # If not possible to adjust without overlap, try reducing the number of cells\n    # This is a simplified greedy approach; more sophisticated methods can be used.\n    k = 0\n    for color_cells in [color1, color2, color3]:\n        k += len(color_cells) - 1  # Reduce by one cell to try avoiding overlap\n    \n    return k\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    cells = []\n    \n    index = 1\n    for _ in range(n):\n        x = int(data[index])\n        y = int(data[index + 1])\n        c = int(data[index + 2])\n        cells.append((x, y, c))\n        index += 3\n    \n    result = max_cells_in_rectangles(n, cells)\n    print(result)', 'def validate_rectangles(rectangles):\n    # Check if rectangles are non-overlapping\n    for i in range(len(rectangles)):\n        for j in range(i + 1, len(rectangles)):\n            r1 = rectangles[i]\n            r2 = rectangles[j]\n            # Check if r1 and r2 overlap\n            if not (r1[2] < r2[0] or r2[2] < r1[0] or r1[3] < r2[1] or r2[3] < r1[1]):\n                return False\n    return True\n\ndef calculate_bounding_rectangle(cells):\n    # Calculate the bounding rectangle for a set of cells\n    if not cells:\n        return None\n    min_x = min(cell[0] for cell in cells)\n    max_x = max(cell[0] for cell in cells)\n    min_y = min(cell[1] for cell in cells)\n    max_y = max(cell[1] for cell in cells)\n    return (min_x, min_y, max_x, max_y)\n\ndef backtrack(cells_by_color, current_selection, max_k):\n    # Base case: check if current selection is valid\n    if len(current_selection) == 3:\n        rectangles = [calculate_bounding_rectangle(cells) for cells in current_selection if cells]\n        if len(rectangles) == 3 and validate_rectangles(rectangles):\n            k = sum(len(cells) for cells in current_selection)\n            max_k[0] = max(max_k[0], k)\n        return\n    \n    # Recursive case: try different combinations of cells\n    color_index = len(current_selection)\n    if color_index >= len(cells_by_color):\n        return\n    \n    for i in range(len(cells_by_color[color_index]) + 1):\n        new_selection = current_selection + [cells_by_color[color_index][:i]]\n        backtrack(cells_by_color, new_selection, max_k)\n\ndef find_largest_k(n, cell_data):\n    # Organize cells by color\n    cells_by_color = {0: [], 1: [], 2: []}\n    for x, y, c in cell_data:\n        cells_by_color[c - 1].append((x, y))\n    \n    # Use backtracking to find the largest k\n    max_k = [0]\n    backtrack(cells_by_color, [], max_k)\n    return max_k[0]\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    cell_data = []\n    \n    index = 1\n    for _ in range(n):\n        x = int(data[index])\n        y = int(data[index + 1])\n        c = int(data[index + 2])\n        cell_data.append((x, y, c))\n        index += 3\n    \n    result = find_largest_k(n, cell_data)\n    print(result)', 'from itertools import combinations\n\ndef can_form_rectangles(selected_cells_by_color):\n    # For each color, determine the smallest rectangle that can cover the selected cells.\n    rectangles = []\n    for color_cells in selected_cells_by_color:\n        min_x = min(cell[0] for cell in color_cells)\n        max_x = max(cell[0] for cell in color_cells)\n        min_y = min(cell[1] for cell in color_cells)\n        max_y = max(cell[1] for cell in color_cells)\n        rectangles.append((min_x, max_x, min_y, max_y))\n    \n    # Ensure these rectangles do not intersect by comparing their boundaries.\n    for i in range(3):\n        for j in range(i + 1, 3):\n            if not (rectangles[i][1] < rectangles[j][0] or rectangles[j][1] < rectangles[i][0] or\n                    rectangles[i][3] < rectangles[j][2] or rectangles[j][3] < rectangles[i][2]):\n                return False\n    return True\n\ndef find_largest_k(cells):\n    # Sort cells by color\n    cells_by_color = {1: [], 2: [], 3: []}\n    for x, y, c in cells:\n        cells_by_color[c].append((x, y))\n    \n    # Sort each color\'s cells by coordinates\n    for color in cells_by_color:\n        cells_by_color[color].sort()\n    \n    # Binary search on k\n    low, high = 3, len(cells)\n    best_k = 3\n    \n    while low <= high:\n        mid = (low + high) // 2\n        k_per_color = mid // 3\n        \n        # Try all combinations of k/3 cells for each color\n        possible = False\n        for comb1 in combinations(cells_by_color[1], k_per_color):\n            for comb2 in combinations(cells_by_color[2], k_per_color):\n                for comb3 in combinations(cells_by_color[3], k_per_color):\n                    if can_form_rectangles([comb1, comb2, comb3]):\n                        possible = True\n                        break\n                if possible:\n                    break\n            if possible:\n                break\n        \n        if possible:\n            best_k = mid\n            low = mid + 3\n        else:\n            high = mid - 3\n    \n    return best_k\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    cells = []\n    \n    index = 1\n    for _ in range(n):\n        x = int(data[index])\n        y = int(data[index + 1])\n        c = int(data[index + 2])\n        cells.append((x, y, c))\n        index += 3\n    \n    result = find_largest_k(cells)\n    print(result)', 'def can_form_rectangles(cells_by_color, k):\n    # Attempt to form rectangles for each color with k/3 cells\n    for color in range(1, 4):\n        cells = cells_by_color[color]\n        if len(cells) < k // 3:\n            return False\n        \n        # Try to find a rectangle that contains exactly k/3 cells\n        found = False\n        for i in range(len(cells)):\n            for j in range(i, len(cells)):\n                # Get the bounding rectangle coordinates\n                min_x = min(cells[i][0], cells[j][0])\n                max_x = max(cells[i][0], cells[j][0])\n                min_y = min(cells[i][1], cells[j][1])\n                max_y = max(cells[i][1], cells[j][1])\n                \n                # Count how many cells are within this rectangle\n                count = 0\n                for x, y in cells:\n                    if min_x <= x <= max_x and min_y <= y <= max_y:\n                        count += 1\n                \n                # Check if this rectangle contains exactly k/3 cells\n                if count == k // 3:\n                    found = True\n                    break\n            if found:\n                break\n        \n        if not found:\n            return False\n    \n    return True\n\ndef binary_search_max_k(cells_by_color, n):\n    left, right = 3, n\n    best_k = 3\n    \n    while left <= right:\n        mid = (left + right) // 2\n        if mid % 3 != 0:\n            mid -= mid % 3\n        \n        if can_form_rectangles(cells_by_color, mid):\n            best_k = mid\n            left = mid + 3\n        else:\n            right = mid - 3\n    \n    return best_k\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    cells_by_color = {1: [], 2: [], 3: []}\n    \n    index = 1\n    for i in range(n):\n        x = int(data[index])\n        y = int(data[index + 1])\n        c = int(data[index + 2])\n        cells_by_color[c].append((x, y))\n        index += 3\n    \n    result = binary_search_max_k(cells_by_color, n)\n    print(result)', 'def can_form_non_overlapping_rectangles(selected_cells):\n    # Create a dictionary to store the boundaries of rectangles for each color\n    color_boundaries = {1: [float(\'inf\'), float(\'-inf\'), float(\'inf\'), float(\'-inf\')],\n                        2: [float(\'inf\'), float(\'-inf\'), float(\'inf\'), float(\'-inf\')],\n                        3: [float(\'inf\'), float(\'-inf\'), float(\'inf\'), float(\'-inf\')]}\n    \n    # Update boundaries for each color\n    for x, y, c in selected_cells:\n        color_boundaries[c][0] = min(color_boundaries[c][0], x)  # min x\n        color_boundaries[c][1] = max(color_boundaries[c][1], x)  # max x\n        color_boundaries[c][2] = min(color_boundaries[c][2], y)  # min y\n        color_boundaries[c][3] = max(color_boundaries[c][3], y)  # max y\n    \n    # Check for overlap between rectangles\n    for c1 in range(1, 4):\n        for c2 in range(c1 + 1, 4):\n            if not (color_boundaries[c1][1] < color_boundaries[c2][0] or\n                    color_boundaries[c2][1] < color_boundaries[c1][0] or\n                    color_boundaries[c1][3] < color_boundaries[c2][2] or\n                    color_boundaries[c2][3] < color_boundaries[c1][2]):\n                return False\n    return True\n\ndef find_largest_k(cells, n):\n    from itertools import combinations\n    \n    k = n\n    while k >= 3:\n        num_per_color = k // 3\n        \n        # Separate cells by color\n        color_cells = {1: [], 2: [], 3: []}\n        for x, y, c in cells:\n            color_cells[c].append((x, y, c))\n        \n        # Try combinations of num_per_color cells for each color\n        for comb1 in combinations(color_cells[1], num_per_color):\n            for comb2 in combinations(color_cells[2], num_per_color):\n                for comb3 in combinations(color_cells[3], num_per_color):\n                    selected_cells = list(comb1) + list(comb2) + list(comb3)\n                    if can_form_non_overlapping_rectangles(selected_cells):\n                        return k\n        \n        k -= 3\n    \n    return 0\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    cells = []\n    \n    index = 1\n    for _ in range(n):\n        x = int(data[index])\n        y = int(data[index + 1])\n        c = int(data[index + 2])\n        cells.append((x, y, c))\n        index += 3\n    \n    result = find_largest_k(cells, n)\n    print(result)', 'def can_form_rectangles(cells_by_color, k):\n    # Check if we can form rectangles with k/3 cells for each color\n    for color_cells in cells_by_color:\n        # Sort cells by x and y coordinates\n        color_cells.sort()\n        # Try to form a rectangle with the first k/3 cells\n        x_min = min(cell[0] for cell in color_cells[:k//3])\n        x_max = max(cell[0] for cell in color_cells[:k//3])\n        y_min = min(cell[1] for cell in color_cells[:k//3])\n        y_max = max(cell[1] for cell in color_cells[:k//3])\n        \n        # Check if all k/3 cells are within the rectangle\n        for x, y in color_cells[:k//3]:\n            if not (x_min <= x <= x_max and y_min <= y <= y_max):\n                return False\n    return True\n\ndef binary_search_max_k(cells_by_color, n):\n    left, right = 3, n\n    best_k = 3\n    \n    while left <= right:\n        mid = (left + right) // 2\n        if mid % 3 != 0:\n            mid -= mid % 3\n        \n        if can_form_rectangles(cells_by_color, mid):\n            best_k = mid\n            left = mid + 3\n        else:\n            right = mid - 3\n    \n    return best_k\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    cells_by_color = [[] for _ in range(3)]\n    \n    index = 1\n    for _ in range(n):\n        x = int(data[index])\n        y = int(data[index + 1])\n        c = int(data[index + 2]) - 1\n        cells_by_color[c].append((x, y))\n        index += 3\n    \n    result = binary_search_max_k(cells_by_color, n)\n    print(result)', 'def parse_input():\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    cells = []\n    \n    index = 1\n    for _ in range(n):\n        x = int(data[index])\n        y = int(data[index + 1])\n        c = int(data[index + 2])\n        cells.append((x, y, c))\n        index += 3\n    \n    return n, cells\n\ndef categorize_cells(n, cells):\n    color_cells = {1: [], 2: [], 3: []}\n    \n    for x, y, c in cells:\n        color_cells[c].append((x, y))\n    \n    return color_cells\n\ndef find_largest_rectangle(cells):\n    # Sort cells by x and then by y\n    cells.sort()\n    \n    max_k = 0\n    m = len(cells)\n    \n    # Try to form rectangles starting from each cell\n    for i in range(m):\n        x_min = cells[i][0]\n        y_min = cells[i][1]\n        \n        for j in range(i, m):\n            x_max = cells[j][0]\n            y_max = max(y_min, cells[j][1])\n            \n            # Check if all cells between i and j can form a rectangle\n            if all(x_min <= cells[k][0] <= x_max and y_min <= cells[k][1] <= y_max for k in range(i, j + 1)):\n                max_k = max(max_k, j - i + 1)\n    \n    return max_k\n\ndef calculate_max_k(color_cells):\n    max_k_per_color = []\n    \n    for color in color_cells:\n        max_k_per_color.append(find_largest_rectangle(color_cells[color]))\n    \n    # The largest k is the minimum of the largest rectangles we can form for each color\n    return min(max_k_per_color) * 3\n\nif __name__ == "__main__":\n    n, cells = parse_input()\n    \n    if n == 3:\n        print(n)\n    else:\n        color_cells = categorize_cells(n, cells)\n        result = calculate_max_k(color_cells)\n        print(result)']
----------
["- name: \nSweep Line Algorithm with Coordinate Compression\n\n- content: \nThis method uses a sweep line algorithm enhanced with coordinate compression to efficiently manage large coordinates and optimize selection.\n\n1. Compress the coordinates to reduce the range without affecting relative positions using sorting and mapping.\n2. Utilize a sweep line technique across one axis (e.g., x-axis) and maintain active intervals for each color along the other axis (e.g., y-axis).\n3. For each x-coordinate in sorted order, update and maintain active intervals where each interval represents potential y-ranges for forming rectangles per color.\n4. Use data structures like segment trees or binary indexed trees to efficiently query and update the intervals as you sweep across x-coordinates.\n5. At each step, check potential rectangles formed by active intervals for all colors to ensure non-intersection.\n6. The objective is to maximize the selected cells while maintaining valid rectangle conditions.\n7. Conclude by calculating the maximum number of valid k by counting selected cells that form non-intersecting rectangles.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'endless checkered sheet of paper'\n    Explanation: This refers to a grid-like structure where each cell can be identified by its coordinates.\n\n    'n cells are chosen and colored in three colors'\n    Explanation: The problem involves selecting n cells, each assigned one of three colors.\n\n    'n is divisible by 3'\n    Explanation: The total number of cells is a multiple of 3, ensuring an equal distribution among the three colors.\n\n    'largest such k'\n    Explanation: The goal is to find the maximum number of cells (k) that can be selected while meeting the conditions.\n\n# [phrase showing quantity relationship]\n    'n/3': This indicates that there are exactly n/3 cells of each color.\n    Implementation: This can be used to set up initial conditions or constraints in the code.\n\n    'k/3': This means that for the largest k, there should be k/3 cells of each color.\n    Implementation: This can be used to iterate and check possible values of k.\n\n# [degree adverb]\n    'largest': This indicates the need to maximize the number of cells (k) that can be selected.\n    Implementation: This can be implemented using a loop or optimization technique to find the maximum k.\n\n# [code logic]\n    Steps 1-4 should be considered simultaneously as they involve setting up the data structure and processing the coordinates.\n    Implementation: These steps can be implemented in a single function or code block that handles coordinate compression and interval management.\n\n# [edge case]\n    Input: 3\n           1 1 1\n           2 2 2\n           3 3 3\n    Output: 3\n    Explanation: With only one cell per color, all cells can be selected without intersection.\n\n    Input: 6\n           1 1 1\n           2 2 1\n           3 3 2\n           4 4 2\n           5 5 3\n           6 6 3\n    Output: 6\n    Explanation: Each color has two cells, and they can be selected without intersection.\n\n    Input: 9\n           1 1 1\n           2 2 1\n           3 3 1\n           4 4 2\n           5 5 2\n           6 6 2\n           7 7 3\n           8 8 3\n           9 9 3\n    Output: 9\n    Explanation: All cells can be selected as they form non-intersecting rectangles.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        # Example pseudocode for handling edge cases:\n        if n == 3:\n            return n\n        # Additional logic to handle other specific edge cases based on input constraints.", "- name: \nDynamic Programming with State Compression\n- content: \nUsing dynamic programming to keep track of possible states and transitions to maximize the number of cells while satisfying rectangle constraints.\n\nSteps:\n1. Define a DP state that represents the number of cells selected from each color and the current boundaries of rectangles for those selections.\n2. Initialize the DP table with states where no cells are selected.\n3. Iterate through each cell, updating the DP states to include this cell in its respective color's rectangle if it does not cause an overlap with rectangles for other colors.\n4. Use state compression techniques to reduce memory usage by encoding boundaries efficiently.\n5. Calculate and track the maximum k that can be achieved by valid DP states.\n\nThis method provides a balanced trade-off between time complexity and correctness by leveraging dynamic programming principles to explore combinations efficiently.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'checkered sheet of paper'\n    Explanation: This refers to a grid-like structure where each cell can be identified by its coordinates.\n\n    'n cells are chosen and colored in three colors'\n    Explanation: The problem involves selecting cells on the grid and coloring them with one of three colors.\n\n    'n is divisible by 3'\n    Explanation: The total number of cells is a multiple of 3, ensuring an equal distribution among the three colors.\n\n    'rectangles with sides parallel to the grid lines'\n    Explanation: The rectangles must align with the grid, meaning their sides are either horizontal or vertical.\n\n# [phrase showing quantity relationship]\n    'n/3': This indicates that each color has exactly n/3 cells. In code, this can be implemented by dividing n by 3 to determine the number of cells per color.\n\n    'k/3': This refers to the number of cells of each color that can be chosen when maximizing k. In code, this involves dividing k by 3 to ensure equal distribution among colors.\n\n# [degree adverb]\n    'largest': This means finding the maximum possible value of k that satisfies the conditions. In code, this involves iterating through possible values and keeping track of the maximum valid k.\n\n# [code logic]\n    Steps 1-5 in the plan should be considered simultaneously as they involve setting up and updating the dynamic programming states. The logic for updating DP states and checking conditions should be implemented in a single loop or function to ensure efficiency and correctness.\n\n# [edge case]\n    Input: 3\n           1 1 1\n           2 2 2\n           3 3 3\n    Output: 3\n    Explanation: With only one cell per color, the only valid solution is to keep all three cells, resulting in k = 3.\n\n    Input: 6\n           1 1 1\n           2 2 1\n           3 3 2\n           4 4 2\n           5 5 3\n           6 6 3\n    Output: 6\n    Explanation: Each color has two cells, and they can be grouped into non-overlapping rectangles, allowing all cells to be kept.\n\n    Input: 9\n           -1000000000 -1000000000 1\n           -999999999 -999999999 1\n           -999999998 -999999998 2\n           -999999997 -999999997 2\n           -999999996 -999999996 3\n           -999999995 -999999995 3\n           -999999994 -999999994 1\n           -999999993 -999999993 2\n           -999999992 -999999992 3\n    Output: 6\n    Explanation: Despite large coordinates, the logic remains the same. Three rectangles can be formed with two cells each, maximizing k to 6.\n\n# [extra code for edge case]\n    We need extra code to handle edge cases related to large coordinate values and ensuring no overlap between rectangles.\n    \n```python\ndef handle_large_coordinates_and_no_overlap(cells):\n    # Sort cells by color and coordinates to simplify rectangle formation\n    cells.sort(key=lambda x: (x[2], x[0], x[1]))\n    \n    # Implement logic to form non-overlapping rectangles and maximize k\n    # This involves checking boundaries and ensuring no intersection between rectangles\n    \n    # Example placeholder logic:\n    max_k = 0\n    # Iterate through possible configurations and update max_k accordingly\n    \n    return max_k\n\n# Use this function within the main logic to ensure edge cases are handled.\n```", '- name: \nDynamic Programming with Rectangle Constraints\n- content: \nThis approach involves using dynamic programming to optimize the selection of cells:\n1. Define a DP table where dp[i][j][k] represents the maximum number of cells that can be selected up to cell i for color j with k being the number of selected cells.\n2. Initialize the DP table with base cases where no cells are chosen initially.\n3. For each cell, decide whether to include it in the rectangle based on previous state transitions, ensuring no overlap with rectangles of other colors.\n4. Use constraints from previous states to dynamically calculate the smallest rectangle that can contain all selected cells.\n5. The final state of the DP table will indicate the maximum number of non-overlapping cells that can be selected, constrained by rectangles covering only one color each.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'checkered sheet of paper\'\n    Explanation: This refers to a grid-like structure where each cell can be identified by its coordinates.\n\n    \'n cells are chosen and colored in three colors\'\n    Explanation: The problem involves selecting cells that are colored in one of three colors, and n is divisible by 3, meaning there are equal numbers of each color.\n\n    \'rectangles with sides parallel to the grid lines\'\n    Explanation: The rectangles must align with the grid, meaning their sides are either horizontal or vertical.\n\n# [phrase showing quantity relationship]\n    \'n is divisible by 3\': This means n/3 cells are of each color.\n    Implementation: Ensure that the input n is checked for divisibility by 3.\n\n    \'k/3 cells of each color\': This means selecting an equal number of cells for each color.\n    Implementation: Calculate k as a multiple of 3 and ensure k/3 cells are selected for each color.\n\n# [degree adverb]\n    \'largest\': This refers to finding the maximum possible value of k.\n    Implementation: Use a maximization approach in the dynamic programming solution to find the largest k.\n\n# [code logic]\n    Steps 3 and 4 in the plan should be considered simultaneously. \n    "For each cell, decide whether to include it in the rectangle based on previous state transitions, ensuring no overlap with rectangles of other colors."\n    "Use constraints from previous states to dynamically calculate the smallest rectangle that can contain all selected cells."\n    These steps involve checking conditions and updating the DP table, which can be done in a single loop over the cells.\n\n# [edge case]\n    Input: 3\n           1 1 1\n           2 2 2\n           3 3 3\n    Output: 3\n    Explanation: With only one cell per color, all must be selected, resulting in k = 3.\n\n    Input: 6\n           1 1 1\n           2 2 1\n           3 3 2\n           4 4 2\n           5 5 3\n           6 6 3\n    Output: 6\n    Explanation: Each color has exactly two cells, so all can be selected without overlap, resulting in k = 6.\n\n    Input: 9\n           -10^9 -10^9 1\n           -10^9 -10^9+1 1\n           -10^9+1 -10^9+1 2\n           -10^9+1 -10^9+2 2\n           -10^9+2 -10^9+2 3\n           -10^9+2 -10^9+3 3\n           -10^9+3 -10^9+3 1\n           -10^9+3 -10^9+4 2\n           -10^9+4 -10^9+4 3\n    Output: 6\n    Explanation: Despite large coordinates, the logic remains the same; select two cells per color without overlap.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling edge cases)\n        Ensure that the DP table initialization and transitions account for edge cases where minimal cells are available or coordinates are at extreme values.', "- name: \nDynamic Programming with State Compression\n\n- content: \nUse dynamic programming to find the maximum number of cells that can be left while satisfying the rectangle conditions.\n1. Define a state DP[c][x][y] representing the maximum number of cells left considering up to cell (x, y) for color c.\n2. Initialize DP with base cases: for each color c, start with a rectangle containing no cells and add one cell at a time.\n3. Transition between states by considering adding one more cell to an existing rectangle without causing overlap.\n4. Use state compression to efficiently store only necessary states, taking advantage of grid properties and constraints.\n5. Iterate through possible states updating DP values while maintaining non-overlapping conditions.\n6. After processing all input, retrieve the largest value from DP for the full grid and return it as the largest possible k.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'checkered sheet of paper'\n    Explanation: This refers to a grid-like structure where each cell can be identified by its coordinates.\n\n    'n cells are chosen and colored in three colors'\n    Explanation: This means that there are n cells, each assigned one of three possible colors.\n\n    'n is divisible by 3'\n    Explanation: The total number of cells is a multiple of 3, ensuring an equal distribution among the three colors.\n\n    'No two rectangles can intersect'\n    Explanation: The rectangles must not overlap in area, though they can share edges.\n\n# [phrase showing quantity relationship]\n    'n/3': This indicates that each color has exactly one-third of the total number of marked cells.\n    Implementation: This can be calculated as `n // 3` in code to determine the number of cells per color.\n\n    'k/3': This refers to the number of cells of each color that can be chosen when maximizing k.\n    Implementation: This can be calculated as `k // 3` in code to determine the number of cells per color for the largest k.\n\n# [degree adverb]\n    'largest': This refers to finding the maximum possible value of k such that the conditions are satisfied.\n    Implementation: This involves iterating through possible values and updating the maximum found.\n\n# [code logic]\n    Steps 1-6 in the plan should be considered simultaneously as they are part of a dynamic programming approach. The logic involves initializing states, transitioning between them, and updating values based on conditions, all within a single iterative process.\n\n# [edge case]\n    Input: 3\n           1 1 1\n           2 2 2\n           3 3 3\n    Output: 3\n    Explanation: With only one cell per color, the only possible k is 3, as each rectangle will contain exactly one cell.\n\n    Input: 6\n           1 1 1\n           2 2 1\n           3 3 2\n           4 4 2\n           5 5 3\n           6 6 3\n    Output: 6\n    Explanation: Each color has exactly two cells, and they can be grouped into non-overlapping rectangles, allowing all cells to be used.\n\n    Input: 9\n           -1000000000 -1000000000 1\n           -999999999 -999999999 1\n           -999999998 -999999998 2\n           -999999997 -999999997 2\n           -999999996 -999999996 3\n           -999999995 -999999995 3\n           -999999994 -999999994 1\n           -999999993 -999999993 2\n           -999999992 -999999992 3\n    Output: 9\n    Explanation: Despite large coordinates, all cells can be grouped into non-overlapping rectangles, allowing all cells to be used.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        # Ensure that the dynamic programming state transitions account for large coordinate values and non-overlapping conditions.\n        # Implement checks for boundary conditions and ensure that state compression efficiently handles large grids.", "- name: \nDynamic Programming with State Representation\n\n- content: \nThis approach uses dynamic programming to keep track of possible subsets of cells that can form valid rectangles for each color.\n1. Represent each subset of cells by a state, where each state tracks the bounds of potential rectangles.\n2. Initialize DP tables for each color with base cases representing single-cell rectangles.\n3. Transition between states by expanding the current rectangle's boundaries if it can encompass additional cells of the same color without overlapping others.\n4. Use DP to calculate the maximum number of cells that can be included in valid rectangles for each color, then sum these for k.\nThis method systematically explores all possibilities, ensuring optimal substructure and overlapping subproblem properties are utilized effectively.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'checkered sheet of paper'\n    Explanation: This refers to a grid-like structure where each cell can be identified by its coordinates.\n\n    'n cells are chosen and colored in three colors'\n    Explanation: This means that there are n cells, each assigned one of three possible colors.\n\n    'n is divisible by 3'\n    Explanation: The total number of cells is a multiple of 3, ensuring an equal distribution among the three colors.\n\n    'largest such k'\n    Explanation: The goal is to find the maximum number of cells that can be retained while satisfying the given conditions.\n\n# [phrase showing quantity relationship]\n    'n/3': This indicates that each color has exactly one-third of the total number of marked cells.\n    Implementation: This can be calculated as `n // 3` in Python.\n\n    'k/3': This refers to the number of cells of each color that can be chosen to form valid rectangles.\n    Implementation: This can be calculated as `k // 3` in Python.\n\n# [degree adverb]\n    'largest': This means finding the maximum possible value of k that satisfies the conditions.\n    Implementation: This involves iterating through possible values and keeping track of the maximum valid k.\n\n# [code logic]\n    The steps in the plan involve dynamic programming, which inherently requires simultaneous consideration of multiple states. The transition between states (expanding rectangle boundaries) should be handled within a single loop or function to ensure all possibilities are explored efficiently.\n\n# [edge case]\n    Input: 3\n           1 1 1\n           2 2 2\n           3 3 3\n    Output: 3\n    Explanation: With only one cell per color, the only valid solution is to keep all three cells, forming one rectangle per color.\n\n    Input: 6\n           1 1 1\n           2 2 1\n           3 3 2\n           4 4 2\n           5 5 3\n           6 6 3\n    Output: 6\n    Explanation: Each color can form a rectangle with its two cells, allowing all six cells to be retained.\n\n    Input: 9\n           1 1 1\n           2 2 1\n           3 3 1\n           4 4 2\n           5 5 2\n           6 6 2\n           7 7 3\n           8 8 3\n           9 9 3\n    Output: 9\n    Explanation: Each color has three cells, which can form a rectangle, allowing all nine cells to be retained.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        # Example code snippet:\n        def handle_edge_cases(n, cells):\n            if n == len(cells):\n                return n\n            # Additional logic to handle specific edge cases based on input constraints and conditions.", "- name: \nBinary Search with Rectangle Validation\n\n- content: \n1. Sort the cells of each color by their coordinates.\n2. Use binary search on k, ranging from 3 to n, to find the largest valid k.\n3. For each mid value of k in the binary search, try to select k/3 cells for each color.\n4. Implement a function to check if the selected cells can be enclosed in three non-intersecting rectangles:\n   - For each color, determine the smallest rectangle that can cover the selected cells.\n   - Ensure these rectangles do not intersect by comparing their boundaries.\n5. If the rectangles are valid for a given k, continue searching in the upper half; otherwise, search in the lower half.\n6. Once the binary search completes, return the largest valid k found.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'n cells are chosen and colored in three colors'\n    Explanation: This means that the total number of cells is divided into three equal groups, each group having a distinct color.\n\n    'largest such k'\n    Explanation: The task is to find the maximum number of cells that can be retained while satisfying the given conditions.\n\n    'rectangles with sides parallel to the grid lines'\n    Explanation: The rectangles must align with the grid, meaning their sides are either horizontal or vertical.\n\n# [phrase showing quantity relationship]\n    'n is divisible by 3': This means n can be divided by 3 without a remainder, ensuring equal distribution among the three colors.\n    \n    'n/3': This indicates that each color has exactly one-third of the total number of marked cells.\n    \n    'k/3': This means for any chosen k, each color should have exactly k/3 cells.\n\n# [degree adverb]\n    'largest': This indicates the need to maximize the value of k while meeting all conditions.\n\n# [code logic]\n    Steps 2 and 4 should be considered simultaneously. During the binary search for k, the validation of whether k/3 cells can be enclosed in non-intersecting rectangles should be done in tandem. This involves checking the feasibility of forming rectangles as part of the binary search process.\n\n# [edge case]\n    Input: 3\n           1 1 1\n           2 2 2\n           3 3 3\n    Output: 3\n    Explanation: With only one cell per color, each can form its own rectangle without intersection.\n\n    Input: 6\n           1 1 1\n           2 2 1\n           3 3 2\n           4 4 2\n           5 5 3\n           6 6 3\n    Output: 6\n    Explanation: Each color can form a rectangle with its two cells, and none of these rectangles intersect.\n\n    Input: 9\n           -1 -1 1\n           -2 -2 1\n           -3 -3 1\n           1 1 2\n           2 2 2\n           3 3 2\n           -1 -1 3\n           -2 -2 3\n           -3 -3 3\n    Output: 6\n    Explanation: The maximum k is not all cells because forming non-intersecting rectangles for all would not be possible.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n    The code should include a function to validate if selected cells can form non-intersecting rectangles:\n    \n```python\ndef can_form_rectangles(cells_by_color):\n    # Implement logic to check if selected cells can form non-intersecting rectangles\n    # For each color, determine the smallest rectangle that can cover the selected cells.\n    # Ensure these rectangles do not intersect by comparing their boundaries.\n    pass\n\ndef find_largest_k(cells):\n    # Sort cells by color and coordinates\n    # Implement binary search on k\n    # Use can_form_rectangles to validate each mid value of k\n    pass\n\n# Example usage:\n# result = find_largest_k(cells)\n```", "- name: \nBinary Search with Bounding Rectangles\n\n- content: \nUse binary search over the number of cells retained to maximize k while maintaining valid non-overlapping rectangles for each color.\n\n1. Sort all colored cells based on x and y coordinates to facilitate rectangle formation.\n2. Define a binary search range from 3 to n, representing the potential values for k.\n3. For each candidate k value in the binary search:\n   - Attempt to form a rectangle for each color that contains k/3 cells.\n   - Ensure that these rectangles do not overlap by checking boundaries.\n   - Use greedy or line-sweep techniques to validate the feasibility of forming such rectangles.\n4. If successful, try a larger k; otherwise, try smaller.\n5. The process continues until the largest feasible k is found.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'endless checkered sheet of paper'\n    Explanation: This refers to a grid-like structure where cells can be marked and colored, similar to a chessboard.\n\n    'n is divisible by 3'\n    Explanation: This ensures that the number of cells can be evenly divided among the three colors.\n\n    'rectangles with sides parallel to the grid lines'\n    Explanation: The rectangles must align with the grid, meaning their sides are either vertical or horizontal.\n\n# [phrase showing quantity relationship]\n    'n/3': This indicates that each color has exactly n/3 marked cells.\n    Implementation: Calculate n/3 to determine the number of cells for each color.\n\n    'k/3': This indicates that for any chosen k, k/3 cells of each color should be retained.\n    Implementation: Calculate k/3 to determine how many cells of each color can be retained.\n\n# [degree adverb]\n    'largest': This refers to finding the maximum possible value of k.\n    Implementation: Use binary search to maximize k while ensuring conditions are met.\n\n# [code logic]\n    Steps 3-5 in the plan should be considered simultaneously:\n    - Attempting to form rectangles and ensuring they do not overlap should be done in one logical block, possibly using a loop or recursive function to validate rectangle formation for each candidate k.\n\n# [edge case]\n    Input: 3\n    1 1 1\n    2 2 2\n    3 3 3\n    Output: 3\n    Explanation: With only one cell per color, the rectangles can trivially be formed without overlap.\n\n    Input: 6\n    1 1 1\n    2 2 1\n    3 3 2\n    4 4 2\n    5 5 3\n    6 6 3\n    Output: 6\n    Explanation: Each color has exactly two cells, allowing for non-overlapping rectangles.\n\n    Input: 9\n    1 1 1\n    2 2 1\n    3 3 1\n    4 4 2\n    5 5 2\n    6 6 2\n    7 7 3\n    8 8 3\n    9 9 3\n    Output: 9\n    Explanation: All cells can be retained as they naturally form non-overlapping rectangles.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        Implement checks for rectangle formation and overlap validation within the binary search logic.", "- name: \nBrute Force with Optimized Rectangular Selection\n\n- content: \nThis approach involves trying different subsets of the colored cells and checking if they can form the required non-overlapping rectangles for each color.\n\n1. Start with k = n, where n is the total number of colored cells.\n2. While k is greater than or equal to 3, attempt to find a valid selection:\n   a. Choose k/3 cells of each color.\n   b. For each color, find the smallest rectangle that can contain all selected cells of that color.\n   c. Check if these rectangles overlap. If they do not overlap, the selection is valid, and k can be returned as the result.\n   d. If no valid selection is found, decrement k by 3 and repeat.\n3. The process ends when a valid configuration is found or when k becomes less than 3.\n4. The key here is to efficiently check for non-overlapping rectangles, which could be done by utilizing coordinate sorting and boundary checking.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'endless checkered sheet of paper'\n    Explanation: This refers to a grid-like structure where each cell can be identified by its coordinates.\n\n    'n cells are chosen and colored in three colors'\n    Explanation: This means that there are n cells, each assigned one of three possible colors.\n\n    'n is divisible by 3'\n    Explanation: The total number of cells is a multiple of 3, ensuring an equal distribution among the three colors.\n\n    'largest such k'\n    Explanation: The goal is to find the maximum number of cells that can be retained while satisfying the given conditions.\n\n# [phrase showing quantity relationship]\n    'n is divisible by 3': This means n/3 cells are of each color.\n    Implementation: Ensure that any operations or selections respect this division.\n\n    'k/3 cells of each color': This means selecting an equal number of cells for each color.\n    Implementation: When selecting cells, ensure that the count for each color is k/3.\n\n# [degree adverb]\n    'largest': This indicates the need to maximize the value of k.\n    Implementation: Use a loop to decrement k and check conditions until the largest valid k is found.\n\n# [code logic]\n    Steps 2a, 2b, and 2c should be implemented simultaneously.\n    Explanation: These steps involve selecting cells, forming rectangles, and checking for overlap, which are interdependent processes that should be handled together in a loop or function.\n\n# [edge case]\n    Input: 3\n           1 1 1\n           2 2 2\n           3 3 3\n    Output: 3\n    Explanation: With only one cell per color, the only valid configuration is to keep all three cells.\n\n    Input: 6\n           1 1 1\n           2 2 1\n           3 3 2\n           4 4 2\n           5 5 3\n           6 6 3\n    Output: 6\n    Explanation: Each color can form a rectangle with its two cells without overlap.\n\n    Input: 9\n           1 1 1\n           2 2 1\n           3 3 1\n           4 4 2\n           5 5 2\n           6 6 2\n           7 7 3\n           8 8 3\n           9 9 3\n    Output: 9\n    Explanation: All cells can be retained as they naturally form non-overlapping rectangles.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        - Implement a function to check if selected rectangles overlap.\n        - Use sorting and boundary checking to efficiently determine non-overlapping configurations.", "- name: \nDynamic Programming with State Compression\n\n- content: \n1. Treat each color as a separate problem to find a rectangle covering the maximum number of cells.\n2. Use dynamic programming to determine feasible subproblems where rectangles are adjusted dynamically as new cells are considered.\n3. The state would involve tracking combinations of selected cells and their bounding box constraints for each color.\n4. Iterate through cells while updating states, ensuring no overlap among the rectangles by checking against previously calculated states.\n5. Use state compression to efficiently manage the large potential state space due to high coordinate range.\n6. The result is derived from combining maximal solutions from each state where all three colors have valid bounding boxes without overlap.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'checkered sheet of paper'\n    Explanation: This refers to a grid-like structure where each cell can be identified by its coordinates.\n\n    'n cells are chosen and colored in three colors'\n    Explanation: The problem involves selecting cells on the grid that are colored in one of three colors.\n\n    'n is divisible by 3'\n    Explanation: The total number of cells is a multiple of 3, ensuring an equal distribution of colors.\n\n    'rectangles with sides parallel to the grid lines'\n    Explanation: The rectangles must align with the grid, meaning their sides are either horizontal or vertical.\n\n# [phrase showing quantity relationship]\n    'n/3': This means that each color has exactly n/3 cells. In code, this can be implemented by dividing n by 3 to determine the number of cells per color.\n\n    'k/3': This means that for any chosen k, there should be k/3 cells of each color. In code, this can be implemented by dividing k by 3 to determine the number of cells per color to keep.\n\n# [degree adverb]\n    'largest': This refers to finding the maximum possible value of k that satisfies the conditions. In code, this can be implemented by iterating over possible values of k and checking the conditions.\n\n# [code logic]\n    Steps 1 and 2 should be considered simultaneously as they both involve treating each color separately and using dynamic programming to find the maximum number of cells that can be covered by a rectangle for each color.\n\n# [edge case]\n    Input: 3\n           1 1 1\n           2 2 2\n           3 3 3\n    Output: 3\n    Explanation: With only one cell per color, the only possible solution is to keep all three cells, resulting in k = 3.\n\n    Input: 6\n           1 1 1\n           2 2 1\n           3 3 2\n           4 4 2\n           5 5 3\n           6 6 3\n    Output: 6\n    Explanation: Each color has two cells, and it's possible to select all of them without overlap, resulting in k = 6.\n\n    Input: 9\n           -1000000000 -1000000000 1\n           -999999999 -999999999 1\n           -999999998 -999999998 2\n           -999999997 -999999997 2\n           -999999996 -999999996 3\n           -999999995 -999999995 3\n           -999999994 -999999994 1\n           -999999993 -999999993 2\n           -999999992 -999999992 3\n    Output: 6\n    Explanation: Despite large coordinates, it's possible to select two cells per color without overlap, resulting in k = 6.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        # Example pseudo-code:\n        def handle_edge_cases(cells):\n            # Check if there are exactly n/3 cells per color and handle accordingly\n            if len(cells) == n:\n                return n\n            # Implement logic to find maximum k considering edge cases\n            # ... (additional logic)\n", "- name: \nDivide and Conquer with Dynamic Programming\n\n- content: \n1. Parse the input to categorize cells by color.\n2. Sort cells within each color based on their coordinates to facilitate rectangle formation.\n3. Use a divide-and-conquer approach to recursively partition the grid into non-overlapping regions that can potentially form rectangles.\n4. Implement dynamic programming to track possible configurations and maximize k by trying different partitions and calculating potential rectangle areas for each color.\n5. Merge results from subproblems while ensuring no two rectangles overlap across different colors.\n6. Continuously update and check dp states to find the largest k that satisfies the problem constraints.\n7. Output the largest valid k.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'endless checkered sheet of paper'\n    Explanation: This refers to a grid-like structure where each cell can be identified by its coordinates.\n\n    'n cells are chosen and colored in three colors'\n    Explanation: The problem involves selecting n cells, each assigned one of three colors.\n\n    'n is divisible by 3'\n    Explanation: The total number of cells is a multiple of 3, ensuring an equal distribution among the three colors.\n\n    'rectangles with sides parallel to the grid lines'\n    Explanation: The rectangles must align with the grid, meaning their sides are either horizontal or vertical.\n\n# [phrase showing quantity relationship]\n    'n/3': This indicates that each color has exactly n/3 cells. In code, this can be implemented by dividing n by 3 to determine the number of cells per color.\n\n    'k/3': This refers to the number of cells of each color that can be chosen when maximizing k. In code, this involves dividing k by 3 to ensure equal distribution among colors.\n\n# [degree adverb]\n    'largest': This means finding the maximum possible value of k that satisfies the conditions. In code, this involves iterating through possible values and updating the maximum found.\n\n# [code logic]\n    Steps 3 and 4 should be considered simultaneously. The divide-and-conquer approach and dynamic programming should work together to partition the grid and track configurations. This can be implemented by integrating recursive partitioning with dynamic programming state updates in a single code block.\n\n# [edge case]\n    Input: 3\n           1 1 1\n           2 2 2\n           3 3 3\n    Output: 3\n    Explanation: With only one cell per color, the maximum k is simply the total number of cells, which is 3.\n\n    Input: 6\n           1 1 1\n           2 2 1\n           3 3 2\n           4 4 2\n           5 5 3\n           6 6 3\n    Output: 6\n    Explanation: Each color has exactly two cells, allowing all to be used without overlap, resulting in k = 6.\n\n    Input: 9\n           -1 -1 1\n           -2 -2 1\n           -3 -3 1\n           -4 -4 2\n           -5 -5 2\n           -6 -6 2\n           -7 -7 3\n           -8 -8 3\n           -9 -9 3\n    Output: 9\n    Explanation: All cells can be used as they are already separated by color and do not overlap, resulting in k = 9.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        # Ensure that the dynamic programming approach considers cases where all cells can be used.\n        # Implement checks for minimal input sizes and ensure that partitions do not overlap.\n        # Example:\n        if n == 3:\n            return n\n        # Additional logic to handle larger cases with dynamic programming and partitioning."]
----------
True
----------
1
multi-gen-prompt:
In the year 2420 humans have finally built a colony on Mars thanks to the work of Elon Tusk. There are 10^9+7 cities arranged in a circle in this colony and none of them are connected yet. Elon Tusk wants to connect some of those cities using only roads of the same size in order to lower the production cost of those roads. Because of that he gave a list on N cities. Some cities can appear more than once on the list and there are Q queries that you need to answer. For the query you need to determine if it is possible to connect all the cities from L_{i} to R_{i} on that list using only roads of length D_{i}. 

Input

The first line contains two integers N and Q (1 ≤ N, Q ≤ 2⋅10^5 ) — the length of the array of cities and the number of queries you need to answer. 

The second lines contains N integers representing the array of cites. Next Q lines contain three integers L, R and D (1 ≤ L_{i}, R_{i} ≤ N, 0 ≤ D_{i} ≤ 10^9+6) — the range of cities that needs to be connected and the length of the road that you can use. 

Output

The output contains Q lines. If it is possible to connect all the cities from the i-th query can be connected with roads of length D_{i} the i-th line should contain the word "Yes", otherwise it should contain the word "No". 

Examples

Input


9 8
17 0 12 6 10 8 2 4 5
2 3 12
2 3 6
2 4 6
4 6 2
2 8 2
1 2 17
1 8 2
9 9 14


Output


Yes
No
Yes
Yes
Yes
Yes
No
Yes


Input


4 1
7 21 14 0
1 4 1000000000


Output


Yes

Note

In the 5^{th} query of the first test case we can connect cities in this order 0-2-4-6-8-10-12 this way distance between any two connected cities is 2. In the second test case we can connect cities in this order 21-14-7-0 this way distance between any two connected cities is 10^9 module 10^9+7. 
multi-gen-prompt:
In the year 2420 humans have finally built a colony on Mars thanks to the work of Elon Tusk. There are 10^9+7 cities arranged in a circle in this colony which are still unconnected. Elon Tusk wants to connect some of those cities using only roads of the same size in order to lower the production cost of those roads. Because of that he gave a list on N cites where some cites can appear more than once and Q queries that you need to answer. For the query, determine if it is possible to connect all the cities from L_{i} to R_{i} on that list using only roads of length D_{i}.

Input

The first line contains two integers N and Q (1 ≤ N, Q ≤ 2⋅10^5 ) — the length of the array of cities and the number of queries you need to answer. 

The second lines contains N integers representing the array of cites. Next Q lines contain three integers L, R and D (1 ≤ L_{i}, R_{i} ≤ N, 0 ≤ D_{i} ≤ 10^9+6) — the range of cities that needs to be connected and the length of the road that you can use. 

Output

The output contains Q lines. If it is possible to connect all the cities from the i-th query can be connected with roads of length D_{i} the i-th line should contain the word "Yes", otherwise it should contain the word "No". 

Examples

Input


9 8
17 0 12 6 10 8 2 4 5
2 3 12
2 3 6
2 4 6
4 6 2
2 8 2
1 2 17
1 8 2
9 9 14


Output


Yes
No
Yes
Yes
Yes
Yes
No
Yes


Input


4 1
7 21 14 0
1 4 1000000000


Output


Yes

Note

In the 5^{th} query of the first test case we can connect cities in this order 0-2-4-6-8-10-12 this way distance between any two connected cities is 2. In the second test case we can connect cities in this order 21-14-7-0 this way distance between any two connected cities is 10^9 module 10^9+7. 
generating with gpt-4o
----------
['def can_connect(cities, L, R, D):\n    # Check if all consecutive differences in the range [L, R] are divisible by D\n    for i in range(L, R):\n        if abs(cities[i] - cities[i - 1]) % D != 0:\n            return False\n    return True\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    queries = []\n    index = N + 2\n    for _ in range(Q):\n        L = int(data[index])\n        R = int(data[index + 1])\n        D = int(data[index + 2])\n        queries.append((L, R, D))\n        index += 3\n    \n    # Answer each query\n    results = []\n    for L, R, D in queries:\n        if can_connect(cities, L, R, D):\n            results.append("Yes")\n        else:\n            results.append("No")\n    \n    # Print results\n    for result in results:\n        print(result)', 'def can_connect_cities(cities, L, R, D):\n    # If there\'s only one city, it\'s trivially connected\n    if L == R:\n        return True\n    \n    # Calculate the modulo D for the first city in the range\n    mod_value = cities[L] % D\n    \n    # Check if all cities in the range have the same modulo D value\n    for i in range(L + 1, R + 1):\n        if cities[i] % D != mod_value:\n            return False\n    return True\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    queries = []\n    index = N + 2\n    for _ in range(Q):\n        L = int(data[index]) - 1  # Convert to 0-based index\n        R = int(data[index + 1]) - 1  # Convert to 0-based index\n        D = int(data[index + 2])\n        queries.append((L, R, D))\n        index += 3\n    \n    results = []\n    for L, R, D in queries:\n        if can_connect_cities(cities, L, R, D):\n            results.append("Yes")\n        else:\n            results.append("No")\n    \n    for result in results:\n        print(result)', 'import sys\nimport math\n\ndef compute_prefix_gcd(cities):\n    n = len(cities)\n    prefix_gcd = [0] * n\n    prefix_gcd[0] = cities[0]\n    for i in range(1, n):\n        prefix_gcd[i] = math.gcd(prefix_gcd[i-1], cities[i])\n    return prefix_gcd\n\ndef can_connect(cities, L, R, D):\n    if L == R:\n        return True\n    segment_gcd = cities[L-1]\n    for i in range(L, R):\n        segment_gcd = math.gcd(segment_gcd, cities[i])\n    return segment_gcd % D == 0\n\nif __name__ == "__main__":\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    queries = []\n    for i in range(Q):\n        L = int(data[N+2 + i*3])\n        R = int(data[N+3 + i*3])\n        D = int(data[N+4 + i*3])\n        queries.append((L, R, D))\n    \n    results = []\n    for L, R, D in queries:\n        if can_connect(cities, L, R, D):\n            results.append("Yes")\n        else:\n            results.append("No")\n    \n    for result in results:\n        print(result)', 'def can_connect_cities(cities, L, R, D):\n    # Handle edge case where L == R\n    if L == R:\n        return "Yes"\n    \n    # Iterate over the range [L, R] and check consecutive differences\n    for i in range(L - 1, R - 1):\n        if (cities[i + 1] - cities[i]) % D != 0:\n            return "No"\n    \n    return "Yes"\n\ndef process_queries(cities, queries):\n    results = []\n    for L, R, D in queries:\n        result = can_connect_cities(cities, L, R, D)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    queries = []\n    index = N + 2\n    for _ in range(Q):\n        L = int(data[index])\n        R = int(data[index + 1])\n        D = int(data[index + 2])\n        queries.append((L, R, D))\n        index += 3\n    \n    results = process_queries(cities, queries)\n    \n    for result in results:\n        print(result)', 'def can_connect(cities, L, R, D):\n    # Extract the subarray of cities from L to R\n    subarray = cities[L-1:R]\n    \n    # Sort the subarray\n    subarray.sort()\n    \n    # Check if all consecutive cities can be connected with roads of length D\n    for i in range(1, len(subarray)):\n        if (subarray[i] - subarray[i-1]) % D != 0:\n            return "No"\n    \n    return "Yes"\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    results = []\n    index = N + 2\n    for _ in range(Q):\n        L = int(data[index])\n        R = int(data[index+1])\n        D = int(data[index+2])\n        index += 3\n        \n        result = can_connect(cities, L, R, D)\n        results.append(result)\n    \n    for result in results:\n        print(result)', 'def can_connect_cities(cities, l, r, d):\n    # Check if the difference between consecutive cities is divisible by d\n    for i in range(l, r):\n        if (cities[i] - cities[i - 1]) % d != 0:\n            return False\n    return True\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    queries = []\n    for i in range(N+2, len(data), 3):\n        L = int(data[i])\n        R = int(data[i+1])\n        D = int(data[i+2])\n        queries.append((L, R, D))\n    \n    results = []\n    for L, R, D in queries:\n        if can_connect_cities(cities, L, R, D):\n            results.append("Yes")\n        else:\n            results.append("No")\n    \n    for result in results:\n        print(result)', 'from collections import deque\n\ndef can_connect(cities, L, R, D):\n    # Adjust indices to be zero-based\n    L -= 1\n    R -= 1\n    \n    # BFS to check connectivity\n    visited = [False] * (R - L + 1)\n    queue = deque([0])  # Start BFS from the first city in the range\n    visited[0] = True\n    \n    while queue:\n        current = queue.popleft()\n        current_city = cities[L + current]\n        \n        # Check all possible connections from the current city\n        for i in range(R - L + 1):\n            if not visited[i]:\n                next_city = cities[L + i]\n                if (next_city - current_city) % D == 0:\n                    visited[i] = True\n                    queue.append(i)\n    \n    # If all cities in the range are visited, they are connected\n    return all(visited)\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    index = N + 2\n    results = []\n    \n    for _ in range(Q):\n        L = int(data[index])\n        R = int(data[index+1])\n        D = int(data[index+2])\n        index += 3\n        \n        if can_connect(cities, L, R, D):\n            results.append("Yes")\n        else:\n            results.append("No")\n    \n    for result in results:\n        print(result)', 'import sys\nimport math\n\ndef compute_prefix_differences(cities):\n    n = len(cities)\n    prefix_diff = [0] * n\n    for i in range(1, n):\n        prefix_diff[i] = cities[i] - cities[i - 1]\n    return prefix_diff\n\ndef gcd_of_subarray(prefix_diff, L, R):\n    current_gcd = 0\n    for i in range(L + 1, R + 1):\n        current_gcd = math.gcd(current_gcd, prefix_diff[i])\n    return current_gcd\n\ndef can_connect_cities(cities, queries):\n    prefix_diff = compute_prefix_differences(cities)\n    results = []\n    \n    for L, R, D in queries:\n        # Convert to zero-based index\n        L -= 1\n        R -= 1\n        \n        if L == R:\n            # If L == R, it\'s a single city, trivially "Yes"\n            results.append("Yes")\n            continue\n        \n        subarray_gcd = gcd_of_subarray(prefix_diff, L, R)\n        \n        if subarray_gcd % D == 0:\n            results.append("Yes")\n        else:\n            results.append("No")\n    \n    return results\n\nif __name__ == "__main__":\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    queries = []\n    index = N + 2\n    for _ in range(Q):\n        L = int(data[index])\n        R = int(data[index + 1])\n        D = int(data[index + 2])\n        queries.append((L, R, D))\n        index += 3\n    \n    results = can_connect_cities(cities, queries)\n    \n    for result in results:\n        print(result)', 'def can_connect_cities(cities, queries):\n    results = []\n    for L, R, D in queries:\n        can_connect = True\n        for i in range(L - 1, R - 1):  # Adjusting for 0-based indexing\n            if (cities[i + 1] - cities[i]) % D != 0:\n                can_connect = False\n                break\n        if can_connect:\n            results.append("Yes")\n        else:\n            results.append("No")\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    queries = []\n    index = N + 2\n    for _ in range(Q):\n        L = int(data[index])\n        R = int(data[index + 1])\n        D = int(data[index + 2])\n        queries.append((L, R, D))\n        index += 3\n    \n    results = can_connect_cities(cities, queries)\n    \n    for result in results:\n        print(result)', 'def can_connect_cities(cities, L, R, D):\n    # Extract the subarray of cities from L to R\n    subarray = cities[L-1:R]\n    \n    # If the range includes only one city, trivially return "Yes"\n    if len(subarray) == 1:\n        return "Yes"\n    \n    # Sort the subarray\n    subarray.sort()\n    \n    # Check if each consecutive pair of cities has a difference of D\n    for i in range(1, len(subarray)):\n        if subarray[i] - subarray[i-1] != D:\n            return "No"\n    \n    return "Yes"\n\ndef process_queries(cities, queries):\n    results = []\n    for L, R, D in queries:\n        result = can_connect_cities(cities, L, R, D)\n        results.append(result)\n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    N = int(data[0])\n    Q = int(data[1])\n    \n    cities = list(map(int, data[2:N+2]))\n    \n    queries = []\n    index = N + 2\n    for _ in range(Q):\n        L = int(data[index])\n        R = int(data[index+1])\n        D = int(data[index+2])\n        queries.append((L, R, D))\n        index += 3\n    \n    results = process_queries(cities, queries)\n    \n    for result in results:\n        print(result)']
----------
['- name: \nPreprocessing with Modular Arithmetic\n\n- content: \nThis solution preprocesses the array using modular arithmetic to establish possible connections, aiming for efficiency in handling queries.\nSteps:\n1. Preprocess the array by calculating prefix sums of cities modulo D_i for all possible road lengths.\n2. For each query, retrieve the preprocessed prefix sums for the given road length D_i.\n3. Check if all prefix sum values from L_i to R_i are equal, indicating that the cities can be connected with roads of length D_i.\n4. If they are equal, return "Yes", otherwise return "No".\nThis approach uses preprocessing to enable rapid query answers by utilizing prefix sums and modular arithmetic, optimizing performance for large inputs.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'modular arithmetic\'\n    Explanation: Modular arithmetic is a system of arithmetic for integers, where numbers wrap around after reaching a certain value, the modulus. In this context, it is used to determine if cities can be connected using roads of a specific length by checking if the differences between city indices are consistent modulo the road length.\n\n# [phrase showing quantity relationship]\n    \'10^9+7\': This is a large prime number often used as a modulus in competitive programming to prevent overflow and ensure uniform distribution of results.\n    \'1 ≤ N, Q ≤ 2⋅10^5\': Indicates the constraints on the number of cities and queries, which suggests the need for an efficient algorithm.\n    \'0 ≤ D_{i} ≤ 10^9+6\': Specifies the range of possible road lengths, which is crucial for determining connectivity.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 1 and 2 should be implemented simultaneously during preprocessing. This involves calculating prefix sums modulo D_i for all possible road lengths and storing them for quick retrieval during queries.\n\n# [edge case]\n    Edge Case 1: N = 1, Q = 1, cities = [0], query = (1, 1, 0)\n    Expected Output: Yes\n    Explanation: With only one city and a road length of 0, the city is trivially connected to itself.\n\n    Edge Case 2: N = 2, Q = 1, cities = [1, 2], query = (1, 2, 1)\n    Expected Output: No\n    Explanation: The cities cannot be connected with a road length of 1 as they are not equidistant modulo 1.\n\n    Edge Case 3: N = 3, Q = 1, cities = [3, 6, 9], query = (1, 3, 3)\n    Expected Output: Yes\n    Explanation: The cities can be connected with a road length of 3 as they are equidistant modulo 3.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The preprocessing step with modular arithmetic inherently handles these cases by checking the consistency of prefix sums modulo D_i.', '- name: \nEfficient Modulo Difference Check Using Prefix Sums\n\n- content: \nThis approach uses prefix sums to efficiently determine if the differences between cities in the specified range can all be made to match the given road length modulo (10^9+7). The steps are as follows:\n1. Compute a prefix sum array where each element stores the sum of city values up to that index.\n2. For each query, use the prefix sum array to quickly calculate the sum of city values between L and R.\n3. Calculate differences between consecutive cities and adjust them using modular arithmetic.\n4. Check if these adjusted differences are congruent to D modulo (10^9+7).\n5. Output "Yes" if they are congruent for all pairs, otherwise output "No".\nThis method leverages prefix sums to make difference calculations more efficient, reducing time complexity for each query.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'modulo\'\n    Explanation: In the requirement, modulo refers to the operation of finding the remainder when one number is divided by another. It is used here to ensure that the differences between cities can be adjusted to match the given road length.\n\n    \'prefix sums\'\n    Explanation: Prefix sums are a technique used to efficiently calculate the sum of elements in a subarray. By precomputing the sum of elements up to each index, we can quickly find the sum of any subarray.\n\n# [phrase showing quantity relationship]\n    \'10^9+7\': This is a large prime number often used in competitive programming to perform modulo operations, ensuring that results fit within typical integer limits.\n    \'length of the road\': Refers to the fixed distance D that must be maintained between connected cities.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 2-4 should be implemented simultaneously:\n    "Use the prefix sum array to quickly calculate the sum of city values between L and R",\n    "Calculate differences between consecutive cities and adjust them using modular arithmetic",\n    "Check if these adjusted differences are congruent to D modulo (10^9+7)"\n    This can be done by iterating through the range of cities specified in each query, calculating differences, and checking congruence in one loop.\n\n# [edge case] \n    Input: 1 1\n           0\n           1 1 0\n    Output: Yes\n    Explanation: With only one city, no roads are needed, so the output is "Yes" regardless of D.\n\n    Input: 2 1\n           0 0\n           1 2 0\n    Output: Yes\n    Explanation: Both cities have the same value, so they can be connected with a road length of 0.\n\n    Input: 3 1\n           1 2 3\n           1 3 1\n    Output: No\n    Explanation: The differences between consecutive cities (1 and 2) are not congruent to D=1 modulo (10^9+7).\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if L == R:\n            print("Yes")\n            continue\n        if all(cities[i] == cities[L-1] for i in range(L-1, R)):\n            print("Yes")\n            continue\n        (other code)', '- name: \nUnion-Find with Path Compression\n\n- content: \nUtilize a Union-Find data structure with path compression to dynamically connect cities:\n1. Initialize a Union-Find structure with each city as its own parent.\n2. For each query, attempt to connect cities within the range using roads of length D:\n   - For each pair of consecutive cities in the range, check if their difference is a multiple of D.\n   - Use union operation to connect cities satisfying the condition.\n   - After processing all pairs in the range, verify if all cities are part of a single connected component.\n3. Output "Yes" if all cities in the range are connected, otherwise output "No".\nThis approach efficiently manages connections and supports dynamic connectivity checks within queries.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'Union-Find with Path Compression\'\n    Explanation: This is a data structure used to efficiently manage and query connectivity between elements. It helps in dynamically connecting cities and checking if they form a single connected component.\n\n# [phrase showing quantity relationship]\n    \'multiple of D\': This means that the difference between consecutive cities should be divisible by D without a remainder. In code, this can be implemented using the modulus operator: `if (city[i+1] - city[i]) % D == 0`.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented simultaneously within each query. Specifically, checking if consecutive cities can be connected and performing union operations should be done in a single loop for each query.\n\n# [edge case]\n    Input: 1 1\n           5\n           1 1 0\n    Output: Yes\n    Explanation: With only one city, it is trivially connected regardless of the road length D.\n\n    Input: 2 1\n           5 10\n           1 2 5\n    Output: Yes\n    Explanation: The difference between the two cities is exactly 5, which is a multiple of D=5, so they can be connected.\n\n    Input: 3 1\n           5 10 15\n           1 3 5\n    Output: Yes\n    Explanation: All differences between consecutive cities (5) are multiples of D=5, so they can be connected.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic of checking if differences are multiples of D and using union-find will handle these cases correctly.', '- name: \nSegment Tree Approach\n\n- content: \nUsing a segment tree, efficiently compute and query the GCD of city differences over a range. Segment trees allow for fast range queries and updates.\nSteps:\n1. Build a segment tree where each node stores the GCD of city differences for its segment.\n2. For each query, use the segment tree to compute the GCD of the range [L, R].\n3. Check if this GCD is divisible by D and return "Yes" or "No" accordingly.\nThis approach allows handling queries in logarithmic time, ensuring efficiency even for large inputs.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'circle\': The cities are arranged in a circular manner, which means the last city is connected to the first city.\n    \'roads of the same size\': All roads used to connect cities must have the same length.\n    \'GCD\': Greatest Common Divisor, used to determine if a set of numbers can be evenly divided by another number.\n\n# [phrase showing quantity relationship]\n    \'10^9+7\': Represents the total number of cities, which is a large prime number often used in competitive programming for modular arithmetic.\n    \'1 ≤ N, Q ≤ 2⋅10^5\': Indicates the constraints on the number of cities and queries, suggesting the need for efficient algorithms.\n    \'0 ≤ D_{i} ≤ 10^9+6\': Specifies the range for road lengths, which can be very large.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be implemented simultaneously. After computing the GCD for the range [L, R] using the segment tree, immediately check if this GCD is divisible by D to determine the output ("Yes" or "No").\n\n# [edge case]\n    Query with L = R = 1 and D = 0 = Yes\n    Explanation: Since L and R are the same, no road is needed, and any road length (including 0) is trivially valid.\n    \n    Query with L = R = N and D = 10^9+6 = Yes\n    Explanation: Similar to the previous case, no road is needed when L equals R, so any road length is valid.\n    \n    Query with L = 1, R = N, and D = 1 = No\n    Explanation: If D is 1, it requires that all differences between consecutive cities in the range are divisible by 1, which is always true. However, if the cities are not connected in a circular manner or have varying differences, it might not be possible to connect them with roads of length 1.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where L equals R.\n        if L == R:\n            print("Yes")\n        else:\n            # Original logic for handling other cases\n            gcd_value = compute_gcd(segment_tree, L, R)\n            if gcd_value % D == 0:\n                print("Yes")\n            else:\n                print("No")', '- name: \nHashing Differences for Quick Queries\n\n- content: \n- Compute and store the differences between consecutive cities modulo 10^9+7 in a separate array.\n- For each query, examine if all differences in the range [L, R-1] (since R is inclusive but we consider pairs) are identical and equal to D.\n- Use a hash map to quickly check for consistent differences within each queried range.\n- This approach efficiently uses hashing to manage potentially large input sizes and frequent queries.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'circle\'\n    Explanation: The cities are arranged in a circular manner, meaning the last city is connected back to the first city, forming a loop.\n\n    \'roads of the same size\'\n    Explanation: All roads used to connect cities must have the same length, which is specified in each query.\n\n# [phrase showing quantity relationship]\n    \'10^9+7\': This represents the total number of cities arranged in a circle. In code, this can be used as a modulus for operations involving city indices to ensure circular connections.\n    \n    \'1 ≤ N, Q ≤ 2⋅10^5\': This indicates the constraints on the number of cities and queries, which suggests that the solution should be efficient enough to handle large inputs.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The plan suggests computing differences between consecutive cities and storing them. For each query, check if all differences in the specified range are equal to D. This can be implemented using a single loop for each query to check the differences.\n\n# [edge case]\n    Input: 1 1\n           5\n           1 1 0\n    Output: Yes\n    Explanation: With only one city, no roads are needed, so any road length is trivially valid.\n\n    Input: 3 1\n           5 5 5\n           1 3 0\n    Output: No\n    Explanation: All cities are identical, but a road length of 0 does not connect them.\n\n    Input: 5 1\n           1 2 3 4 5\n           1 5 1\n    Output: No\n    Explanation: The differences between consecutive cities are not all equal to 1.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if L == R:\n            print("Yes")\n            continue\n        differences = [(cities[i] - cities[i-1]) % (10**9+7) for i in range(1, N)]\n        for query in queries:\n            L, R, D = query\n            if all(differences[i] == D for i in range(L-1, R-1)):\n                print("Yes")\n            else:\n                print("No")', '- name: \nBrute Force Check for Each Query\n\n- content: \nFor each query, iterate through the cities in the specified range and check if the differences between consecutive cities are divisible by the given road length D_i.\nSteps:\n1. For each query, extract the sublist of cities from L_i to R_i.\n2. Iterate through the sublist and calculate the difference between each consecutive pair of cities.\n3. Check if each difference is divisible by D_i. If all differences are divisible, output "Yes"; otherwise, output "No".\nThis approach is straightforward but may be inefficient for larger inputs due to the repeated calculations for each query.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'circle\'\n    Explanation: The cities are arranged in a circular manner, meaning the last city is connected back to the first city, forming a loop.\n\n    \'roads of the same size\'\n    Explanation: All roads used to connect cities must have the same length, which is specified in each query.\n\n# [phrase showing quantity relationship]\n    \'10^9+7\': This represents the total number of cities arranged in a circle. It is a large number used to define the modulus for calculations.\n    \'divisible by\': This means that the difference between consecutive cities must be exactly divisible by the road length D_i, i.e., the remainder when divided by D_i should be zero.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be implemented simultaneously. As you iterate through the sublist, you can immediately check if the difference is divisible by D_i in the same loop. This avoids unnecessary iterations and checks.\n\n# [edge case] \n    Input: 1 1\n           5\n           1 1 0\n    Output: Yes\n    Explanation: With only one city, no roads are needed, so it is trivially possible to connect it with any road length.\n\n    Input: 3 1\n           1 2 3\n           1 3 1\n    Output: Yes\n    Explanation: The differences between consecutive cities (1 and 2, 2 and 3) are both divisible by 1.\n\n    Input: 5 1\n           10 20 30 40 50\n           1 5 15\n    Output: No\n    Explanation: The differences between consecutive cities (10, 20, etc.) are not all divisible by 15.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if L == R:\n            print("Yes")\n            continue\n        (other code)', '- name: \nGraph-based Connectivity via BFS\n\n- content: \nModel the connection problem as a graph traversal problem where cities represent nodes and roads represent edges of fixed length. Use BFS to check connectivity within the specified range.\nSteps:\n1. Treat each city as a node in a graph.\n2. For each query, construct a graph with edges between cities within range [L, R] that can be connected directly via road length D.\n3. Use BFS starting from the first city in the range to explore connectivity to other cities.\n4. If BFS visits all cities in the range, output "Yes"; otherwise, output "No".\nThis approach transforms the problem into a connectivity checking problem in graph theory, using BFS to efficiently explore connections based on road length constraints.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'cities arranged in a circle\'\n    Explanation: This implies that the cities are connected in a circular manner, meaning the last city is connected back to the first city, forming a loop.\n\n    \'roads of the same size\'\n    Explanation: All roads used to connect cities must have the same length, which is specified in each query.\n\n# [phrase showing quantity relationship]\n    \'10^9+7 cities\'\n    Explanation: This indicates the total number of cities in the colony, which is a large number, emphasizing the need for efficient algorithms.\n\n    \'1 ≤ N, Q ≤ 2⋅10^5\'\n    Explanation: This specifies the constraints on the number of cities and queries, indicating that the solution must handle large inputs efficiently.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be implemented simultaneously.\n    "For each query, construct a graph with edges between cities within range [L, R] that can be connected directly via road length D."\n    "Use BFS starting from the first city in the range to explore connectivity to other cities."\n    These steps can be combined by constructing the graph and immediately performing BFS to check connectivity.\n\n# [edge case]\n    Edge Case 1: N = 1, Q = 1, cities = [0], query = (1, 1, 0)\n    Expected Output: Yes\n    Explanation: With only one city and a road length of 0, it is trivially possible to connect the city to itself.\n\n    Edge Case 2: N = 5, Q = 1, cities = [1, 2, 3, 4, 5], query = (1, 5, 1)\n    Expected Output: Yes\n    Explanation: All cities can be connected sequentially with roads of length 1.\n\n    Edge Case 3: N = 5, Q = 1, cities = [1, 3, 5, 7, 9], query = (1, 5, 2)\n    Expected Output: Yes\n    Explanation: The cities can be connected with roads of length 2 (1-3-5-7-9).\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using BFS will naturally handle these cases by checking connectivity based on road length constraints.', '- name: \nGraph Connectivity via Union-Find\n\n- content: \nTreat each city as a node in a graph and roads of length D as edges. Use a Union-Find data structure to track connected components.\n- Initialize a Union-Find structure for the N cities.\n- For each city pair (i, j), if (cities[i] - cities[j]) modulo 10^9+7 equals D, connect them in the Union-Find structure.\n- For each query, simply check if all cities in range [L, R] belong to the same connected component.\n- This approach efficiently determines connectivity using union-find operations with an overall complexity of O(N log N + Q).\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'circle arrangement\'\n    Explanation: The cities are arranged in a circular manner, which means the last city is connected to the first city, forming a loop.\n\n    \'roads of the same size\'\n    Explanation: All roads used to connect cities must have the same length, D, as specified in each query.\n\n# [phrase showing quantity relationship]\n    \'10^9+7\': This is a large number representing the total number of cities and is used as a modulus for calculations.\n    Explanation: It is used to ensure that operations involving city indices wrap around correctly due to the circular arrangement.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps involving checking connectivity for each query should be implemented simultaneously.\n    Explanation: For each query, you need to check if all cities in the range [L, R] can be connected using roads of length D. This involves checking if they belong to the same connected component in the Union-Find structure.\n\n# [edge case]\n    Input: 1 1\n           0\n           1 1 0\n    Output: Yes\n    Explanation: With only one city, it is trivially connected to itself regardless of road length.\n\n    Input: 5 1\n           1 2 3 4 5\n           1 5 10^9+6\n    Output: No\n    Explanation: The road length is too large to connect any two cities within the given range.\n\n    Input: 3 1\n           5 5 5\n           1 3 0\n    Output: Yes\n    Explanation: All cities have the same value, so they can be connected with roads of length 0.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if N == 1:\n            print("Yes")\n            return\n        # Additional logic for handling large road lengths and identical city values.\n        (other code)', '- name: \nPrefix GCD Array Approach\n\n- content: \n- Precompute a prefix GCD array where prefix_gcd[i] stores the GCD of all city values from 1 to i.\n- For each query (L, R, D), calculate the GCD of cities[L] to cities[R] using the prefix_gcd array.\n- Check if this calculated GCD is divisible by D. If it is, output "Yes", otherwise output "No".\n- This approach leverages precomputation for efficient query processing and ensures that all differences in a range can be checked collectively.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'circle\'\n    Explanation: The cities are arranged in a circular manner, which means the last city is connected to the first city, forming a loop.\n\n    \'roads of the same size\'\n    Explanation: All roads used to connect cities must have the same length, which is specified in each query.\n\n# [phrase showing quantity relationship]\n    \'10^9+7\': This represents the total number of cities arranged in a circle. In code, this can be represented as a constant value for calculations involving city indices.\n    \n    \'1 ≤ N, Q ≤ 2⋅10^5\': This indicates the constraints on the number of cities and queries, which affects the efficiency and scalability of the solution.\n    \n    \'0 ≤ D_{i} ≤ 10^9+6\': This specifies the range of possible road lengths, which must be considered when checking divisibility in queries.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented sequentially. Precomputing the prefix GCD array is a separate step that should be done before processing each query. Each query can then be processed independently using the precomputed data.\n\n# [edge case]\n    Input: 1 1\n           5\n           1 1 5\n    Output: Yes\n    Explanation: With only one city and a road length equal to the city\'s value, it is trivially possible to connect the city to itself.\n\n    Input: 3 1\n           3 6 9\n           1 3 3\n    Output: Yes\n    Explanation: All cities can be connected with roads of length 3 since each city\'s value is divisible by 3.\n\n    Input: 5 1\n           2 4 6 8 10\n           1 5 7\n    Output: No\n    Explanation: None of the cities\' values are divisible by 7, so it\'s impossible to connect them with roads of length 7.\n\n# [extra code for edge case]\n    We do not need extra code to handle the edge cases. The original logic using prefix GCD array and divisibility check will handle these cases correctly.', '- name: \nHash Map for Differences\n\n- content: \nUse a hash map to store the difference between each consecutive city in the list. For each query, extract the subset of cities and compute the differences between consecutive cities. Store these differences in the hash map and check if all differences are equal to D. If they are, return "Yes"; otherwise, return "No". This approach avoids sorting by leveraging hashing for quick checks.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'circle\'\n    Explanation: The cities are arranged in a circular manner, meaning the last city is connected back to the first city, forming a loop.\n\n    \'roads of the same size\'\n    Explanation: All roads used to connect cities must have the same length, specified by D in each query.\n\n# [phrase showing quantity relationship]\n    \'10^9+7\': This represents the total number of cities arranged in a circle. It is a large number used to define the modulus for calculations.\n    \'1 ≤ N, Q ≤ 2⋅10^5\': This indicates the constraints on the number of cities and queries, ensuring they are within a manageable range for computation.\n    \'0 ≤ D_{i} ≤ 10^9+6\': This defines the range for the length of roads, ensuring they are non-negative and within a specified limit.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The plan suggests using a hash map to store differences between consecutive cities. For each query, differences should be checked simultaneously to determine if they are all equal to D. This can be implemented in one code block where differences are calculated and checked in a loop.\n\n# [edge case] \n    Input: 1 1\n           0\n           1 1 0\n    Output: Yes\n    Explanation: With only one city and a road length of 0, it is trivially possible to connect the city to itself.\n\n    Input: 2 1\n           5 5\n           1 2 0\n    Output: Yes\n    Explanation: Two identical cities can be connected with a road length of 0.\n\n    Input: 3 1\n           1 2 3\n           1 3 1\n    Output: No\n    Explanation: The differences between consecutive cities (1 and 2, 2 and 3) are not equal to the road length of 1.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if L == R:\n            return "Yes"\n        differences = []\n        for i in range(L-1, R-1):\n            differences.append(cities[i+1] - cities[i])\n        if all(diff == D for diff in differences):\n            return "Yes"\n        else:\n            return "No"']
----------
True
----------
10
multi-gen-prompt:
There is a city park represented as a tree with n attractions as its vertices and n - 1 rails as its edges. The i-th attraction has happiness value a_i.

Each rail has a color. It is either black if t_i = 0, or white if t_i = 1. Black trains only operate on a black rail track. White trains only operate on a white rail track. If you are previously on a black train and want to ride a white train, or you are previously on a white train and want to ride a black train, you need to use 1 ticket.

The path of a tour must be a simple path — it must not visit an attraction more than once. You do not need a ticket the first time you board a train. You only have k tickets, meaning you can only switch train types at most k times. In particular, you do not need a ticket to go through a path consisting of one rail color.

Define f(u, v) as the sum of happiness values of the attractions in the tour (u, v), which is a simple path that starts at the u-th attraction and ends at the v-th attraction. Find the sum of f(u,v) for all valid tours (u, v) (1 ≤ u ≤ v ≤ n) that does not need more than k tickets, modulo 10^9 + 7.

Input

The first line contains two integers n and k (2 ≤ n ≤ 2 ⋅ 10^5, 0 ≤ k ≤ n-1) — the number of attractions in the city park and the number of tickets you have.

The second line contains n integers a_1, a_2,…, a_n (0 ≤ a_i ≤ 10^9) — the happiness value of each attraction.

The i-th of the next n - 1 lines contains three integers u_i, v_i, and t_i (1 ≤ u_i, v_i ≤ n, 0 ≤ t_i ≤ 1) — an edge between vertices u_i and v_i with color t_i. The given edges form a tree.

Output

Output an integer denoting the total happiness value for all valid tours (u, v) (1 ≤ u ≤ v ≤ n), modulo 10^9 + 7.

Examples

Input


5 0
1 3 2 6 4
1 2 1
1 4 0
3 2 1
2 5 0


Output


45


Input


3 1
1 1 1
1 2 1
3 2 0


Output


10
multi-gen-prompt:
There is a city park represented as a tree with n attractions as its vertices and n - 1 rails as its edges. The i-th attraction has happiness value a_i.

Each rail has a color, either black if t_i = 0, or white if t_i = 1, and black trains operate on black rails while white trains operate on white rails, requiring 1 ticket to switch train colors. The path of a tour must be a simple path — it must not visit an attraction more than once. You do not need a ticket the first time you board a train. You only have k tickets, meaning you can only switch train types at most k times. In particular, you do not need a ticket to go through a path consisting of one rail color.

Define f(u, v) as the sum of happiness values of the attractions in the tour (u, v), which is a simple path that starts at the u-th attraction and ends at the v-th attraction. Find the sum of f(u,v) for all valid tours (u, v) (1 ≤ u ≤ v ≤ n) that does not need more than k tickets, modulo 10^9 + 7.

Input

The first line contains two integers n and k (2 ≤ n ≤ 2 ⋅ 10^5, 0 ≤ k ≤ n-1) — the number of attractions in the city park and the number of tickets you have.

The second line contains n integers a_1, a_2,…, a_n (0 ≤ a_i ≤ 10^9) — the happiness value of each attraction.

The i-th of the next n - 1 lines contains three integers u_i, v_i, and t_i (1 ≤ u_i, v_i ≤ n, 0 ≤ t_i ≤ 1) — an edge between vertices u_i and v_i with color t_i. The given edges form a tree.

Output

Output an integer denoting the total happiness value for all valid tours (u, v) (1 ≤ u ≤ v ≤ n), modulo 10^9 + 7.

Examples

Input


5 0
1 3 2 6 4
1 2 1
1 4 0
3 2 1
2 5 0


Output


45


Input


3 1
1 1 1
1 2 1
3 2 0


Output


10
generating with gpt-4o
----------
['MOD = 10**9 + 7\n\ndef dfs(node, parent, current_color, switch_count, adj_list, happiness_values, k, dp):\n    # Base case: if switch_count exceeds k, return 0\n    if switch_count > k:\n        return 0\n    \n    # Store the result in dp to avoid recomputation\n    if (node, switch_count) in dp:\n        return dp[(node, switch_count)]\n    \n    # Initialize total happiness for this path\n    total_happiness = happiness_values[node - 1]\n    \n    # Explore all adjacent nodes\n    for neighbor, rail_color in adj_list[node]:\n        if neighbor == parent:\n            continue\n        \n        # Determine if a switch is needed\n        new_switch_count = switch_count + (1 if rail_color != current_color and current_color != -1 else 0)\n        \n        # Recursively calculate happiness for the subtree rooted at the neighbor\n        total_happiness += dfs(neighbor, node, rail_color, new_switch_count, adj_list, happiness_values, k, dp)\n        total_happiness %= MOD\n    \n    # Store the result in dp\n    dp[(node, switch_count)] = total_happiness\n    return total_happiness\n\ndef calculate_happiness(n, k, happiness_values, edges):\n    # Create adjacency list\n    adj_list = [[] for _ in range(n + 1)]\n    for u, v, t in edges:\n        adj_list[u].append((v, t))\n        adj_list[v].append((u, t))\n    \n    # Initialize total happiness\n    total_happiness = 0\n    \n    # Perform DFS from each node as a starting point\n    for start_node in range(1, n + 1):\n        dp = {}\n        total_happiness += dfs(start_node, -1, -1, 0, adj_list, happiness_values, k, dp)\n        total_happiness %= MOD\n    \n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    k = int(data[1])\n    \n    happiness_values = list(map(int, data[2:n+2]))\n    \n    edges = []\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n    \n    result = calculate_happiness(n, k, happiness_values, edges)\n    print(result)', 'def centroid_decomposition(tree, n):\n    # Helper function to calculate subtree sizes\n    def calculate_subtree_sizes(node, parent):\n        size = 1\n        for neighbor, _ in tree[node]:\n            if neighbor != parent and not removed[neighbor]:\n                size += calculate_subtree_sizes(neighbor, node)\n        subtree_sizes[node] = size\n        return size\n\n    # Helper function to find the centroid of a subtree\n    def find_centroid(node, parent, total_size):\n        for neighbor, _ in tree[node]:\n            if neighbor != parent and not removed[neighbor] and subtree_sizes[neighbor] > total_size // 2:\n                return find_centroid(neighbor, node, total_size)\n        return node\n\n    # Main decomposition function\n    def decompose(node):\n        total_size = calculate_subtree_sizes(node, -1)\n        centroid = find_centroid(node, -1, total_size)\n        removed[centroid] = True\n        centroids.append(centroid)\n\n        for neighbor, _ in tree[centroid]:\n            if not removed[neighbor]:\n                decompose(neighbor)\n\n    subtree_sizes = [0] * n\n    removed = [False] * n\n    centroids = []\n    decompose(0)\n    return centroids, removed\n\ndef solve(n, k, happiness_values, edges):\n    MOD = 10**9 + 7\n\n    # Build the tree from edges\n    tree = [[] for _ in range(n)]\n    for u, v, t in edges:\n        tree[u-1].append((v-1, t))\n        tree[v-1].append((u-1, t))\n\n    # Perform centroid decomposition\n    centroids, removed = centroid_decomposition(tree, n)\n\n    # Initialize DP tables and other necessary structures\n    dp_black = [0] * n\n    dp_white = [0] * n\n\n    # Function to calculate happiness values using DP\n    def calculate_happiness(centroid, removed):\n        # Reset DP tables for the current centroid\n        dp_black[centroid] = happiness_values[centroid]\n        dp_white[centroid] = happiness_values[centroid]\n\n        # Traverse the tree from the centroid and calculate DP values\n        def dfs(node, parent, current_color, tickets_used, removed):\n            if tickets_used > k:\n                return\n\n            for neighbor, rail_color in tree[node]:\n                if neighbor == parent or removed[neighbor]:\n                    continue\n\n                if rail_color == current_color:\n                    dfs(neighbor, node, current_color, tickets_used, removed)\n                else:\n                    dfs(neighbor, node, rail_color, tickets_used + 1, removed)\n\n                if rail_color == 0:  # Black rail\n                    dp_black[node] += dp_black[neighbor]\n                    dp_black[node] %= MOD\n                else:  # White rail\n                    dp_white[node] += dp_white[neighbor]\n                    dp_white[node] %= MOD\n\n        dfs(centroid, -1, 0, 0, removed)  # Start with black rail\n        dfs(centroid, -1, 1, 0, removed)  # Start with white rail\n\n    total_happiness = 0\n\n    # Calculate happiness for each centroid component\n    for centroid in centroids:\n        calculate_happiness(centroid, removed)\n        total_happiness += dp_black[centroid] + dp_white[centroid]\n        total_happiness %= MOD\n\n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n\n    n = int(data[0])\n    k = int(data[1])\n    happiness_values = list(map(int, data[2:n+2]))\n    \n    edges = []\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n\n    result = solve(n, k, happiness_values, edges)\n    print(result)', 'def dfs(node, parent, adj_list, happiness_values, dp, k):\n    # Initialize dp for the current node\n    dp[node][0] = happiness_values[node - 1]\n    \n    # Explore neighbors\n    for neighbor, rail_color in adj_list[node]:\n        if neighbor != parent:\n            dfs(neighbor, node, adj_list, happiness_values, dp, k)\n            \n            # Update dp for the current node based on the neighbor\'s dp\n            for i in range(k + 1):\n                dp[node][i] += dp[neighbor][i]\n                if i > 0:\n                    dp[node][i] = max(dp[node][i], dp[neighbor][i - 1] + happiness_values[node - 1])\n\ndef calculate_happiness(n, k, happiness_values, edges):\n    MOD = 10**9 + 7\n    \n    # Build adjacency list\n    adj_list = [[] for _ in range(n + 1)]\n    for u, v, t in edges:\n        adj_list[u].append((v, t))\n        adj_list[v].append((u, t))\n    \n    # Initialize dp array\n    dp = [[0] * (k + 1) for _ in range(n + 1)]\n    \n    # Perform DFS from an arbitrary root node (e.g., node 1)\n    dfs(1, -1, adj_list, happiness_values, dp, k)\n    \n    # Calculate total happiness\n    total_happiness = sum(dp[i][k] for i in range(1, n + 1)) % MOD\n    \n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    k = int(data[1])\n    \n    happiness_values = list(map(int, data[2:n+2]))\n    \n    edges = []\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n    \n    result = calculate_happiness(n, k, happiness_values, edges)\n    print(result)', 'def dfs(node, parent, color, adj, happiness, dp_black, dp_white, k):\n    # Initialize DP tables for the current node\n    dp_black[node] = [0] * (k + 1)\n    dp_white[node] = [0] * (k + 1)\n    \n    # Base case: happiness value of the node itself\n    dp_black[node][0] = happiness[node]\n    dp_white[node][0] = happiness[node]\n    \n    for neighbor, rail_color in adj[node]:\n        if neighbor == parent:\n            continue\n        \n        # Perform DFS on the child node\n        dfs(neighbor, node, rail_color, adj, happiness, dp_black, dp_white, k)\n        \n        # Update DP tables based on the rail color\n        if rail_color == 0:  # Black rail\n            for i in range(k + 1):\n                dp_black[node][i] += dp_black[neighbor][i]\n                if i > 0:\n                    dp_black[node][i] = max(dp_black[node][i], dp_white[neighbor][i - 1] + happiness[node])\n        else:  # White rail\n            for i in range(k + 1):\n                dp_white[node][i] += dp_white[neighbor][i]\n                if i > 0:\n                    dp_white[node][i] = max(dp_white[node][i], dp_black[neighbor][i - 1] + happiness[node])\n\ndef calculate_total_happiness(n, k, happiness, edges):\n    MOD = 10**9 + 7\n    \n    # Convert happiness values to zero-based index\n    happiness = [0] + happiness\n    \n    # Build adjacency list\n    adj = [[] for _ in range(n + 1)]\n    for u, v, t in edges:\n        adj[u].append((v, t))\n        adj[v].append((u, t))\n    \n    # Initialize DP tables\n    dp_black = [[0] * (k + 1) for _ in range(n + 1)]\n    dp_white = [[0] * (k + 1) for _ in range(n + 1)]\n    \n    # Perform DFS from node 1 (assuming node indices start from 1)\n    dfs(1, -1, -1, adj, happiness, dp_black, dp_white, k)\n    \n    # Calculate total happiness sum\n    total_happiness = 0\n    for node in range(1, n + 1):\n        for i in range(k + 1):\n            total_happiness += dp_black[node][i]\n            total_happiness += dp_white[node][i]\n            total_happiness %= MOD\n    \n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    k = int(data[1])\n    \n    happiness = list(map(int, data[2:n+2]))\n    \n    edges = []\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n    \n    result = calculate_total_happiness(n, k, happiness, edges)\n    print(result)', 'def dfs(attraction, parent, current_color, switches, happiness_values, adj_list, k, visited):\n    MOD = 10**9 + 7\n    total_happiness = happiness_values[attraction]\n    \n    for neighbor, rail_color in adj_list[attraction]:\n        if neighbor == parent or visited[neighbor]:\n            continue\n        \n        new_switches = switches\n        if current_color is not None and rail_color != current_color:\n            new_switches += 1\n        \n        if new_switches <= k:\n            visited[neighbor] = True\n            total_happiness += dfs(neighbor, attraction, rail_color, new_switches, happiness_values, adj_list, k, visited)\n            visited[neighbor] = False\n    \n    return total_happiness % MOD\n\ndef calculate_happiness(n, k, happiness_values, edges):\n    MOD = 10**9 + 7\n    adj_list = [[] for _ in range(n)]\n    \n    for u, v, t in edges:\n        adj_list[u-1].append((v-1, t))\n        adj_list[v-1].append((u-1, t))\n    \n    total_happiness = 0\n    \n    for start in range(n):\n        visited = [False] * n\n        visited[start] = True\n        total_happiness += dfs(start, -1, None, 0, happiness_values, adj_list, k, visited)\n        total_happiness %= MOD\n    \n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    k = int(data[1])\n    \n    happiness_values = list(map(int, data[2:n+2]))\n    \n    edges = []\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n    \n    result = calculate_happiness(n, k, happiness_values, edges)\n    print(result)', 'def dfs(node, parent, dp, adj, happiness, k):\n    MOD = 10**9 + 7\n    n = len(happiness)\n    \n    # Initialize DP table for current node\n    dp[node][0][0] = dp[node][0][1] = happiness[node]\n    \n    for neighbor, rail_color in adj[node]:\n        if neighbor == parent:\n            continue\n        \n        dfs(neighbor, node, dp, adj, happiness, k)\n        \n        # Update DP table for current node based on its children\n        for c in range(k + 1):\n            for t in range(2):\n                if t == rail_color:\n                    dp[node][c][t] = (dp[node][c][t] + dp[neighbor][c][t]) % MOD\n                elif c < k:\n                    dp[node][c + 1][rail_color] = (dp[node][c + 1][rail_color] + dp[neighbor][c][t]) % MOD\n\ndef calculate_total_happiness(n, k, happiness, edges):\n    MOD = 10**9 + 7\n    \n    # Convert happiness to zero-indexed\n    happiness = [0] + happiness\n    \n    # Build adjacency list\n    adj = [[] for _ in range(n + 1)]\n    for u, v, t in edges:\n        adj[u].append((v, t))\n        adj[v].append((u, t))\n    \n    # Initialize DP table\n    dp = [[[0] * 2 for _ in range(k + 1)] for _ in range(n + 1)]\n    \n    # Perform DFS from node 1\n    dfs(1, -1, dp, adj, happiness, k)\n    \n    # Sum up all valid paths\' happiness values\n    total_happiness = 0\n    for u in range(1, n + 1):\n        for c in range(k + 1):\n            for t in range(2):\n                total_happiness = (total_happiness + dp[u][c][t]) % MOD\n    \n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    k = int(data[1])\n    \n    happiness = list(map(int, data[2:n+2]))\n    \n    edges = []\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n    \n    result = calculate_total_happiness(n, k, happiness, edges)\n    print(result)', 'def dfs(node, parent, graph, happiness, dp, k):\n    MOD = 10**9 + 7\n    dp[node][0][0] = happiness[node]\n    dp[node][0][1] = happiness[node]\n    \n    for neighbor, rail_color in graph[node]:\n        if neighbor == parent:\n            continue\n        dfs(neighbor, node, graph, happiness, dp, k)\n        \n        new_dp = [[-1] * 2 for _ in range(k + 1)]\n        \n        for switches in range(k + 1):\n            for current_color in range(2):\n                if dp[node][switches][current_color] == -1:\n                    continue\n                \n                for neighbor_switches in range(k + 1 - switches):\n                    if dp[neighbor][neighbor_switches][rail_color] == -1:\n                        continue\n                    \n                    new_switches = switches + (current_color != rail_color)\n                    if new_switches <= k:\n                        new_dp[new_switches][rail_color] = max(\n                            new_dp[new_switches][rail_color],\n                            dp[node][switches][current_color] + dp[neighbor][neighbor_switches][rail_color]\n                        )\n        \n        for switches in range(k + 1):\n            for current_color in range(2):\n                if new_dp[switches][current_color] != -1:\n                    dp[node][switches][current_color] = max(\n                        dp[node][switches][current_color],\n                        new_dp[switches][current_color]\n                    )\n    \n    for switches in range(k + 1):\n        for current_color in range(2):\n            if dp[node][switches][current_color] != -1:\n                dp[node][switches][current_color] %= MOD\n\ndef calculate_happiness(n, k, happiness_values, edges):\n    MOD = 10**9 + 7\n    graph = [[] for _ in range(n)]\n    \n    for u, v, t in edges:\n        graph[u - 1].append((v - 1, t))\n        graph[v - 1].append((u - 1, t))\n    \n    dp = [[[-1] * 2 for _ in range(k + 1)] for _ in range(n)]\n    \n    dfs(0, -1, graph, happiness_values, dp, k)\n    \n    total_happiness = 0\n    for node in range(n):\n        for switches in range(k + 1):\n            for current_color in range(2):\n                if dp[node][switches][current_color] != -1:\n                    total_happiness += dp[node][switches][current_color]\n                    total_happiness %= MOD\n    \n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    k = int(data[1])\n    \n    happiness_values = list(map(int, data[2:n+2]))\n    \n    edges = []\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n    \n    result = calculate_happiness(n, k, happiness_values, edges)\n    print(result)', 'def dfs(node, parent, dp, adj, happiness, k, mod):\n    # Initialize DP table for the current node\n    dp[node][0] = happiness[node]\n    \n    # Traverse all children of the current node\n    for neighbor, rail_color in adj[node]:\n        if neighbor == parent:\n            continue\n        \n        # Perform DFS on the child node\n        dfs(neighbor, node, dp, adj, happiness, k, mod)\n        \n        # Update DP table for the current node using the child\'s DP table\n        for switches in range(k + 1):\n            dp[node][switches] = (dp[node][switches] + dp[neighbor][switches]) % mod\n            if switches > 0:\n                dp[node][switches] = (dp[node][switches] + dp[neighbor][switches - 1]) % mod\n\ndef calculate_total_happiness(n, k, happiness, edges):\n    mod = 10**9 + 7\n    \n    # Build adjacency list for the tree\n    adj = [[] for _ in range(n + 1)]\n    for u, v, t in edges:\n        adj[u].append((v, t))\n        adj[v].append((u, t))\n    \n    # Initialize DP table\n    dp = [[0] * (k + 1) for _ in range(n + 1)]\n    \n    # Perform DFS from node 1 (assuming 1-based index)\n    dfs(1, -1, dp, adj, happiness, k, mod)\n    \n    # Calculate total happiness from DP table\n    total_happiness = sum(sum(dp[i]) for i in range(1, n + 1)) % mod\n    \n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    k = int(data[1])\n    \n    # Adjust happiness list to be 1-based by adding a dummy element at the start\n    happiness = [0] + list(map(int, data[2:n+2]))\n    \n    edges = []\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n    \n    result = calculate_total_happiness(n, k, happiness, edges)\n    print(result)', 'def dfs_size_and_parent(node, parent, adj, size, parent_list):\n    size[node] = 1\n    parent_list[node] = parent\n    for neighbor, color in adj[node]:\n        if neighbor != parent:\n            dfs_size_and_parent(neighbor, node, adj, size, parent_list)\n            size[node] += size[neighbor]\n\ndef dfs_hld(node, parent, adj, size, chain_head, chain_index, pos_in_base, base_array, current_chain, current_pos):\n    chain_head[node] = current_chain\n    chain_index[node] = current_pos\n    pos_in_base[node] = len(base_array)\n    base_array.append(node)\n\n    # Find the heavy child\n    heavy_child = -1\n    max_size = -1\n    for neighbor, color in adj[node]:\n        if neighbor != parent and size[neighbor] > max_size:\n            max_size = size[neighbor]\n            heavy_child = neighbor\n\n    # Process the heavy child\n    if heavy_child != -1:\n        dfs_hld(heavy_child, node, adj, size, chain_head, chain_index, pos_in_base, base_array, current_chain, current_pos + 1)\n\n    # Process the light children\n    for neighbor, color in adj[node]:\n        if neighbor != parent and neighbor != heavy_child:\n            dfs_hld(neighbor, node, adj, size, chain_head, chain_index, pos_in_base, base_array, neighbor, 0)\n\ndef build_segment_tree(base_array, happiness_values):\n    n = len(base_array)\n    seg_tree = [0] * (2 * n)\n    for i in range(n):\n        seg_tree[n + i] = happiness_values[base_array[i]]\n    for i in range(n - 1, 0, -1):\n        seg_tree[i] = seg_tree[2 * i] + seg_tree[2 * i + 1]\n    return seg_tree\n\ndef query_segment_tree(seg_tree, l, r):\n    n = len(seg_tree) // 2\n    l += n\n    r += n\n    sum_happiness = 0\n    while l < r:\n        if l & 1:\n            sum_happiness += seg_tree[l]\n            l += 1\n        if r & 1:\n            r -= 1\n            sum_happiness += seg_tree[r]\n        l //= 2\n        r //= 2\n    return sum_happiness\n\ndef path_query(u, v, chain_head, chain_index, pos_in_base, seg_tree, parent_list):\n    sum_happiness = 0\n    while chain_head[u] != chain_head[v]:\n        if chain_index[u] < chain_index[v]:\n            u, v = v, u\n        head_u = chain_head[u]\n        sum_happiness += query_segment_tree(seg_tree, pos_in_base[head_u], pos_in_base[u] + 1)\n        u = parent_list[head_u]\n    if chain_index[u] > chain_index[v]:\n        u, v = v, u\n    sum_happiness += query_segment_tree(seg_tree, pos_in_base[u], pos_in_base[v] + 1)\n    return sum_happiness\n\ndef calculate_total_happiness(n, k, happiness_values, edges):\n    MOD = 10**9 + 7\n\n    # Build adjacency list with edge colors\n    adj = [[] for _ in range(n)]\n    for u, v, t in edges:\n        adj[u - 1].append((v - 1, t))\n        adj[v - 1].append((u - 1, t))\n\n    # Initialize arrays for HLD\n    size = [0] * n\n    parent_list = [-1] * n\n    chain_head = [-1] * n\n    chain_index = [-1] * n\n    pos_in_base = [-1] * n\n    base_array = []\n\n    # Perform initial DFS to calculate sizes and parents\n    dfs_size_and_parent(0, -1, adj, size, parent_list)\n\n    # Perform HLD decomposition\n    dfs_hld(0, -1, adj, size, chain_head, chain_index, pos_in_base, base_array, 0, 0)\n\n    # Build segment tree for happiness values along the base array\n    seg_tree = build_segment_tree(base_array, happiness_values)\n\n    # Calculate total happiness for all valid paths (u,v)\n    total_happiness = 0\n\n    # Iterate over all pairs (u,v) and calculate happiness using path queries\n    for u in range(n):\n        for v in range(u + 1, n):\n            total_happiness += path_query(u, v, chain_head, chain_index, pos_in_base, seg_tree, parent_list)\n            total_happiness %= MOD\n\n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    n = int(data[0])\n    k = int(data[1])\n    \n    happiness_values = list(map(int, data[2:n+2]))\n    \n    edges = []\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n    \n    result = calculate_total_happiness(n, k, happiness_values, edges)\n    \n    print(result)', 'def dfs(node, parent, graph, happiness, dp, k):\n    # Initialize the DP table for the current node\n    dp[node][0][0] = happiness[node]\n    dp[node][0][1] = happiness[node]\n    \n    # Traverse each neighbor\n    for neighbor, edge_color in graph[node]:\n        if neighbor == parent:\n            continue\n        \n        # Perform DFS on the child node\n        dfs(neighbor, node, graph, happiness, dp, k)\n        \n        # Update DP table for the current node based on the child node\'s DP table\n        for tickets_used in range(k + 1):\n            # If the edge color is the same as the current train color\n            dp[node][tickets_used][edge_color] += dp[neighbor][tickets_used][edge_color]\n            \n            # If we can switch train types (use a ticket)\n            if tickets_used > 0:\n                dp[node][tickets_used][edge_color] += dp[neighbor][tickets_used - 1][1 - edge_color]\n\ndef calculate_happiness(n, k, happiness_values, edges):\n    MOD = 10**9 + 7\n\n    # Build the graph\n    graph = [[] for _ in range(n)]\n    for u, v, t in edges:\n        graph[u - 1].append((v - 1, t))\n        graph[v - 1].append((u - 1, t))\n\n    # Initialize DP table\n    dp = [[[0] * 2 for _ in range(k + 1)] for _ in range(n)]\n\n    # Perform DFS starting from node 0 (or any arbitrary node)\n    dfs(0, -1, graph, happiness_values, dp, k)\n\n    # Calculate total happiness by summing up all possible paths\n    total_happiness = sum(dp[i][j][c] for i in range(n) for j in range(k + 1) for c in range(2)) % MOD\n\n    return total_happiness\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n\n    n = int(data[0])\n    k = int(data[1])\n    happiness_values = list(map(int, data[2:n+2]))\n    edges = []\n\n    index = n + 2\n    for _ in range(n - 1):\n        u = int(data[index])\n        v = int(data[index + 1])\n        t = int(data[index + 2])\n        edges.append((u, v, t))\n        index += 3\n\n    result = calculate_happiness(n, k, happiness_values, edges)\n    print(result)']
----------
["- name: \nCentroid Decomposition with Path Counting\n- content: \n- Use centroid decomposition to break the tree into smaller subproblems.\n- For each centroid, consider paths that start and end at any of its subtree nodes.\n- Count paths using a color-based two-pointer technique to avoid counting invalid paths with too many switches.\n- Maintain a balance between black and white paths using a data structure like a multiset.\n- For each valid path, calculate and accumulate its happiness sum, applying modulo 10^9 + 7.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected graph with no cycles, meaning there is exactly one path between any two vertices.\n\n    'happiness value'\n    Explanation: Each attraction has a happiness value associated with it, which contributes to the total happiness of a tour.\n\n    'rail color'\n    Explanation: Rails can be either black or white, and the color determines which type of train can operate on them.\n\n    'tickets'\n    Explanation: Tickets are used to switch between train types. You can switch at most k times.\n\n# [phrase showing quantity relationship]\n    'n - 1 rails': Indicates that the number of edges in the tree is one less than the number of vertices.\n    'at most k times': Indicates the maximum number of train type switches allowed, which is implemented by checking if the number of switches does not exceed k.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps involving counting paths and maintaining a balance between black and white paths should be implemented simultaneously. This can be done using a two-pointer technique and a multiset to efficiently manage path counts and ensure valid paths are considered.\n\n# [edge case]\n    Edge case 1: n = 2, k = 0, a = [1, 2], edges = [(1, 2, 0)]\n    Expected output: 3\n    Explanation: With only one edge and no tickets, the only valid tour is from attraction 1 to 2, summing their happiness values.\n\n    Edge case 2: n = 3, k = 1, a = [1, 1, 1], edges = [(1, 2, 1), (3, 2, 0)]\n    Expected output: 10\n    Explanation: All tours are valid with one ticket available for switching train types.\n\n    Edge case 3: n = 4, k = 0, a = [5, 5, 5, 5], edges = [(1, 2, 0), (2, 3, 0), (3, 4, 0)]\n    Expected output: 40\n    Explanation: All rails are of the same color (black), so no tickets are needed for any tour.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        - Implement centroid decomposition to break down the tree.\n        - Use a two-pointer technique to count valid paths without exceeding k switches.\n        - Use a multiset or similar data structure to maintain path balance and count efficiently.", "- name: \nDynamic Programming with Tree Decomposition\n\n- content: \nUtilize dynamic programming along with tree decomposition techniques such as centroid decomposition to efficiently calculate the sum of happiness values for all valid tours. The approach breaks down the problem into smaller subproblems based on tree partitions:\n1. Perform a centroid decomposition on the tree to divide it into smaller components.\n2. Use dynamic programming within each component to calculate happiness values for paths, considering train color switches.\n3. Maintain DP tables to store happiness sums for each node and train color combinations.\n4. Aggregate results from all components to obtain the total happiness value of valid tours.\n5. Ensure results are computed modulo 10^9 + 7 for all valid tours.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree': A data structure consisting of nodes connected by edges, forming a hierarchy with a single root node and no cycles.\n    'happiness value': The value associated with each attraction, representing the level of happiness it provides.\n    'rail color': The color of the rail, which determines the type of train that can operate on it (black or white).\n    'ticket': A resource that allows switching between train types.\n\n# [phrase showing quantity relationship]\n    'n - 1 rails': Indicates the number of edges in the tree, which is one less than the number of vertices.\n    'at most k times': Specifies the maximum number of train type switches allowed, which is limited by the number of tickets.\n\n# [degree adverb]\n    No degree adverb present in the requirement.\n\n# [code logic]\n    Steps 1 and 2 should be implemented simultaneously as they both involve processing the tree structure to set up the dynamic programming framework. This can be done by performing centroid decomposition and initializing DP tables in one code block.\n\n# [edge case]\n    Edge case 1: n = 2, k = 0, a = [1, 1], edges = [(1, 2, 0)]\n    Expected output: 2\n    Explanation: With only two attractions and no tickets, the only valid tour is from attraction 1 to 2 without switching train types.\n\n    Edge case 2: n = 3, k = 0, a = [1, 2, 3], edges = [(1, 2, 0), (2, 3, 0)]\n    Expected output: 12\n    Explanation: All attractions are connected by black rails, allowing tours without switching train types.\n\n    Edge case 3: n = 4, k = 1, a = [1, 2, 3, 4], edges = [(1, 2, 0), (2, 3, 1), (3, 4, 0)]\n    Expected output: 20\n    Explanation: With one ticket available, a switch from black to white rail is possible once, allowing tours that include all attractions.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling edge cases)\n        Ensure that the DP tables are initialized correctly to handle cases with minimal attractions and tickets.\n        Implement logic to check rail colors and manage ticket usage efficiently within the DP framework.", "- name: \nDynamic Programming with Preprocessing\n\n- content: \n- Use a dynamic programming approach to track the maximum happiness from each node to other nodes with at most k train type switches.\n- Preprocess the tree to determine distances and paths between nodes using a BFS or DFS to set up an ancestor matrix or similar structure.\n- For each node, iterate over all possible endpoints and compute possible happiness sums for paths with varying switch counts, using precomputed data to quickly determine feasibility.\n- Use dynamic programming to calculate and cache results of subproblems (happiness sums for sub-paths) to optimize repeated calculations.\n- Aggregate results to obtain the total happiness sum modulo 10^9 + 7.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected graph with no cycles, meaning there is exactly one path between any two vertices.\n\n    'happiness value'\n    Explanation: Each attraction has a happiness value associated with it, which contributes to the total happiness of a tour.\n\n    'rail color'\n    Explanation: Rails can be either black or white, and the color determines which type of train can operate on them.\n\n    'ticket'\n    Explanation: Tickets are used to switch between train types. You can switch at most k times.\n\n# [phrase showing quantity relationship]\n    'at most k times': You can switch train types up to k times, meaning the number of switches must be ≤ k.\n    Implementation: Use a counter to track the number of switches and ensure it does not exceed k.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The preprocessing step to determine distances and paths between nodes should be implemented simultaneously with setting up an ancestor matrix or similar structure. This can be done using BFS or DFS in one code block.\n\n# [edge case]\n    Edge case 1: n = 2, k = 0, happiness values = [1, 2], edges = [(1, 2, 0)]\n    Expected output: 3\n    Explanation: With only one edge and no tickets, the only valid tour is from attraction 1 to 2, summing their happiness values.\n\n    Edge case 2: n = 3, k = 1, happiness values = [1, 1, 1], edges = [(1, 2, 1), (3, 2, 0)]\n    Expected output: 10\n    Explanation: You can switch train types once, allowing tours that include all attractions.\n\n    Edge case 3: n = 4, k = 0, happiness values = [5, 5, 5, 5], edges = [(1, 2, 0), (2, 3, 0), (3, 4, 0)]\n    Expected output: 40\n    Explanation: All rails are the same color, so no tickets are needed. All tours are valid.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        # Ensure that the number of switches does not exceed k\n        def is_valid_tour(switch_count, k):\n            return switch_count <= k\n\n        # Preprocess tree using BFS/DFS\n        def preprocess_tree(n, edges):\n            # Initialize ancestor matrix or similar structure\n            # Perform BFS/DFS to set up distances and paths\n\n        # Calculate happiness sums using dynamic programming\n        def calculate_happiness(n, k, happiness_values, edges):\n            preprocess_tree(n, edges)\n            total_happiness = 0\n            # Iterate over all nodes and endpoints\n            for u in range(1, n+1):\n                for v in range(u, n+1):\n                    if is_valid_tour(switch_count(u, v), k):\n                        total_happiness += compute_happiness(u, v)\n            return total_happiness % (10**9 + 7)", "- name: \nDynamic Programming with Tree Decomposition\n- content: \nThis method uses dynamic programming combined with tree decomposition to efficiently compute the sum of happiness for all valid paths.\n\nSteps:\n1. Utilize a tree decomposition algorithm to break down the tree into components, focusing on minimizing switches.\n2. Use dynamic programming to calculate possible paths and associated happiness sums within each component, storing results in a DP table indexed by node and switch count.\n3. Merge results from components, ensuring the switch count does not exceed k.\n4. Iterate through potential paths using precomputed values, summing happiness values where paths meet criteria.\n5. Apply modulo operation to ensure results fit within required constraints.\n\nThis approach aims to reduce complexity by leveraging tree properties and avoiding redundant calculations.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree': A data structure consisting of nodes connected by edges, forming a hierarchy with a single root node and no cycles.\n    'happiness value': A numerical value associated with each attraction, representing the level of happiness it provides.\n    'rail color': Indicates the type of rail (black or white) that connects attractions, affecting train operations and ticket usage.\n\n# [phrase showing quantity relationship]\n    'n - 1 rails': Indicates the number of edges in the tree, which is always one less than the number of vertices (attractions).\n    'at most k times': Specifies the maximum number of train type switches allowed, which is crucial for determining valid paths.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be considered simultaneously as they both involve calculating paths and merging results based on switch counts. This can be implemented using dynamic programming to store and update path information efficiently.\n\n# [edge case]\n    Edge Case 1: n = 2, k = 0, happiness values = [1, 1], edges = [(1, 2, 0)]\n    Expected Output: 2\n    Explanation: With only one edge and no switches allowed, the only valid path is from attraction 1 to 2, summing their happiness values.\n\n    Edge Case 2: n = 3, k = 1, happiness values = [1, 2, 3], edges = [(1, 2, 0), (2, 3, 1)]\n    Expected Output: 6\n    Explanation: Paths (1,2), (2,3), and (1,3) are valid with one switch allowed. The sum of happiness values is 6.\n\n    Edge Case 3: n = 4, k = 0, happiness values = [5, 5, 5, 5], edges = [(1, 2, 0), (2, 3, 0), (3, 4, 0)]\n    Expected Output: 20\n    Explanation: All attractions are connected by black rails with no switches needed. The sum of all happiness values is valid.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if k == 0:\n            # Handle paths with no switches allowed\n            calculate_paths_no_switch()\n        else:\n            # Handle paths with switches allowed\n            calculate_paths_with_switch()\n        # Apply modulo operation\n        result %= (10**9 + 7)", '- name: \nDFS with Memoization\n\n- content: \n- Use Depth-First Search (DFS) to explore the tree starting from each node.\n- For each node, calculate all possible paths and their happiness sums while keeping track of the number of train type switches.\n- Use memoization to store already computed paths and their happiness sums to avoid redundant calculations.\n- Only consider paths that require k or fewer switches.\n- Sum all valid paths\' happiness values, and return the result modulo 10^9 + 7.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected graph with no cycles, meaning there is exactly one path between any two vertices. In this context, the attractions and rails form a tree structure.\n\n    \'happiness value\'\n    Explanation: Each attraction has a happiness value associated with it, which contributes to the total happiness of a tour.\n\n    \'simple path\'\n    Explanation: A simple path is a path that does not visit any vertex more than once.\n\n    \'ticket\'\n    Explanation: A ticket is required to switch between train types (black to white or white to black) during a tour.\n\n# [phrase showing quantity relationship]\n    \'more than k times\': means that the number of train type switches must be less than or equal to k.\n    Implementation: Ensure the number of switches does not exceed k during path exploration.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps "Use Depth-First Search (DFS) to explore the tree starting from each node" and "Calculate all possible paths and their happiness sums while keeping track of the number of train type switches" should be implemented simultaneously. This can be done by integrating the switch count logic within the DFS traversal.\n\n# [edge case]\n    Case 1: n = 2, k = 0, happiness values = [1, 1], edges = [(1, 2, 0)]\n    Expected output: 2\n    Explanation: With only one edge and no tickets, the only valid tour is from attraction 1 to 2.\n\n    Case 2: n = 3, k = 1, happiness values = [1, 2, 3], edges = [(1, 2, 0), (2, 3, 1)]\n    Expected output: 6\n    Explanation: You can switch train types once, allowing tours (1,2), (2,3), and (1,3).\n\n    Case 3: n = 4, k = 0, happiness values = [5, 5, 5, 5], edges = [(1, 2, 0), (2, 3, 0), (3, 4, 0)]\n    Expected output: 20\n    Explanation: All rails are black; no switches are needed. All tours are valid.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        def dfs(node, parent, current_color, switches):\n            if switches > k:\n                return\n            # Calculate happiness sum for current path\n            # Memoize results to avoid redundant calculations\n            # Explore child nodes with DFS\n        # Initialize DFS from each node and sum valid paths\' happiness values modulo 10^9 + 7', "- name: \nCentroid Decomposition for Efficient Path Calculation\n\n- content: \n- Use centroid decomposition on the tree to break it down into smaller, manageable components.\n- For each component, use a DFS or BFS to compute paths starting from the centroid and consider both colors separately.\n- Track the number of switches needed and calculate happiness sums accordingly for paths within the component.\n- Use a combination of prefix sums and hashing to efficiently compute happiness values for valid paths that do not exceed k switches.\n- Aggregate results from all components and return the total happiness sum modulo 10^9 + 7.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected graph with no cycles, meaning there is exactly one path between any two vertices.\n\n    'happiness value'\n    Explanation: Each attraction has a happiness value associated with it, which contributes to the total happiness of a tour.\n\n    'rail color'\n    Explanation: Rails can be either black or white, and the color determines which type of train can operate on them.\n\n    'ticket'\n    Explanation: Tickets are used to switch between train types when traversing rails of different colors.\n\n# [phrase showing quantity relationship]\n    'n - 1 rails': Indicates that the number of edges in the tree is one less than the number of vertices.\n    \n    '1 ticket': Indicates that switching between train types requires one ticket.\n    \n    'at most k times': Indicates the maximum number of train type switches allowed.\n\n# [degree adverb]\n    'valid tours': Refers to tours that do not exceed the allowed number of train type switches (k).\n\n# [code logic]\n    The steps involving centroid decomposition and path calculation should be considered simultaneously. The decomposition helps break down the problem into smaller components, and path calculations within these components can be done using DFS/BFS while considering rail colors and ticket constraints.\n\n# [edge case]\n    Edge Case 1: n = 2, k = 0, happiness values = [1, 2], edges = [(1, 2, 0)]\n    Expected Output: 3\n    Explanation: With only one rail and no tickets, the only valid tour is from attraction 1 to 2, summing their happiness values.\n\n    Edge Case 2: n = 3, k = 1, happiness values = [1, 1, 1], edges = [(1, 2, 1), (3, 2, 0)]\n    Expected Output: 10\n    Explanation: The valid tours are (1,2), (2,3), and (1,3) with one switch allowed. The sum of happiness values for all valid tours is 10.\n\n    Edge Case 3: n = 4, k = 0, happiness values = [5, 5, 5, 5], edges = [(1, 2, 0), (2, 3, 0), (3, 4, 0)]\n    Expected Output: 40\n    Explanation: All rails are of the same color and no switches are needed. The sum of happiness values for all possible tours is calculated.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        # Implement centroid decomposition\n        def centroid_decomposition(tree):\n            # Code for decomposing the tree into manageable components\n\n        # Calculate happiness values for valid paths\n        def calculate_happiness(tree, k):\n            # Code for calculating happiness values using DFS/BFS and considering ticket constraints\n\n        # Aggregate results\n        def aggregate_results(components):\n            # Code for aggregating results from all components\n\n        # Main function\n        def main():\n            tree = build_tree()\n            components = centroid_decomposition(tree)\n            result = aggregate_results(components)\n            return result % (10**9 + 7)", "- name: \nDFS with Memoization\n\n- content: \nUse Depth-First Search (DFS) with memoization to efficiently find all valid paths and their happiness sums.\n1. Perform a DFS starting at each attraction u to explore all paths to other attractions v.\n2. As we explore each path, track the current happiness sum and the number of train color switches required.\n3. Use memoization to store results of previously calculated paths to avoid redundant calculations.\n4. If a path is valid (switches <= k), add its happiness sum to a running total.\n5. Ensure all attractions are covered as starting points in separate DFS calls.\n6. Return the total happiness sum modulo 10^9 + 7.\nThis solution efficiently handles larger inputs by leveraging memoization to minimize redundant path calculations.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected graph with no cycles, meaning there is exactly one path between any two vertices.\n\n    'simple path'\n    Explanation: A simple path is a path that does not visit any vertex more than once.\n\n    'tickets'\n    Explanation: Tickets are used to switch train colors. You can switch at most k times.\n\n    'happiness value'\n    Explanation: Each attraction has a happiness value, and the goal is to maximize the sum of these values for valid tours.\n\n# [phrase showing quantity relationship]\n    'n - 1 rails'\n    Explanation: The number of edges in a tree with n vertices is always n - 1.\n\n    'at most k times'\n    Explanation: You can switch train colors up to k times, but not more.\n\n# [degree adverb]\n    'all valid tours'\n    Explanation: The requirement is to consider every possible valid tour that meets the ticket constraint.\n\n# [code logic]\n    Steps 1-4 in the plan should be implemented simultaneously within the DFS function. As you perform DFS, you should track the current path's happiness sum and the number of color switches, using memoization to store results of previously calculated paths.\n\n# [edge case]\n    Edge Case 1: n = 2, k = 0, happiness values = [1, 2], edges = [(1, 2, 0)]\n    Expected Output: 3\n    Explanation: With only one edge and no tickets, the only valid tour is from attraction 1 to 2.\n\n    Edge Case 2: n = 3, k = 1, happiness values = [1, 1, 1], edges = [(1, 2, 0), (2, 3, 1)]\n    Expected Output: 6\n    Explanation: You can switch once, allowing tours (1,2), (2,3), and (1,3).\n\n    Edge Case 3: n = 4, k = 0, happiness values = [5, 5, 5, 5], edges = [(1, 2, 0), (2, 3, 0), (3, 4, 0)]\n    Expected Output: 50\n    Explanation: All paths are on the same color rail; no switches needed.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        - Implement a check for paths that do not require any switches when k = 0.\n        - Ensure memoization accounts for paths with zero switches.\n        - Handle cases where all rails are of the same color efficiently.", '- name: \nBFS with Path Color Tracking\n\n- content: \n- Implement Breadth First Search (BFS) starting from each node to explore all possible paths.\n- Track the color of the current path and count how many times color switches occur.\n- For each node pair (u, v), use BFS to check if a valid path exists based on ticket constraints.\n- Maintain a running sum of happiness values for all valid paths identified during BFS traversal.\n- Return the accumulated sum modulo 10^9 + 7 after processing all node pairs.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected graph with no cycles, meaning there is exactly one path between any two vertices.\n\n    \'simple path\'\n    Explanation: A simple path is a path that does not visit any vertex more than once.\n\n    \'tickets\'\n    Explanation: Tickets are used to switch train colors. You can switch at most k times, and you don\'t need a ticket for the first train or for paths of a single color.\n\n# [phrase showing quantity relationship]\n    \'n - 1 rails\'\n    Explanation: The number of edges in a tree with n vertices is always n - 1.\n\n    \'at most k times\'\n    Explanation: You can switch train colors up to k times, but not more.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps "Track the color of the current path and count how many times color switches occur" and "For each node pair (u, v), use BFS to check if a valid path exists based on ticket constraints" should be implemented simultaneously. This can be done by modifying the BFS to track the current path color and count switches as it explores paths.\n\n# [edge case]\n    Case 1: n = 2, k = 0, happiness values = [1, 2], edges = [(1, 2, 0)]\n    Expected output: 3\n    Explanation: There is only one path (1, 2) with no color switch needed.\n\n    Case 2: n = 3, k = 1, happiness values = [1, 2, 3], edges = [(1, 2, 0), (2, 3, 1)]\n    Expected output: 6\n    Explanation: Paths (1, 2) and (2, 3) are valid with no switch needed. Path (1, 3) requires one switch and is valid.\n\n    Case 3: n = 4, k = 0, happiness values = [1, 1, 1, 1], edges = [(1, 2, 0), (2, 3, 0), (3, 4, 0)]\n    Expected output: 10\n    Explanation: All paths are of the same color and require no switches.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where k = 0 or all paths are of the same color.\n    \n```python\ndef calculate_happiness(n, k, happiness_values, edges):\n    MOD = 10**9 + 7\n    # Implement BFS with color tracking\n    # Initialize data structures for BFS\n    # Track color switches and validate paths based on k\n    # Accumulate happiness values for valid paths\n    # Return result modulo MOD\n```\n', "- name: \nHeavy-Light Decomposition\n\n- content: \n- Decompose the tree using Heavy-Light Decomposition (HLD) to manage path queries efficiently.\n- Perform an initial DFS to classify edges into heavy and light categories based on subtree sizes.\n- After decomposition, use segment trees or Fenwick trees to keep track of happiness values along heavy paths.\n- For each query path, break it down into heavy-light segments and compute happiness values accordingly, considering ticket constraints.\n- Implement additional logic to handle rail color changes efficiently during path computation across different segments.\n- Sum the total happiness for all valid paths adhering to ticket constraints and return it modulo 10^9 + 7.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected graph with no cycles, meaning there is exactly one path between any two vertices.\n\n    'simple path'\n    Explanation: A simple path is a path that does not visit any vertex more than once.\n\n    'tickets'\n    Explanation: Tickets are used to switch train colors. You can switch train types at most k times.\n\n# [phrase showing quantity relationship]\n    'n - 1': Indicates the number of rails, which is always one less than the number of attractions in a tree.\n    Implementation: This is inherent in the tree structure and doesn't require explicit coding.\n\n    'at most k times': Refers to the maximum number of times you can switch train colors.\n    Implementation: Use a counter to track the number of switches and ensure it does not exceed k.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps involving decomposition and path queries should be considered simultaneously:\n    - Decompose the tree using Heavy-Light Decomposition (HLD).\n    - Use segment trees or Fenwick trees to manage happiness values along heavy paths.\n    These steps are interdependent and should be implemented in conjunction to efficiently handle path queries.\n\n# [edge case]\n    Input: 2 0\n           1 1\n           1 2 0\n    Output: 2\n    Explanation: With only one rail and no tickets, the only valid path is from attraction 1 to 2, summing their happiness values.\n\n    Input: 3 0\n           5 5 5\n           1 2 0\n           2 3 0\n    Output: 15\n    Explanation: All attractions are connected by black rails, and no tickets are needed. The sum of all happiness values is valid.\n\n    Input: 4 1\n           1 2 3 4\n           1 2 0\n           2 3 1\n           3 4 0\n    Output: 10\n    Explanation: You can switch train colors once, allowing you to traverse from attraction 1 to attraction 4.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        if k == 0:\n            # Handle paths with no color switches allowed\n            # Traverse only paths with uniform rail color\n        else:\n            # Implement logic to track and limit color switches using tickets\n            # Ensure paths adhere to ticket constraints", '- name: \nPreprocessing with Path Decomposition\n\n- content: \nThis approach involves preprocessing the tree to decompose it into paths of uniform rail colors, which can then be quickly queried for potential tours.\nSteps:\n1. Decompose the tree into maximal sub-paths where all rails have the same color.\n2. Calculate happiness sums for these sub-paths during preprocessing.\n3. For each pair of attractions, determine if a valid path exists using a sequence of these sub-paths with up to `k` switches.\n4. Use precomputed happiness values to quickly assess potential valid paths and sum them up.\n5. Iterate over all attraction pairs, considering both direct paths and paths composed of multiple uniform color segments.\n6. Return the total sum of happiness values modulo 10^9 + 7.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\': A connected graph with no cycles, representing the park\'s attractions and rails.\n    \'happiness value\': The integer value associated with each attraction, contributing to the tour\'s total happiness.\n    \'rail color\': Indicates the type of train that can operate on the rail, either black or white.\n    \'ticket\': Allows switching between train types, with a limited number available.\n\n# [phrase showing quantity relationship]\n    \'n - 1 rails\': Indicates the number of edges in the tree, which is always one less than the number of vertices (attractions).\n    \'at most k times\': Specifies the maximum number of train type switches allowed during a tour.\n    Implementation: Use a counter to track switches and ensure it does not exceed k.\n\n# [degree adverb]\n    \'valid tours\': Tours that do not exceed the allowed number of train type switches (k).\n    Implementation: Check each path to ensure it meets the switch constraint before calculating happiness.\n\n# [code logic]\n    Steps 1 and 2 should be implemented simultaneously as part of preprocessing to efficiently calculate happiness sums for uniform color sub-paths.\n    "Decompose the tree into maximal sub-paths where all rails have the same color",\n    "Calculate happiness sums for these sub-paths during preprocessing"\n    This can be done by traversing the tree and grouping consecutive edges of the same color, then summing their happiness values.\n\n# [edge case]\n    Edge case 1: n = 2, k = 0, a = [1, 1], edges = [(1, 2, 0)]\n    Expected output: 2\n    Explanation: Only one path exists with no switches needed, so the total happiness is simply the sum of both attractions.\n\n    Edge case 2: n = 3, k = 1, a = [1, 2, 3], edges = [(1, 2, 0), (2, 3, 1)]\n    Expected output: 6\n    Explanation: The path from attraction 1 to 3 requires one switch, which is allowed. The total happiness is the sum of all attractions.\n\n    Edge case 3: n = 4, k = 0, a = [5, 5, 5, 5], edges = [(1, 2, 0), (2, 3, 0), (3, 4, 0)]\n    Expected output: 35\n    Explanation: All rails are of the same color, so no switches are needed. The total happiness is the sum of all possible paths.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        def calculate_happiness(n, k, happiness_values, edges):\n            # Preprocess tree into uniform color paths\n            # Calculate happiness sums for these paths\n            # Check paths for valid tours with up to k switches\n            # Sum valid paths\' happiness values modulo 10^9 + 7\n            pass']
----------
False
----------
0
multi-gen-prompt:
'Twas the night before Christmas, and Santa's frantically setting up his new Christmas tree! There are n nodes in the tree, connected by n-1 edges. On each edge of the tree, there's a set of Christmas lights. The lights can be represented by an integer in binary representation.

<image>

He has m elves come over and admire his tree. Each elf is assigned two nodes, a and b, and that elf looks at all lights on the simple path between the two nodes. After this, the elf's favorite number becomes the [bitwise XOR](https://en.wikipedia.org/wiki/Bitwise_operation#XOR) of the values of the lights on the edges in that path.

However, the North Pole has been recovering from a nasty bout of flu. Because of this, Santa forgot some of the configurations of lights he had put on the tree, and he has already left the North Pole! Fortunately, the elves came to the rescue, and each one told Santa what pair of nodes he was assigned (a_i, b_i), as well as the parity of the number of set bits in his favorite number. In other words, he remembers whether the number of 1's when his favorite number is written in binary is odd or even.

Help Santa determine if it's possible that the memories are consistent. If it is possible, remember what his tree looked like, and maybe you'll go down in history!

Input

The first line contains one integer t (1 ≤ t ≤ 2 ⋅ 10^4) — the number of test cases. Then t cases follow.

The first line of each test case contains two integers, n and m (2 ≤ n ≤ 2 ⋅ 10^5; 1 ≤ m ≤ 2 ⋅ 10^5) — the size of tree and the number of elves respectively.

The next n-1 lines of each test case each contains three integers, x, y, and v (1 ≤ x, y ≤ n; -1 ≤ v < 2^{30}) — meaning that there's an edge between nodes x and y. If 

  * v = -1: Santa doesn't remember what the set of lights were on for this edge. 
  * v ≥ 0: The set of lights on the edge is v. 



The next m lines of each test case each contains three integers, a, b, and p (1 ≤ a, b ≤ n; a ≠ b; 0 ≤ p ≤ 1) — the nodes that the elf was assigned to, and the parity of the number of set bits in the elf's favorite number.

It is guaranteed that the sum of all n and the sum of all m don't exceed 2 ⋅ 10^5 each.

It is guaranteed that the given edges form a tree.

Output

For each test case, first print either YES or NO (in any case), whether there's a tree consistent with Santa's memory or not. 

If the answer is YES, print n-1 lines each containing three integers: x, y, and v (1 ≤ x, y ≤ n; 0 ≤ v < 2^{30}) — the edge and the integer on that edge. The set of edges must be the same as in the input, and if the value of some edge was specified earlier, it can not change. You can print the edges in any order.

If there are multiple answers, print any.

Example

Input


4
6 5
1 2 -1
1 3 1
4 2 7
6 3 0
2 5 -1
2 3 1
2 5 0
5 6 1
6 1 1
4 5 1
5 3
1 2 -1
1 3 -1
1 4 1
4 5 -1
2 4 0
3 4 1
2 3 1
3 3
1 2 -1
1 3 -1
1 2 0
1 3 1
2 3 0
2 1
1 2 1
1 2 0


Output


YES
1 2 0
1 3 1
2 4 7
3 6 0
2 5 0
YES
1 2 1
1 3 0
1 4 1
4 5 1
NO
NO

Note

The first test case is the image in the statement.

One possible answer is assigning the value of the edge (1, 2) to 5, and the value of the edge (2, 5) to 3. This is correct because: 

  * The first elf goes from node 2 to node 3. This elf's favorite number is 4, so he remembers the value 1 (as 4 has an odd number of 1 bits in its binary representation). 
  * The second elf goes from node 2 to node 5. This elf's favorite number is 3, so he remembers the value 0 (as 3 has an even number of 1 bits in its binary representation). 
  * The third elf goes from node 5 to node 6. This elf's favorite number is 7, so he remembers the value 1 (as 7 has an odd number of 1 bits in its binary representation). 
  * The fourth elf goes from node 6 to node 1. This elf's favorite number is 1, so he remembers the value 1 (as 1 has an odd number of 1 bits in its binary representation). 
  * The fifth elf goes from node 4 to node 5. This elf's favorite number is 4, so he remembers the number 1 (as 4 has an odd number of 1 bits in its binary representation). 



Note that there are other possible answers.
multi-gen-prompt:
'Twas the night before Christmas, and Santa's frantically setting up his new Christmas tree! There are n nodes in the tree, connected by n-1 edges, and on each edge of the tree, there's a set of Christmas lights, which can be represented by an integer in binary representation.

<image>

He has m elves come over and admire his tree. Each elf is assigned two nodes, a and b, and that elf looks at all lights on the simple path between the two nodes. After this, the elf's favorite number becomes the [bitwise XOR](https://en.wikipedia.org/wiki/Bitwise_operation#XOR) of the values of the lights on the edges in that path.

However, the North Pole has been recovering from a nasty bout of flu, and because of this, Santa forgot some of the configurations of lights he had put on the tree, and he has already left the North Pole! Fortunately, the elves came to the rescue, and each one told Santa what pair of nodes he was assigned (a_i, b_i), as well as the parity of the number of set bits in his favorite number. In other words, he remembers whether the number of 1's when his favorite number is written in binary is odd or even.

Help Santa determine if it's possible that the memories are consistent, and if it is, remember what his tree looked like, and maybe you'll go down in history!

Input

The first line contains one integer t (1 ≤ t ≤ 2 ⋅ 10^4) — the number of test cases. Then t cases follow.

The first line of each test case contains two integers, n and m (2 ≤ n ≤ 2 ⋅ 10^5; 1 ≤ m ≤ 2 ⋅ 10^5) — the size of tree and the number of elves respectively.

The next n-1 lines of each test case each contains three integers, x, y, and v (1 ≤ x, y ≤ n; -1 ≤ v < 2^{30}) — meaning that there's an edge between nodes x and y. If 

  * v = -1: Santa doesn't remember what the set of lights were on for this edge. 
  * v ≥ 0: The set of lights on the edge is v. 



The next m lines of each test case each contains three integers, a, b, and p (1 ≤ a, b ≤ n; a ≠ b; 0 ≤ p ≤ 1) — the nodes that the elf was assigned to, and the parity of the number of set bits in the elf's favorite number.

It is guaranteed that the sum of all n and the sum of all m don't exceed 2 ⋅ 10^5 each.

It is guaranteed that the given edges form a tree.

Output

For each test case, first print either YES or NO (in any case), whether there's a tree consistent with Santa's memory or not. 

If the answer is YES, print n-1 lines each containing three integers: x, y, and v (1 ≤ x, y ≤ n; 0 ≤ v < 2^{30}) — the edge and the integer on that edge. The set of edges must be the same as in the input, and if the value of some edge was specified earlier, it can not change. You can print the edges in any order.

If there are multiple answers, print any.

Example

Input


4
6 5
1 2 -1
1 3 1
4 2 7
6 3 0
2 5 -1
2 3 1
2 5 0
5 6 1
6 1 1
4 5 1
5 3
1 2 -1
1 3 -1
1 4 1
4 5 -1
2 4 0
3 4 1
2 3 1
3 3
1 2 -1
1 3 -1
1 2 0
1 3 1
2 3 0
2 1
1 2 1
1 2 0


Output


YES
1 2 0
1 3 1
2 4 7
3 6 0
2 5 0
YES
1 2 1
1 3 0
1 4 1
4 5 1
NO
NO

Note

The first test case is the image in the statement.

One possible answer is assigning the value of the edge (1, 2) to 5, and the value of the edge (2, 5) to 3. This is correct because: 

  * The first elf goes from node 2 to node 3. This elf's favorite number is 4, so he remembers the value 1 (as 4 has an odd number of 1 bits in its binary representation). 
  * The second elf goes from node 2 to node 5. This elf's favorite number is 3, so he remembers the value 0 (as 3 has an even number of 1 bits in its binary representation). 
  * The third elf goes from node 5 to node 6. This elf's favorite number is 7, so he remembers the value 1 (as 7 has an odd number of 1 bits in its binary representation). 
  * The fourth elf goes from node 6 to node 1. This elf's favorite number is 1, so he remembers the value 1 (as 1 has an odd number of 1 bits in its binary representation). 
  * The fifth elf goes from node 4 to node 5. This elf's favorite number is 4, so he remembers the number 1 (as 4 has an odd number of 1 bits in its binary representation). 



Note that there are other possible answers.
generating with gpt-4o
----------
['def find(parent, parity, x):\n    if parent[x] != x:\n        orig_parent = parent[x]\n        parent[x] = find(parent, parity, parent[x])\n        parity[x] ^= parity[orig_parent]\n    return parent[x]\n\ndef union(parent, parity, x, y, value):\n    root_x = find(parent, parity, x)\n    root_y = find(parent, parity, y)\n    \n    if root_x != root_y:\n        parent[root_x] = root_y\n        parity[root_x] = parity[x] ^ parity[y] ^ value\n\ndef process_constraints(n, m, edges, constraints):\n    parent = list(range(n + 1))\n    parity = [0] * (n + 1)\n    \n    for x, y, v in edges:\n        if v != -1:\n            union(parent, parity, x, y, bin(v).count(\'1\') % 2)\n    \n    for a, b, p in constraints:\n        if find(parent, parity, a) == find(parent, parity, b):\n            if (parity[a] ^ parity[b]) != p:\n                return "NO", []\n        else:\n            union(parent, parity, a, b, p)\n    \n    result_edges = []\n    for x, y, v in edges:\n        if v == -1:\n            root_x = find(parent, parity, x)\n            root_y = find(parent, parity, y)\n            v = parity[x] ^ parity[y]\n        result_edges.append((x, y, v))\n    \n    return "YES", result_edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index])\n            y = int(data[index + 1])\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        constraints = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            p = int(data[index + 2])\n            constraints.append((a, b, p))\n            index += 3\n        \n        result_status, result_edges = process_constraints(n, m, edges, constraints)\n        results.append((result_status, result_edges))\n    \n    for status, edges in results:\n        print(status)\n        if status == "YES":\n            for x, y, v in edges:\n                print(x, y, v)', 'def find(parent, xor_value, x):\n    if parent[x] != x:\n        orig_parent = parent[x]\n        parent[x] = find(parent, xor_value, parent[x])\n        xor_value[x] ^= xor_value[orig_parent]\n    return parent[x]\n\ndef union(parent, rank, xor_value, x, y, value):\n    root_x = find(parent, xor_value, x)\n    root_y = find(parent, xor_value, y)\n    if root_x != root_y:\n        if rank[root_x] > rank[root_y]:\n            parent[root_y] = root_x\n            xor_value[root_y] = xor_value[x] ^ xor_value[y] ^ value\n        elif rank[root_x] < rank[root_y]:\n            parent[root_x] = root_y\n            xor_value[root_x] = xor_value[x] ^ xor_value[y] ^ value\n        else:\n            parent[root_y] = root_x\n            xor_value[root_y] = xor_value[x] ^ xor_value[y] ^ value\n            rank[root_x] += 1\n\ndef solve_tree_problem(test_cases):\n    results = []\n    for n, m, edges, elf_constraints in test_cases:\n        # Initialize Union-Find structure\n        parent = list(range(n + 1))\n        rank = [0] * (n + 1)\n        xor_value = [0] * (n + 1)\n\n        # Process known edges\n        for x, y, v in edges:\n            if v != -1:\n                union(parent, rank, xor_value, x, y, v)\n\n        # Check elf constraints\n        consistent = True\n        for a, b, p in elf_constraints:\n            if find(parent, xor_value, a) == find(parent, xor_value, b):\n                if (xor_value[a] ^ xor_value[b]) % 2 != p:\n                    consistent = False\n                    break\n            else:\n                union(parent, rank, xor_value, a, b, p)\n\n        # Collect result\n        if consistent:\n            result = ["YES"]\n            # Assign values to unknown edges\n            for x, y, v in edges:\n                if v == -1:\n                    find(parent, xor_value, x)\n                    find(parent, xor_value, y)\n                    result.append(f"{x} {y} {xor_value[x] ^ xor_value[y]}")\n                else:\n                    result.append(f"{x} {y} {v}")\n            results.append("\\n".join(result))\n        else:\n            results.append("NO")\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index])\n            y = int(data[index + 1])\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        elf_constraints = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            p = int(data[index + 2])\n            elf_constraints.append((a, b, p))\n            index += 3\n        \n        test_cases.append((n, m, edges, elf_constraints))\n    \n    results = solve_tree_problem(test_cases)\n    \n    for result in results:\n        print(result)', 'def find(parent, x):\n    if parent[x] != x:\n        parent[x] = find(parent, parent[x])\n    return parent[x]\n\ndef union(parent, rank, x, y):\n    rootX = find(parent, x)\n    rootY = find(parent, y)\n    if rootX != rootY:\n        if rank[rootX] > rank[rootY]:\n            parent[rootY] = rootX\n        elif rank[rootX] < rank[rootY]:\n            parent[rootX] = rootY\n        else:\n            parent[rootY] = rootX\n            rank[rootX] += 1\n\ndef solve_tree_problem(test_cases):\n    results = []\n    \n    for n, m, edges, queries in test_cases:\n        # Initialize union-find structures\n        parent = list(range(n + 1))\n        rank = [0] * (n + 1)\n        xor_from_root = [-1] * (n + 1)\n        xor_from_root[1] = 0\n        \n        # Process known edges and set up initial XOR values\n        for x, y, v in edges:\n            if v != -1:\n                union(parent, rank, x, y)\n                if xor_from_root[x] == -1 and xor_from_root[y] != -1:\n                    xor_from_root[x] = xor_from_root[y] ^ v\n                elif xor_from_root[y] == -1 and xor_from_root[x] != -1:\n                    xor_from_root[y] = xor_from_root[x] ^ v\n        \n        # Process queries to check consistency and resolve unknowns\n        consistent = True\n        constraints = []\n        \n        for a, b, p in queries:\n            if find(parent, a) == find(parent, b):\n                path_xor = xor_from_root[a] ^ xor_from_root[b]\n                if (bin(path_xor).count(\'1\') % 2) != p:\n                    consistent = False\n                    break\n            else:\n                constraints.append((a, b, p))\n        \n        if not consistent:\n            results.append("NO")\n            continue\n        \n        # Resolve constraints using union-find\n        for a, b, p in constraints:\n            if find(parent, a) != find(parent, b):\n                union(parent, rank, a, b)\n                if xor_from_root[a] == -1 and xor_from_root[b] != -1:\n                    xor_from_root[a] = xor_from_root[b] ^ p\n                elif xor_from_root[b] == -1 and xor_from_root[a] != -1:\n                    xor_from_root[b] = xor_from_root[a] ^ p\n        \n        # Assign values to unknown edges\n        edge_values = {}\n        for x, y, v in edges:\n            if v == -1:\n                edge_values[(min(x, y), max(x, y))] = xor_from_root[x] ^ xor_from_root[y]\n            else:\n                edge_values[(min(x, y), max(x, y))] = v\n        \n        # Check final consistency\n        consistent = True\n        for a, b, p in queries:\n            path_xor = xor_from_root[a] ^ xor_from_root[b]\n            if (bin(path_xor).count(\'1\') % 2) != p:\n                consistent = False\n                break\n        \n        if consistent:\n            results.append("YES")\n            result_edges = []\n            for x, y, _ in edges:\n                result_edges.append((x, y, edge_values[(min(x, y), max(x, y))]))\n            results.append(result_edges)\n        else:\n            results.append("NO")\n    \n    return results\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    test_cases = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index])\n            y = int(data[index + 1])\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        queries = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            p = int(data[index + 2])\n            queries.append((a, b, p))\n            index += 3\n        \n        test_cases.append((n, m, edges, queries))\n    \n    results = solve_tree_problem(test_cases)\n    \n    i = 0\n    while i < len(results):\n        result = results[i]\n        if result == "NO":\n            print("NO")\n            i += 1\n        else:\n            print("YES")\n            i += 1\n            result_edges = results[i]\n            for edge in result_edges:\n                x, y, v = edge\n                print(x, y, v)\n            i += 1', 'class UnionFind:\n    def __init__(self, n):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n        self.xor_to_parent = [0] * n\n\n    def find(self, x):\n        if self.parent[x] != x:\n            orig_parent = self.parent[x]\n            self.parent[x] = self.find(self.parent[x])\n            self.xor_to_parent[x] ^= self.xor_to_parent[orig_parent]\n        return self.parent[x]\n\n    def union(self, x, y, xor_value):\n        root_x = self.find(x)\n        root_y = self.find(y)\n        \n        if root_x == root_y:\n            return\n\n        if self.rank[root_x] < self.rank[root_y]:\n            self.parent[root_x] = root_y\n            self.xor_to_parent[root_x] = xor_value ^ self.xor_to_parent[x] ^ self.xor_to_parent[y]\n        elif self.rank[root_x] > self.rank[root_y]:\n            self.parent[root_y] = root_x\n            self.xor_to_parent[root_y] = xor_value ^ self.xor_to_parent[x] ^ self.xor_to_parent[y]\n        else:\n            self.parent[root_y] = root_x\n            self.xor_to_parent[root_y] = xor_value ^ self.xor_to_parent[x] ^ self.xor_to_parent[y]\n            self.rank[root_x] += 1\n\ndef solve_tree_queries(n, m, edges, queries):\n    uf = UnionFind(n + 1)\n    \n    # Process known edges\n    for x, y, v in edges:\n        if v != -1:\n            uf.union(x, y, v)\n    \n    # Check queries for consistency\n    for a, b, p in queries:\n        if uf.find(a) == uf.find(b):\n            if (uf.xor_to_parent[a] ^ uf.xor_to_parent[b]) % 2 != p:\n                return "NO", None\n        else:\n            # Union the nodes with the parity constraint\n            uf.union(a, b, p)\n    \n    # Determine values for unknown edges\n    result_edges = []\n    for x, y, v in edges:\n        if v == -1:\n            v = uf.xor_to_parent[x] ^ uf.xor_to_parent[y]\n        result_edges.append((x, y, v))\n    \n    return "YES", result_edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index])\n            y = int(data[index + 1])\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        queries = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            p = int(data[index + 2])\n            queries.append((a, b, p))\n            index += 3\n        \n        result, result_edges = solve_tree_queries(n, m, edges, queries)\n        results.append(result)\n        if result == "YES":\n            results.extend(["{} {} {}".format(x, y, v) for x, y, v in result_edges])\n    \n    print("\\n".join(results))', 'class UnionFind:\n    def __init__(self, n):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n        self.parity = [0] * n\n\n    def find(self, x):\n        if self.parent[x] != x:\n            orig_parent = self.parent[x]\n            self.parent[x] = self.find(self.parent[x])\n            self.parity[x] ^= self.parity[orig_parent]\n        return self.parent[x]\n\n    def union(self, x, y, parity):\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            if self.rank[root_x] > self.rank[root_y]:\n                self.parent[root_y] = root_x\n                self.parity[root_y] = self.parity[x] ^ self.parity[y] ^ parity\n            elif self.rank[root_x] < self.rank[root_y]:\n                self.parent[root_x] = root_y\n                self.parity[root_x] = self.parity[x] ^ self.parity[y] ^ parity\n            else:\n                self.parent[root_y] = root_x\n                self.parity[root_y] = self.parity[x] ^ self.parity[y] ^ parity\n                self.rank[root_x] += 1\n\ndef solve():\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index]) - 1\n            y = int(data[index + 1]) - 1\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        queries = []\n        for _ in range(m):\n            a = int(data[index]) - 1\n            b = int(data[index + 1]) - 1\n            p = int(data[index + 2])\n            queries.append((a, b, p))\n            index += 3\n        \n        uf = UnionFind(n)\n        \n        # Process known edges\n        for x, y, v in edges:\n            if v != -1:\n                uf.union(x, y, bin(v).count(\'1\') % 2)\n        \n        # Check queries\n        consistent = True\n        for a, b, p in queries:\n            if uf.find(a) == uf.find(b):\n                if (uf.parity[a] ^ uf.parity[b]) != p:\n                    consistent = False\n                    break\n            else:\n                uf.union(a, b, p)\n        \n        if not consistent:\n            results.append("NO")\n            continue\n        \n        # Assign values to unknown edges\n        for x, y, v in edges:\n            if v == -1:\n                if uf.find(x) != uf.find(y):\n                    uf.union(x, y, 0)\n        \n        results.append("YES")\n        for x, y, v in edges:\n            if v == -1:\n                v = uf.parity[x] ^ uf.parity[y]\n            results.append(f"{x + 1} {y + 1} {v}")\n    \n    sys.stdout.write("\\n".join(results) + "\\n")\n\nif __name__ == "__main__":\n    solve()', 'def find_parity(x):\n    return bin(x).count(\'1\') % 2\n\ndef dfs(node, parent, graph, values, xor_from_root):\n    for neighbor, edge_value in graph[node]:\n        if neighbor == parent:\n            continue\n        if edge_value != -1:\n            xor_from_root[neighbor] = xor_from_root[node] ^ edge_value\n        dfs(neighbor, node, graph, values, xor_from_root)\n\ndef solve(n, m, edges, queries):\n    graph = [[] for _ in range(n + 1)]\n    values = [-1] * (n + 1)\n    \n    for x, y, v in edges:\n        graph[x].append((y, v))\n        graph[y].append((x, v))\n    \n    xor_from_root = [0] * (n + 1)\n    dfs(1, -1, graph, values, xor_from_root)\n    \n    constraints = []\n    for a, b, p in queries:\n        constraints.append((xor_from_root[a] ^ xor_from_root[b], p))\n    \n    for x, y, v in edges:\n        if v == -1:\n            values[x] = values[y] = -1\n    \n    for x, y, v in edges:\n        if v != -1:\n            values[x] = values[y] = v\n    \n    for a, b, p in constraints:\n        if find_parity(a) != p:\n            return "NO", []\n    \n    result_edges = []\n    for x, y, v in edges:\n        if v == -1:\n            result_edges.append((x, y, 0))\n        else:\n            result_edges.append((x, y, v))\n    \n    return "YES", result_edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index])\n            y = int(data[index + 1])\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        queries = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            p = int(data[index + 2])\n            queries.append((a, b, p))\n            index += 3\n        \n        result = solve(n, m, edges, queries)\n        results.append(result)\n    \n    for result in results:\n        print(result[0])\n        if result[0] == "YES":\n            for edge in result[1]:\n                print(edge[0], edge[1], edge[2])', 'class UnionFind:\n    def __init__(self, n):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n        self.xor_to_parent = [0] * n\n\n    def find(self, x):\n        if self.parent[x] != x:\n            orig_parent = self.parent[x]\n            self.parent[x] = self.find(self.parent[x])\n            self.xor_to_parent[x] ^= self.xor_to_parent[orig_parent]\n        return self.parent[x]\n\n    def union(self, x, y, xor_value):\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            if self.rank[root_x] < self.rank[root_y]:\n                root_x, root_y = root_y, root_x\n            self.parent[root_y] = root_x\n            self.xor_to_parent[root_y] = xor_value ^ self.xor_to_parent[x] ^ self.xor_to_parent[y]\n            if self.rank[root_x] == self.rank[root_y]:\n                self.rank[root_x] += 1\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n\n    def get_xor(self, x, y):\n        if not self.connected(x, y):\n            return None\n        return self.xor_to_parent[x] ^ self.xor_to_parent[y]\n\ndef solve():\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index]) - 1\n            y = int(data[index + 1]) - 1\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        queries = []\n        for _ in range(m):\n            a = int(data[index]) - 1\n            b = int(data[index + 1]) - 1\n            p = int(data[index + 2])\n            queries.append((a, b, p))\n            index += 3\n        \n        uf = UnionFind(n)\n        \n        for x, y, v in edges:\n            if v != -1:\n                uf.union(x, y, v)\n        \n        consistent = True\n        \n        for a, b, p in queries:\n            if uf.connected(a, b):\n                if uf.get_xor(a, b) % 2 != p:\n                    consistent = False\n                    break\n            else:\n                uf.union(a, b, p)\n        \n        if not consistent:\n            results.append("NO")\n            continue\n        \n        results.append("YES")\n        \n        for x, y, v in edges:\n            if v == -1:\n                v = uf.get_xor(x, y)\n                if v is None:\n                    v = 0\n                results.append(f"{x + 1} {y + 1} {v}")\n            else:\n                results.append(f"{x + 1} {y + 1} {v}")\n    \n    sys.stdout.write("\\n".join(results) + "\\n")\n\nif __name__ == "__main__":\n    solve()', 'class DSU:\n    def __init__(self, n):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n        self.xor_to_parent = [0] * n\n\n    def find(self, x):\n        if self.parent[x] != x:\n            orig_parent = self.parent[x]\n            self.parent[x] = self.find(self.parent[x])\n            self.xor_to_parent[x] ^= self.xor_to_parent[orig_parent]\n        return self.parent[x]\n\n    def union(self, x, y, xor_value):\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            if self.rank[root_x] < self.rank[root_y]:\n                self.parent[root_x] = root_y\n                self.xor_to_parent[root_x] = xor_value ^ self.xor_to_parent[x] ^ self.xor_to_parent[y]\n            elif self.rank[root_x] > self.rank[root_y]:\n                self.parent[root_y] = root_x\n                self.xor_to_parent[root_y] = xor_value ^ self.xor_to_parent[x] ^ self.xor_to_parent[y]\n            else:\n                self.parent[root_y] = root_x\n                self.xor_to_parent[root_y] = xor_value ^ self.xor_to_parent[x] ^ self.xor_to_parent[y]\n                self.rank[root_x] += 1\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n\n    def get_xor(self, x, y):\n        if not self.connected(x, y):\n            return None\n        return self.xor_to_parent[x] ^ self.xor_to_parent[y]\n\ndef solve_constraints(n, edges, queries):\n    dsu = DSU(n + 1)\n    \n    for x, y, v in edges:\n        if v != -1:\n            dsu.union(x, y, v)\n    \n    for a, b, p in queries:\n        if dsu.connected(a, b):\n            path_xor = dsu.get_xor(a, b)\n            if path_xor is not None and (bin(path_xor).count(\'1\') % 2) != p:\n                return False\n        else:\n            dsu.union(a, b, p)\n    \n    result_edges = []\n    for x, y, v in edges:\n        if v == -1:\n            v = dsu.get_xor(x, y)\n            if v is None:\n                v = 0\n        result_edges.append((x, y, v))\n    \n    return result_edges\n\ndef main():\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index])\n            y = int(data[index + 1])\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        queries = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            p = int(data[index + 2])\n            queries.append((a, b, p))\n            index += 3\n        \n        result_edges = solve_constraints(n, edges, queries)\n        \n        if result_edges is False:\n            results.append("NO")\n        else:\n            results.append("YES")\n            for x, y, v in result_edges:\n                results.append(f"{x} {y} {v}")\n    \n    print("\\n".join(results))\n\nif __name__ == "__main__":\n    main()', 'class UnionFind:\n    def __init__(self, n):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n        self.xor_to_root = [0] * n\n\n    def find(self, x):\n        if self.parent[x] != x:\n            original_parent = self.parent[x]\n            self.parent[x] = self.find(self.parent[x])\n            self.xor_to_root[x] ^= self.xor_to_root[original_parent]\n        return self.parent[x]\n\n    def union(self, x, y, xor_value):\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            if self.rank[root_x] > self.rank[root_y]:\n                self.parent[root_y] = root_x\n                self.xor_to_root[root_y] = xor_value ^ self.xor_to_root[x] ^ self.xor_to_root[y]\n            elif self.rank[root_x] < self.rank[root_y]:\n                self.parent[root_x] = root_y\n                self.xor_to_root[root_x] = xor_value ^ self.xor_to_root[x] ^ self.xor_to_root[y]\n            else:\n                self.parent[root_y] = root_x\n                self.xor_to_root[root_y] = xor_value ^ self.xor_to_root[x] ^ self.xor_to_root[y]\n                self.rank[root_x] += 1\n\ndef solve_test_case(n, m, edges, queries):\n    uf = UnionFind(n)\n    unknown_edges = []\n\n    for x, y, v in edges:\n        if v != -1:\n            uf.union(x - 1, y - 1, v)\n        else:\n            unknown_edges.append((x - 1, y - 1))\n\n    parity_constraints = []\n    for a, b, p in queries:\n        root_a = uf.find(a - 1)\n        root_b = uf.find(b - 1)\n        if root_a == root_b:\n            if (uf.xor_to_root[a - 1] ^ uf.xor_to_root[b - 1]) % 2 != p:\n                return "NO", []\n        else:\n            parity_constraints.append((a - 1, b - 1, p))\n\n    for x, y, p in parity_constraints:\n        root_x = uf.find(x)\n        root_y = uf.find(y)\n        if root_x == root_y:\n            if (uf.xor_to_root[x] ^ uf.xor_to_root[y]) % 2 != p:\n                return "NO", []\n        else:\n            uf.union(x, y, p)\n\n    result_edges = []\n    for x, y, v in edges:\n        if v == -1:\n            root_x = uf.find(x - 1)\n            root_y = uf.find(y - 1)\n            v = uf.xor_to_root[x - 1] ^ uf.xor_to_root[y - 1]\n        result_edges.append((x, y, v))\n\n    return "YES", result_edges\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index])\n            y = int(data[index + 1])\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        queries = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            p = int(data[index + 2])\n            queries.append((a, b, p))\n            index += 3\n        \n        result, result_edges = solve_test_case(n, m, edges, queries)\n        results.append(result)\n        if result == "YES":\n            results.extend(["{} {} {}".format(x, y, v) for x, y, v in result_edges])\n    \n    sys.stdout.write("\\n".join(results) + "\\n")', 'class UnionFind:\n    def __init__(self, n):\n        self.parent = list(range(n))\n        self.rank = [0] * n\n        self.parity = [0] * n\n\n    def find(self, u):\n        if self.parent[u] != u:\n            original_parent = self.parent[u]\n            self.parent[u] = self.find(self.parent[u])\n            self.parity[u] ^= self.parity[original_parent]\n        return self.parent[u]\n\n    def union(self, u, v, edge_parity):\n        root_u = self.find(u)\n        root_v = self.find(v)\n\n        if root_u == root_v:\n            return (self.parity[u] ^ self.parity[v]) == edge_parity\n\n        if self.rank[root_u] < self.rank[root_v]:\n            root_u, root_v = root_v, root_u\n\n        self.parent[root_v] = root_u\n        self.parity[root_v] = self.parity[u] ^ self.parity[v] ^ edge_parity\n\n        if self.rank[root_u] == self.rank[root_v]:\n            self.rank[root_u] += 1\n\n        return True\n\ndef solve_tree(n, m, edges, elves):\n    uf = UnionFind(n + 1)\n    result_edges = [-1] * (n - 1)\n\n    for i, (x, y, v) in enumerate(edges):\n        if v != -1:\n            if not uf.union(x, y, bin(v).count(\'1\') % 2):\n                return "NO", []\n\n    for a, b, p in elves:\n        if not uf.union(a, b, p):\n            return "NO", []\n\n    for i, (x, y, v) in enumerate(edges):\n        if v == -1:\n            root_x = uf.find(x)\n            root_y = uf.find(y)\n            result_edges[i] = uf.parity[x] ^ uf.parity[y]\n        else:\n            result_edges[i] = v\n\n    result_edges_output = [(edges[i][0], edges[i][1], result_edges[i]) for i in range(n - 1)]\n    return "YES", result_edges_output\n\nif __name__ == "__main__":\n    import sys\n    input = sys.stdin.read\n    data = input().split()\n    \n    index = 0\n    t = int(data[index])\n    index += 1\n    \n    results = []\n    \n    for _ in range(t):\n        n = int(data[index])\n        m = int(data[index + 1])\n        index += 2\n        \n        edges = []\n        for _ in range(n - 1):\n            x = int(data[index])\n            y = int(data[index + 1])\n            v = int(data[index + 2])\n            edges.append((x, y, v))\n            index += 3\n        \n        elves = []\n        for _ in range(m):\n            a = int(data[index])\n            b = int(data[index + 1])\n            p = int(data[index + 2])\n            elves.append((a, b, p))\n            index += 3\n        \n        result, result_edges = solve_tree(n, m, edges, elves)\n        results.append(result)\n        if result == "YES":\n            results.extend(["{} {} {}".format(x, y, v) for x, y, v in result_edges])\n    \n    print("\\n".join(results))']
----------
['- name: \nConstraint Satisfaction with Bipartite Graph\n\n- content: \nModel the problem as a bipartite graph where nodes represent variables (edge values) and constraints (elf queries).\n- Treat each edge with unknown values as a variable and each elf query as a constraint relating these variables.\n- Use BFS or DFS to color the tree with two colors to ensure bipartite property, ensuring parity constraints are consistent within each color group.\n- Assign edge values based on the constraints imposed by queries such that the parity of the XOR matches the given parity for all paths.\n- If a coloring leads to a conflict in parity constraints, output "NO". If not, construct and output a valid configuration consistent with all parity constraints by ensuring path parities are achieved.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'bitwise XOR\'\n    Explanation: Bitwise XOR is a binary operation that takes two bit patterns of equal length and performs the logical exclusive OR operation on each pair of corresponding bits. The result in each position is 1 if the two bits are different, and 0 if they are the same.\n\n    \'parity\'\n    Explanation: Parity refers to whether the number of set bits (1s) in a binary number is odd or even. In this context, it is used to determine the consistency of the elves\' favorite numbers.\n\n# [phrase showing quantity relationship]\n    \'n nodes, n-1 edges\': This indicates that the structure is a tree, as a tree with n nodes always has n-1 edges.\n    \'at least\': This phrase is not directly present in the requirement but is implied in the context of ensuring consistency with parity constraints.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps involving BFS or DFS for coloring the tree and ensuring bipartite property should be implemented simultaneously. This involves traversing the tree and assigning colors to nodes to ensure that parity constraints are consistent within each color group.\n\n# [edge case]\n    Case 1: A tree with only two nodes and one edge with a known value.\n    Input: 2 1\n           1 2 0\n           1 2 0\n    Expected Output: YES\n                     1 2 0\n    Explanation: The only edge has a known value, and the parity matches the elf\'s memory.\n\n    Case 2: A tree with three nodes where all edges have unknown values.\n    Input: 3 2\n           1 2 -1\n           2 3 -1\n           1 3 0\n           2 3 1\n    Expected Output: NO\n    Explanation: The parity constraints are conflicting, making it impossible to assign values to edges that satisfy all elves.\n\n    Case 3: A tree with four nodes where one edge has a known value and others are unknown.\n    Input: 4 3\n           1 2 -1\n           2 3 -1\n           3 4 5\n           1 4 0\n           2 4 1\n           1 3 0\n    Expected Output: YES\n                     (possible values for unknown edges)\n    Explanation: The known value on one edge helps resolve parity constraints, allowing consistent assignment of values to unknown edges.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling edge cases)\n        - Implement BFS or DFS to color the tree and check for bipartite property.\n        - Use parity constraints to assign values to unknown edges.\n        - Check for conflicts in parity constraints during coloring. If conflicts arise, output "NO". If not, construct a valid configuration.', '- name: \nDFS with Parity Check and Union-Find for Consistency\n\n- content: \nTo solve the problem, we can use a combination of DFS to calculate XOR paths and Union-Find to manage connectivity and parity constraints:\n\n1. **Initialization**: \n   - Parse the input and initialize structures to store the tree edges and elf constraints.\n   - Use a Union-Find data structure to manage connectivity between nodes and track parity information.\n\n2. **DFS for Known Values**: \n   - Perform DFS from an arbitrary node to compute XOR values from the root to each node based on known edge values. Store these XOR values for each node.\n\n3. **Union-Find for Parity Consistency**:\n   - For each elf constraint (a, b, p), check the XOR parity of the path between nodes a and b.\n   - If the path includes unknown edges, use Union-Find to determine if setting values can achieve the required parity.\n   - Merge nodes in the Union-Find structure based on required parity conditions.\n\n4. **Solve for Unknown Edges**:\n   - After processing all elf constraints, assign values to unknown edges using the Union-Find structure to ensure consistent parity across paths.\n\n5. **Output**:\n   - If a consistent configuration is found, output "YES" followed by the edge values. If not, output "NO".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected graph with no cycles, consisting of nodes and edges. In this problem, the tree has n nodes and n-1 edges.\n\n    \'bitwise XOR\'\n    Explanation: Bitwise XOR is a binary operation that takes two bits and returns 1 if the bits are different, and 0 if they are the same. It is used here to determine the favorite number of each elf based on the lights on the path between two nodes.\n\n    \'parity\'\n    Explanation: Parity refers to whether a number is odd or even. In this context, it is used to describe the number of set bits (1s) in the binary representation of a number.\n\n# [phrase showing quantity relationship]\n    \'n nodes and n-1 edges\': This indicates that the graph is a tree, as a tree with n nodes always has n-1 edges.\n    \n    \'at least\': This phrase is not explicitly present in the requirement but is implied in ensuring that the parity conditions are met for all paths.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps involving DFS for known values and Union-Find for parity consistency should be considered simultaneously. The DFS helps in calculating XOR values for known paths, while Union-Find ensures that unknown paths can be adjusted to meet parity conditions. These two processes are interdependent as they both contribute to determining the consistency of the tree configuration.\n\n# [edge case]\n    Edge Case 1: A tree with only two nodes and one edge with a known value.\n    Explanation: This is the simplest form of a tree, and if the known value satisfies the elf\'s parity condition, the output should be "YES" with the given edge value.\n\n    Edge Case 2: A tree where all edges have unknown values, but elf constraints can be satisfied by assigning consistent values.\n    Explanation: This tests the ability of the algorithm to assign values to unknown edges while maintaining parity consistency.\n\n    Edge Case 3: A tree where elf constraints contradict each other, making it impossible to satisfy all conditions.\n    Explanation: This tests whether the algorithm correctly identifies when no consistent configuration is possible, resulting in a "NO" output.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where all edges have unknown values or where elf constraints contradict each other. This involves using Union-Find to manage connectivity and parity constraints effectively.\n    \n```python\ndef solve_tree_problem(test_cases):\n    for n, m, edges, elf_constraints in test_cases:\n        # Initialize Union-Find structure\n        parent = list(range(n + 1))\n        rank = [0] * (n + 1)\n        xor_value = [-1] * (n + 1)\n\n        def find(x):\n            if parent[x] != x:\n                orig_parent = parent[x]\n                parent[x] = find(parent[x])\n                xor_value[x] ^= xor_value[orig_parent]\n            return parent[x]\n\n        def union(x, y, value):\n            root_x = find(x)\n            root_y = find(y)\n            if root_x != root_y:\n                if rank[root_x] > rank[root_y]:\n                    parent[root_y] = root_x\n                    xor_value[root_y] = xor_value[x] ^ xor_value[y] ^ value\n                elif rank[root_x] < rank[root_y]:\n                    parent[root_x] = root_y\n                    xor_value[root_x] = xor_value[x] ^ xor_value[y] ^ value\n                else:\n                    parent[root_y] = root_x\n                    xor_value[root_y] = xor_value[x] ^ xor_value[y] ^ value\n                    rank[root_x] += 1\n\n        # Process known edges\n        for x, y, v in edges:\n            if v != -1:\n                union(x, y, v)\n\n        # Check elf constraints\n        consistent = True\n        for a, b, p in elf_constraints:\n            if find(a) == find(b):\n                if (xor_value[a] ^ xor_value[b]) % 2 != p:\n                    consistent = False\n                    break\n            else:\n                union(a, b, p)\n\n        # Output result\n        if consistent:\n            print("YES")\n            # Assign values to unknown edges\n            for x, y, v in edges:\n                if v == -1:\n                    find(x)\n                    find(y)\n                    print(x, y, xor_value[x] ^ xor_value[y])\n                else:\n                    print(x, y, v)\n        else:\n            print("NO")\n```\nThis code uses Union-Find to manage connectivity and parity constraints while processing known and unknown edges. It ensures that all elf constraints are checked for consistency.', "- name: \nGaussian Elimination on XOR Basis\n\n- content: \nApply a Gaussian elimination technique on binary numbers to determine feasible configurations of unknown edges.\nSteps:\n1. Construct a system of linear equations representing parity conditions using XOR operations.\n2. Apply Gaussian elimination in binary form to solve for possible values of unknown edges.\n3. Check consistency of solutions with elf-provided parity constraints.\n4. If a solution exists that satisfies all equations, output YES with edge configurations; otherwise, output NO.\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    'tree'\n    Explanation: A tree is a connected graph with no cycles, consisting of nodes and edges. In this problem, the tree has n nodes and n-1 edges.\n\n    'bitwise XOR'\n    Explanation: XOR is a bitwise operation that takes two bits and returns 1 if the bits are different, and 0 if they are the same. It is used here to determine the favorite number of each elf based on the lights on the path between two nodes.\n\n    'parity'\n    Explanation: Parity refers to whether a number is odd or even. In this context, it refers to the number of 1's in the binary representation of a number.\n\n# [phrase showing quantity relationship]\n    'n nodes and n-1 edges': This indicates that the graph is a tree, as a tree with n nodes always has n-1 edges.\n    \n    'at least as many times': Not applicable in this context.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented in sequence, as each step builds upon the previous one. However, steps 2 and 3 (applying Gaussian elimination and checking consistency) are closely related and could be considered simultaneously in terms of implementation logic.\n\n# [edge case]\n    Edge Case 1: A tree with all known edge values and consistent elf parity constraints.\n    Expected Output: YES with the given edge values.\n    Explanation: If all edge values are known and satisfy the elf constraints, the output should be YES.\n\n    Edge Case 2: A tree with conflicting elf parity constraints.\n    Expected Output: NO\n    Explanation: If any elf's parity constraint cannot be satisfied with any configuration of edge values, the output should be NO.\n\n    Edge Case 3: A tree with all unknown edge values but consistent elf parity constraints.\n    Expected Output: YES with any valid configuration of edge values.\n    Explanation: If all edge values are unknown but can be configured to satisfy all elf constraints, the output should be YES.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where some edges have unknown values (-1). This involves setting up and solving a system of equations using Gaussian elimination to find a consistent configuration of edge values.\n\n```python\ndef solve_tree_configuration(t, test_cases):\n    results = []\n    for case in test_cases:\n        n, m, edges, elves = case\n        # Initialize data structures for Gaussian elimination\n        # Apply Gaussian elimination to find possible configurations\n        # Check consistency with elf constraints\n        # Append result (YES/NO and configurations) to results\n    return results\n```\n\nThis code snippet outlines the need for additional logic to handle unknown edge values using Gaussian elimination.", '- name: \nTree Path Queries using DFS and Parity Propagation\n\n- content: \nThis method employs Depth First Search (DFS) to propagate XOR values across the tree and checks constraints using parity propagation.\n\nSteps:\n1. Represent the tree using an adjacency list from the given edges.\n2. Perform a DFS traversal starting from an arbitrary root node, say node 1, to propagate XOR values from the root to all other nodes.\n   - During DFS, calculate and store the XOR value from the root to each node.\n3. Process each elf\'s query by comparing the stored XOR values for nodes a and b.\n   - Compute the XOR for the path a to b as XOR[a] ^ XOR[b].\n   - Check if the parity of this result matches the provided parity p by the elf.\n   - If any query results in a mismatch, output "NO" as the configuration is inconsistent.\n4. For unknown edges (-1), derive their values by ensuring that all queries maintain their expected parities.\n   - Adjust these unknown values as needed during DFS or when processing queries.\n5. If all queries are consistent, output "YES" and provide one valid configuration of the tree\'s edge values.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected graph with no cycles, consisting of nodes and edges. In this problem, the tree has n nodes and n-1 edges.\n\n    \'bitwise XOR\'\n    Explanation: XOR is a bitwise operation that takes two bits and returns 1 if the bits are different, and 0 if they are the same. It is used here to determine the elf\'s favorite number based on the lights on the path.\n\n    \'parity\'\n    Explanation: Parity refers to whether a number is odd or even. In this context, it is used to describe the number of set bits (1s) in the binary representation of a number.\n\n# [phrase showing quantity relationship]\n    \'n nodes and n-1 edges\': This indicates that the graph is a tree, as a tree with n nodes always has n-1 edges.\n    \n    \'2 ≤ n ≤ 2 ⋅ 10^5; 1 ≤ m ≤ 2 ⋅ 10^5\': These are constraints on the size of the tree and the number of elves, indicating the problem\'s scale.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 2 and 3 should be considered simultaneously:\n    - During DFS traversal, calculate and store the XOR value from the root to each node.\n    - Process each elf\'s query by comparing the stored XOR values for nodes a and b.\n    This can be implemented in a single DFS function that both propagates XOR values and checks query constraints.\n\n# [edge case] \n    Edge Case 1: A tree with only two nodes and one edge with a known value.\n    Input: \n    ```\n    1\n    2 1\n    1 2 3\n    1 2 0\n    ```\n    Expected Output: YES\n    Explanation: The only edge has a known value, and the parity matches the elf\'s memory.\n\n    Edge Case 2: A tree where all edges have unknown values (-1).\n    Input:\n    ```\n    1\n    3 2\n    1 2 -1\n    2 3 -1\n    1 3 0\n    2 3 1\n    ```\n    Expected Output: NO\n    Explanation: It is impossible to assign values to the edges such that both queries have consistent parities.\n\n    Edge Case 3: A tree with conflicting parity requirements.\n    Input:\n    ```\n    1\n    4 2\n    1 2 -1\n    2 3 -1\n    3 4 -1\n    1 4 0\n    2 4 1\n    ```\n    Expected Output: NO\n    Explanation: The parity requirements for paths overlap in a way that makes it impossible to satisfy both.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where all edges have unknown values or conflicting parity requirements.\n    \n```python\ndef handle_edge_cases(n, m, edges, queries):\n    # Initialize data structures for DFS and parity checking\n    adjacency_list = [[] for _ in range(n + 1)]\n    xor_values = [-1] * (n + 1)\n    \n    # Build adjacency list from edges\n    for x, y, v in edges:\n        adjacency_list[x].append((y, v))\n        adjacency_list[y].append((x, v))\n    \n    # DFS function to propagate XOR values\n    def dfs(node, parent, current_xor):\n        xor_values[node] = current_xor\n        for neighbor, value in adjacency_list[node]:\n            if neighbor == parent:\n                continue\n            if value == -1:\n                # Handle unknown edge value during DFS\n                value = determine_value_based_on_queries(node, neighbor)\n            dfs(neighbor, node, current_xor ^ value)\n    \n    # Function to determine edge value based on queries (simplified example)\n    def determine_value_based_on_queries(node_a, node_b):\n        # Logic to determine edge value based on queries\' parity requirements\n        return some_value\n    \n    # Start DFS from node 1 (or any arbitrary node)\n    dfs(1, -1, 0)\n    \n    # Check all queries for consistency\n    for a, b, p in queries:\n        if (xor_values[a] ^ xor_values[b]) % 2 != p:\n            return "NO"\n    \n    return "YES"\n```\nThis code provides a framework for handling edge cases by using DFS to propagate XOR values and checking query consistency.', '- name: \nUnion-Find with Parity Constraints\n\n- content: \nUtilize a Union-Find (Disjoint Set Union) structure combined with parity constraints to solve this problem. The approach involves determining connectivity and parity constraints simultaneously. The steps are:\n1. Initialize a Union-Find structure to manage connectivity among nodes.\n2. Iterate through each edge in the tree:\n   - If the edge has a known value, union the nodes and record the XOR parity information.\n   - If the edge is unknown, defer its processing until later.\n3. For each elf query, use the Union-Find structure to determine if nodes a and b are connected and if their path XOR satisfies the parity constraint.\n4. Attempt to assign values to unknown edges such that all queries are satisfied.\n5. If all constraints can be met, output "YES" and provide one possible configuration; otherwise, output "NO".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'bitwise XOR\'\n    Explanation: This is a binary operation that takes two bit patterns of equal length and performs the logical exclusive OR operation on each pair of corresponding bits. The result in each position is 1 if the two bits are different, and 0 if they are the same.\n\n    \'parity\'\n    Explanation: Parity refers to whether the number of set bits (1s) in a binary number is odd or even. In this context, it is used to determine if the favorite number of an elf has an odd or even number of 1s.\n\n# [phrase showing quantity relationship]\n    \'n nodes and n-1 edges\': This indicates that the structure is a tree, as a tree with n nodes always has n-1 edges.\n    \n    \'at least as many times\': This phrase does not appear in this requirement.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    The steps in the plan should be implemented in sequence, but steps 2 and 3 involve similar operations (checking connectivity and parity), which can be handled together using the Union-Find structure. Specifically, when processing known edges and elf queries, both connectivity and parity constraints should be checked simultaneously.\n\n# [edge case] \n    Edge Case 1: A tree with only two nodes and one edge with a known value.\n    Example: \n    Input: \n    1\n    2 1\n    1 2 0\n    1 2 0\n    Expected Output: YES\n    Explanation: The only edge has a known value that satisfies the elf\'s parity requirement.\n\n    Edge Case 2: A tree where all edges have unknown values, but elf queries can be satisfied with consistent values.\n    Example:\n    Input:\n    1\n    3 2\n    1 2 -1\n    2 3 -1\n    1 3 0\n    2 3 1\n    Expected Output: YES\n    Explanation: Assigning values to unknown edges such that all parity constraints are satisfied is possible.\n\n    Edge Case 3: A tree where known edge values conflict with elf queries.\n    Example:\n    Input:\n    1\n    3 1\n    1 2 0\n    2 3 -1\n    1 3 1\n    Expected Output: NO\n    Explanation: The known edge value conflicts with the elf\'s parity requirement, making it impossible to satisfy all constraints.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where unknown edges need to be assigned values. This involves using the Union-Find structure to manage connectivity and parity constraints, and attempting to assign values to unknown edges in a way that satisfies all elf queries.\n    \n```python\ndef solve():\n    # Initialize Union-Find structure with parity tracking\n    # Process known edges and elf queries\n    # Attempt to assign values to unknown edges\n    # Check if all constraints are satisfied\n```', '- name: \nUse DFS with XOR and Parity Checking\n\n- content: \nThe solution involves using Depth-First Search (DFS) to traverse the tree and calculate the XOR values from the root to all other nodes. This helps in understanding the current state of each node\'s XOR with respect to the root. The parity (even or odd) of the set bits in the XOR values is maintained throughout the traversal.\n\nSteps:\n1. Perform a DFS from an arbitrary root node (typically node 1), calculating the XOR value from the root to each node. Store these XOR values.\n2. For each known edge, apply the given XOR value to update the values.\n3. For each elf query, compute the XOR of the path between nodes a and b using the previously stored XOR values. Check if the parity of the number of set bits in this computed XOR matches the given parity.\n4. For unknown edges, set their values such that all elf constraints are satisfied.\n5. Output "YES" if all constraints can be satisfied; otherwise, output "NO".\n\nThis method ensures that all constraints given by elves are honored while respecting known edge values.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected graph with no cycles, consisting of nodes and edges. In this problem, the tree has n nodes and n-1 edges.\n\n    \'bitwise XOR\'\n    Explanation: XOR is a bitwise operation that takes two bits and returns 1 if the bits are different, and 0 if they are the same. It is used here to determine the favorite number of each elf based on the lights on the path between two nodes.\n\n    \'parity\'\n    Explanation: Parity refers to whether a number is odd or even. In this context, it refers to the number of 1\'s in the binary representation of a number.\n\n# [phrase showing quantity relationship]\n    \'n nodes and n-1 edges\': This indicates that the graph is a tree, as a tree with n nodes always has n-1 edges.\n    \n    \'2 ⋅ 10^4\': This is the upper limit for the number of test cases.\n    \n    \'2 ⋅ 10^5\': This is the upper limit for the size of the tree and the number of elves.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 1 and 2 should be implemented simultaneously:\n    - Perform a DFS from an arbitrary root node to calculate XOR values from the root to each node.\n    - For each known edge, apply the given XOR value to update the values.\n    \n    Steps 3 and 4 should be implemented simultaneously:\n    - For each elf query, compute the XOR of the path between nodes a and b.\n    - For unknown edges, set their values such that all elf constraints are satisfied.\n\n# [edge case] \n    Edge Case 1: A tree with only two nodes and one edge with a known value.\n    Input: \n    ```\n    1\n    2 1\n    1 2 3\n    1 2 0\n    ```\n    Expected Output: YES\n    Explanation: The only edge has a known value, and it satisfies the elf\'s parity requirement.\n\n    Edge Case 2: A tree with three nodes where all edges have unknown values.\n    Input:\n    ```\n    1\n    3 2\n    1 2 -1\n    2 3 -1\n    1 3 0\n    2 3 1\n    ```\n    Expected Output: NO\n    Explanation: It\'s impossible to assign values to both edges such that both elf constraints are satisfied.\n\n    Edge Case 3: A tree with four nodes where one edge has a known value and others are unknown.\n    Input:\n    ```\n    1\n    4 2\n    1 2 -1\n    2 3 -1\n    3 4 5\n    1 4 0\n    2 4 1\n    ```\n    Expected Output: YES\n    Explanation: The known edge value helps in determining possible values for unknown edges to satisfy elf constraints.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where all edges have unknown values or conflicting parity requirements.\n    \n```python\ndef handle_edge_cases(n, m, edges, queries):\n    # Initialize data structures for DFS and parity checking\n    xor_values = [-1] * (n + 1)\n    \n    # Perform DFS to calculate XOR values from root to each node\n    def dfs(node, parent, current_xor):\n        xor_values[node] = current_xor\n        for neighbor, value in edges[node]:\n            if neighbor != parent:\n                dfs(neighbor, node, current_xor ^ value)\n    \n    # Check if all constraints can be satisfied\n    def check_constraints():\n        for a, b, p in queries:\n            if (xor_values[a] ^ xor_values[b]) % 2 != p:\n                return False\n        return True\n    \n    # Main logic to handle edge cases\n    for i in range(1, n + 1):\n        if xor_values[i] == -1:\n            dfs(i, -1, 0)\n    \n    if not check_constraints():\n        return "NO"\n    \n    # Assign values to unknown edges if possible\n    for x, y, v in edges:\n        if v == -1:\n            # Assign a value that satisfies all constraints\n            pass\n    \n    return "YES"\n```', '- name: \nDFS with XOR Propagation\n\n- content: \nThis solution involves using Depth-First Search (DFS) to propagate XOR values and check for consistency with the elf constraints.\n1. Represent the tree using an adjacency list.\n2. Choose a node as the root and perform a DFS to determine the XOR value of each node from the root (XOR from root to each node).\n3. Initialize all unknown edge values as unset.\n4. For each known edge value, set its value and propagate this information through DFS to maintain correct XOR values for nodes.\n5. For each elf constraint:\n   - Determine the XOR of path between nodes a and b using their precomputed XOR values from the root.\n   - Check if this XOR value satisfies the parity constraint given by the elf.\n   - If not satisfied, attempt to adjust unknown edge values along the path if necessary.\n6. If all constraints are consistent after processing, output "YES" and construct valid edge values; otherwise, output "NO".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected graph with no cycles, consisting of nodes and edges. In this problem, the tree has n nodes and n-1 edges.\n\n    \'bitwise XOR\'\n    Explanation: XOR is a bitwise operation that takes two bits and returns 1 if the bits are different, and 0 if they are the same. It is used here to determine the elf\'s favorite number based on the lights on the path between two nodes.\n\n    \'parity\'\n    Explanation: Parity refers to whether a number is odd or even. In this context, it refers to the number of 1\'s in the binary representation of the elf\'s favorite number.\n\n# [phrase showing quantity relationship]\n    \'n nodes in the tree, connected by n-1 edges\'\n    Explanation: This indicates that the graph is a tree, as a tree with n nodes always has n-1 edges.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps 4 and 5 should be considered simultaneously:\n    - For each known edge value, set its value and propagate this information through DFS to maintain correct XOR values for nodes.\n    - For each elf constraint, determine the XOR of path between nodes a and b using their precomputed XOR values from the root, check if this XOR value satisfies the parity constraint given by the elf, and adjust unknown edge values along the path if necessary.\n    This can be implemented by performing a DFS traversal to propagate XOR values and simultaneously checking and adjusting for elf constraints.\n\n# [edge case]\n    Case 1: A tree with only two nodes and one edge with an unknown value.\n    Input: \n    ```\n    1\n    2 1\n    1 2 -1\n    1 2 0\n    ```\n    Expected Output: YES\n    Explanation: The only edge can be set to 0 to satisfy the parity constraint.\n\n    Case 2: A tree where all edges have known values, but one elf constraint cannot be satisfied.\n    Input:\n    ```\n    1\n    3 1\n    1 2 0\n    2 3 1\n    1 3 0\n    ```\n    Expected Output: NO\n    Explanation: The XOR from node 1 to node 3 is 1, which does not satisfy the parity constraint of even (0).\n\n    Case 3: A tree with multiple paths and conflicting elf constraints.\n    Input:\n    ```\n    1\n    4 2\n    1 2 -1\n    2 3 -1\n    3 4 -1\n    1 4 0\n    2 4 1\n    ```\n    Expected Output: NO\n    Explanation: The constraints are conflicting because satisfying one will violate the other.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        - Implement a function to perform DFS and propagate XOR values.\n        - Implement logic to check and adjust unknown edge values based on elf constraints.\n        - Ensure that all constraints are checked for consistency before outputting "YES" or "NO".', '- name: \nBFS with Constraint Propagation\n\n- content: \nThis solution involves using Breadth First Search (BFS) for traversing the tree and propagating constraints across edges. The BFS approach can efficiently handle tree structures and maintain parity constraints.\n\nSteps:\n1. Represent the tree as an adjacency list for efficient traversal.\n2. For each test case, start BFS from an arbitrary root node, computing XOR values from the root to each node.\n3. Process known edges first to determine fixed XOR values on paths, and mark visited nodes.\n4. For each elf\'s constraint, traverse using BFS from node a to node b, ensuring that the path satisfies the given parity constraint.\n5. Use BFS propagation to deduce values of unknown edges based on neighboring edges and constraints, ensuring consistency across nodes.\n6. If any conflicts arise (i.e., unable to satisfy a constraint), return "NO". Otherwise, if successful, assign values to remaining unknown edges and return "YES" with edge configuration.\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected graph with no cycles, consisting of nodes and edges. In this problem, the tree has n nodes and n-1 edges.\n\n    \'bitwise XOR\'\n    Explanation: Bitwise XOR is a binary operation that takes two bits and returns 1 if the bits are different, and 0 if they are the same. It is used here to determine the elf\'s favorite number based on the lights on the path between two nodes.\n\n    \'parity\'\n    Explanation: Parity refers to whether a number has an odd or even number of set bits (1s) in its binary representation. The elves remember the parity of their favorite number.\n\n# [phrase showing quantity relationship]\n    \'n nodes, n-1 edges\': This indicates that the graph is a tree, as a tree with n nodes always has n-1 edges.\n    \n    \'2 ≤ n ≤ 2 ⋅ 10^5; 1 ≤ m ≤ 2 ⋅ 10^5\': These constraints define the size limits for the tree and the number of elves.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    Steps 3 and 5 should be considered simultaneously. While processing known edges and propagating constraints, BFS can be used to deduce values of unknown edges based on neighboring edges and constraints. This ensures consistency across nodes and helps in determining if a valid configuration exists.\n\n# [edge case]\n    Case 1: A tree with all known edge values and consistent elf constraints.\n    Explanation: If all edge values are known and satisfy all elf constraints, the output should be "YES" with the given edge configuration.\n\n    Case 2: A tree with conflicting elf constraints.\n    Explanation: If any elf constraint cannot be satisfied due to conflicting parity requirements, the output should be "NO".\n\n    Case 3: A tree with unknown edge values but consistent elf constraints.\n    Explanation: If unknown edge values can be deduced to satisfy all elf constraints, the output should be "YES" with a valid edge configuration.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases where unknown edge values need to be deduced.\n    \n```python\ndef solve_tree_constraints(t, test_cases):\n    results = []\n    for case in test_cases:\n        n, m, edges, elves = case\n        # Initialize adjacency list for the tree\n        adj_list = {i: [] for i in range(1, n + 1)}\n        for x, y, v in edges:\n            adj_list[x].append((y, v))\n            adj_list[y].append((x, v))\n        \n        # BFS to propagate constraints\n        def bfs_propagate():\n            # Implement BFS logic to propagate known values and deduce unknowns\n            pass\n        \n        # Check consistency of elf constraints\n        def check_constraints():\n            # Implement logic to check if all elf constraints can be satisfied\n            pass\n        \n        if bfs_propagate() and check_constraints():\n            results.append("YES")\n            # Append edge configuration\n        else:\n            results.append("NO")\n    \n    return results\n```\n\nThis code outlines a structure for handling the problem using BFS to propagate constraints and check consistency. The actual implementation details would involve filling in the BFS logic and constraint checking based on the problem requirements.', '- name: \nUnion-Find with XOR Path Analysis\n\n- content: \n- Implement a Union-Find data structure to manage connected components and track XOR paths between nodes.\n- For each test case, initialize components and handle known edges by updating XOR values for connected nodes.\n- For queries involving parity, analyze the path between two nodes using XOR values and ensure it matches the given parity.\n- If unknown edges exist, use parity constraints to deduce possible XOR values for these edges.\n- Verify if all given elf constraints can be satisfied by the deduced configuration.\n- If satisfied, output "YES" and the reconstructed tree; otherwise, "NO".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'tree\'\n    Explanation: A tree is a connected graph with no cycles, consisting of nodes and edges. In this problem, the tree has n nodes and n-1 edges.\n\n    \'bitwise XOR\'\n    Explanation: A bitwise XOR operation takes two binary numbers and returns a binary number where each bit is the result of XORing the corresponding bits of the input numbers. In this context, it is used to determine the elf\'s favorite number based on the lights on the path.\n\n    \'parity\'\n    Explanation: Parity refers to whether a number has an odd or even number of set bits (1s) in its binary representation. The elves remember the parity of their favorite number.\n\n# [phrase showing quantity relationship]\n    \'n nodes and n-1 edges\': This indicates that the graph is a tree, as a tree with n nodes always has n-1 edges.\n    \n    \'at least\': This phrase is not explicitly present in the requirement but is implied in the context of ensuring that all constraints are satisfied.\n\n# [degree adverb]\n    No degree adverb\n\n# [code logic]\n    The steps involving handling known edges and analyzing paths for parity constraints should be considered simultaneously. Specifically, when processing each test case, known edges should be used to update XOR values, and parity constraints should be checked in tandem to deduce possible values for unknown edges.\n\n# [edge case]\n    Case 1: A tree with only two nodes and one edge with a known value.\n    Input: \n    ```\n    1\n    2 1\n    1 2 3\n    1 2 0\n    ```\n    Expected Output: YES\n    Explanation: The only edge has a known value, and the parity constraint matches.\n\n    Case 2: A tree with three nodes where all edges have unknown values.\n    Input:\n    ```\n    1\n    3 2\n    1 2 -1\n    2 3 -1\n    1 3 0\n    2 3 1\n    ```\n    Expected Output: NO\n    Explanation: It\'s impossible to assign values to the edges that satisfy both parity constraints.\n\n    Case 3: A tree with four nodes where one edge has a known value and others are unknown.\n    Input:\n    ```\n    1\n    4 2\n    1 2 -1\n    2 3 -1\n    3 4 5\n    1 4 0\n    2 4 1\n    ```\n    Expected Output: YES\n    Explanation: The known edge value helps deduce possible values for unknown edges that satisfy all constraints.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        (code for handling the edge case)\n        - Implement a function to check if all parity constraints can be satisfied given the current configuration of known and deduced edge values.\n        - Use a Union-Find data structure to efficiently manage connected components and track XOR paths.\n        - For each test case, initialize components and handle known edges by updating XOR values for connected nodes.\n        - For queries involving parity, analyze the path between two nodes using XOR values and ensure it matches the given parity.\n        - If unknown edges exist, use parity constraints to deduce possible XOR values for these edges.\n        - Verify if all given elf constraints can be satisfied by the deduced configuration.', '- name: \nDepth-First Search with Parity Constraints\n\n- content: \nThis approach uses a Depth-First Search (DFS) to traverse the tree and determine the values of the edges based on the parity constraints provided by the elves.\n\nSteps:\n1. Construct an adjacency list for the tree based on the given edges.\n2. Define a DFS function that will traverse from a starting node, calculating XOR values along paths and keeping track of parity constraints.\n3. Start DFS from an arbitrary root node, assigning values to edges as you traverse.\n4. For each elf\'s constraint, compute the XOR for the path between nodes a and b using the DFS results.\n5. Check if the computed XOR value\'s parity matches the given parity p. If not, adjust the values on the path if possible.\n6. Handle unknown edge values (-1) by deducing their values from known constraints.\n7. If all constraints are met, print "YES" and the edge values; otherwise, print "NO".\n\n\nPlease read and understand the following inteperation before coding\n# [core concept]\n    \'bitwise XOR\'\n    Explanation: Bitwise XOR is a binary operation that takes two bit patterns of equal length and performs the logical exclusive OR operation on each pair of corresponding bits. The result in each position is 1 if the bits are different, and 0 if they are the same.\n\n    \'parity\'\n    Explanation: Parity refers to whether the number of set bits (1s) in a binary number is odd or even.\n\n# [phrase showing quantity relationship]\n    \'more than zero\': This indicates that the integer values on the edges must be non-negative.\n    \'at least as many times\': This phrase does not directly apply to this requirement but generally means a quantity must be equal to or greater than another.\n\n# [degree adverb] \n    No degree adverb\n\n# [code logic]\n    Steps 4 and 5 should be considered simultaneously. When checking if the computed XOR value\'s parity matches the given parity, adjustments to the path values should be made if possible. This can be implemented using a conditional statement within the DFS traversal.\n\n# [edge case] \n    Test case with minimum nodes and edges:\n    Input: 2 1\n           1 2 -1\n           1 2 0\n    Expected output: YES\n                     1 2 0\n    Explanation: With only one edge and one elf, the edge value can be set to 0 to satisfy the parity condition.\n\n    Test case with conflicting parity:\n    Input: 3 2\n           1 2 -1\n           2 3 -1\n           1 3 0\n           1 2 1\n    Expected output: NO\n    Explanation: The parity conditions for paths (1,3) and (1,2) conflict, making it impossible to assign consistent values.\n\n    Test case with all known values:\n    Input: 3 2\n           1 2 0\n           2 3 1\n           1 3 0\n           1 2 0\n    Expected output: YES\n                     1 2 0\n                     2 3 1\n    Explanation: All edge values are known and satisfy the parity conditions.\n\n# [extra code for edge case]\n    We need extra code to handle the edge cases.\n        def handle_edge_cases(n, m, edges, elves):\n            # Initialize edge values dictionary\n            edge_values = {}\n            for x, y, v in edges:\n                if v != -1:\n                    edge_values[(x, y)] = v\n            \n            # Check for conflicting parity conditions\n            for a, b, p in elves:\n                path_xor = calculate_path_xor(a, b, edge_values)\n                if path_xor % 2 != p:\n                    return "NO"\n            \n            # Assign values to unknown edges if possible\n            for x, y, v in edges:\n                if v == -1:\n                    edge_values[(x, y)] = deduce_value(x, y, elves)\n            \n            return "YES", edge_values\n\n        def calculate_path_xor(a, b, edge_values):\n            # Implement DFS or BFS to calculate XOR along path from a to b\n            pass\n\n        def deduce_value(x, y, elves):\n            # Deduce value based on constraints from elves\n            pass']
----------
False
----------
0
